<!DOCTYPE html>
<!--
    Type on Strap jekyll theme v2.4.3
    Theme free for personal and commercial use under the MIT license
    https://github.com/sylhare/Type-on-Strap/blob/master/LICENSE
-->
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, minimum-scale=0.5, maximum-scale=5"
    />

    <!-- Theme Mode-->

    <script>
      const isAutoTheme = true;
      document.documentElement.setAttribute(
        "data-theme",
        sessionStorage.getItem("theme")
      );
    </script>

    <!-- Main JS (navbar.js, katex_init.js and masonry_init.js)-->
    <script defer src="/assets/js/main.min.js"></script>

    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css" />

    <!--Favicon-->
    <link rel="shortcut icon" href="" type="image/x-icon" />

    <!-- KaTeX 0.15.2 -->

    <script defer src="/assets/js/vendor/katex.min.js"></script>
    <script
      defer
      src="/assets/js/vendor/auto-render.min.js"
      onload="renderMathInElement(document.body);"
    ></script>

    <!-- Mermaid 9.1.1 -->

    <!-- Simple Jekyll Search 1.10.0 -->
    <script
      src="/assets/js/vendor/simple-jekyll-search.min.js"
      type="text/javascript"
    ></script>

    <!-- Google Analytics / Cookie Consent -->
    <script>
      const cookieName = "cookie-notice-dismissed-https://blog.k3fu.xyz";
      const isCookieConsent = "";
      const analyticsName = "";
      const analyticsNameGA4 = "";
    </script>

    <!-- seo tags -->
    <meta property="og:image" content="https://blog.k3fu.xyz/" />

    <meta property="og:type" content="website" />

    <!-- Begin Jekyll SEO tag v2.7.1 -->
    <title>io_uring + Seastar | some random rants</title>
    <meta name="generator" content="Jekyll v4.1.1" />
    <meta property="og:title" content="io_uring + Seastar" />
    <meta name="author" content="Kefu Chai" />
    <meta property="og:locale" content="en" />
    <meta
      name="description"
      content="如何用在 Seastar 里用上 IORING_OP_SEND_ZC？"
    />
    <meta
      property="og:description"
      content="如何用在 Seastar 里用上 IORING_OP_SEND_ZC？"
    />
    <link
      rel="canonical"
      href="https://blog.k3fu.xyz/seastar/2022/10/03/iouring-seastar.html"
    />
    <meta
      property="og:url"
      content="https://blog.k3fu.xyz/seastar/2022/10/03/iouring-seastar.html"
    />
    <meta property="og:site_name" content="some random rants" />
    <meta property="og:type" content="article" />
    <meta
      property="article:published_time"
      content="2022-10-03T00:00:00+00:00"
    />
    <meta name="twitter:card" content="summary" />
    <meta property="twitter:title" content="io_uring + Seastar" />
    <script type="application/ld+json">
      {
        "datePublished": "2022-10-03T00:00:00+00:00",
        "author": { "@type": "Person", "name": "Kefu Chai" },
        "mainEntityOfPage": {
          "@type": "WebPage",
          "@id": "https://blog.k3fu.xyz/seastar/2022/10/03/iouring-seastar.html"
        },
        "description": "如何用在 Seastar 里用上 IORING_OP_SEND_ZC？",
        "url": "https://blog.k3fu.xyz/seastar/2022/10/03/iouring-seastar.html",
        "@type": "BlogPosting",
        "headline": "io_uring + Seastar",
        "dateModified": "2022-10-03T00:00:00+00:00",
        "@context": "https://schema.org"
      }
    </script>
    <!-- End Jekyll SEO tag -->

    <!-- RSS -->
    <link
      rel="alternate"
      type="application/atom+xml"
      title="some random rants"
      href="https://blog.k3fu.xyz/feed.xml"
    />
    <link
      type="application/atom+xml"
      rel="alternate"
      href="https://blog.k3fu.xyz/feed.xml"
      title="some random rants"
    />

    <!-- Twitter Cards -->
    <meta name="twitter:title" content="io_uring + Seastar" />
    <meta
      name="twitter:description"
      content="如何用在 Seastar 里用上 IORING_OP_SEND_ZC？引子Seastar 的磁盘 IOSeastar 的网络 IO如何让 Seastar 的网络 IO 用上 io_uring网卡和硬盘乐观和悲观io_queue引子linux 6.0 为我们带来了 zero-copy 网络传输的 io_uring ..."
    />

    <meta name="twitter:card" content="summary" />
    <meta name="twitter:image" content="https://blog.k3fu.xyz/" />
    <meta name="twitter:image:alt" content="io_uring + Seastar" />
  </head>

  <body>
    <header class="site-header">
      <!-- Logo and title -->
      <div class="branding">
        <a class="site-title" aria-label="some random rants" href="/">
          some random rants
        </a>
      </div>

      <!-- Toggle menu -->
      <nav class="clear">
        <a aria-label="pull" id="pull" class="toggle" href="#">
          <i class="fas fa-bars fa-lg"></i>
        </a>

        <!-- Menu -->
        <ul class="hide">
          <li class="separator">|</li>
          <li>
            <a class="clear" aria-label="关于" title="关于" href="/about/">
              关于
            </a>
          </li>

          <li class="separator">|</li>
          <li>
            <a class="clear" aria-label="搜索" title="搜索" href="/search/">
              <i class="fas fa-search" aria-hidden="true"></i>
            </a>
          </li>

          <li class="separator">|</li>
          <li>
            <a class="clear" aria-label="Tags" title="Tags" href="/tags/">
              <i class="fas fa-tags" aria-hidden="true"></i>
            </a>
          </li>

          <li class="separator">|</li>
          <li>
            <a
              id="theme-toggle"
              title="io_uring + Seastar "
              aria-label="io_uring + Seastar"
              onclick="themeToggle()"
            ></a>
          </li>
        </ul>
      </nav>
    </header>

    <div class="content">
      <article>
        <header id="main" style="">
          <div class="title-padder">
            <h1 id="io_uring+%2B+Seastar" class="title">io_uring + Seastar</h1>

            <div class="post-info">
              <p class="meta">October 03, 2022</p>
            </div>
          </div>
        </header>

        <section class="post-content">
          <div id="preamble">
            <div class="sectionbody">
              <div class="paragraph">
                <p>如何用在 Seastar 里用上 <code>IORING_OP_SEND_ZC</code>？</p>
              </div>
              <div id="toc" class="toc">
                <div id="toctitle" class="title"></div>
                <ul class="sectlevel1">
                  <li><a href="#引子">引子</a></li>
                  <li><a href="#seastar-的磁盘-io">Seastar 的磁盘 IO</a></li>
                  <li><a href="#seastar-的网络-io">Seastar 的网络 IO</a></li>
                  <li>
                    <a href="#如何让-seastar-的网络-io-用上-io_uring"
                      >如何让 Seastar 的网络 IO 用上 io_uring</a
                    >
                    <ul class="sectlevel2">
                      <li><a href="#网卡和硬盘">网卡和硬盘</a></li>
                      <li><a href="#乐观和悲观">乐观和悲观</a></li>
                      <li><a href="#io_queue">io_queue</a></li>
                    </ul>
                  </li>
                </ul>
              </div>
            </div>
          </div>
          <div class="sect1">
            <h2 id="引子">引子</h2>
            <div class="sectionbody">
              <div class="paragraph">
                <p>
                  <a href="https://lwn.net/Articles/910087/">linux 6.0</a>
                  为我们带来了
                  <a href="https://lwn.net/Articles/879724/"
                    >zero-copy 网络传输的 io_uring 支持</a
                  >。但是 Seastar 对 iouring
                  的支持仍然很有限，它仅仅支持下面几种操作
                </p>
              </div>
              <div class="olist arabic">
                <ol class="arabic">
                  <li>
                    <p>read</p>
                  </li>
                  <li>
                    <p>write</p>
                  </li>
                  <li>
                    <p>readv</p>
                  </li>
                  <li>
                    <p>writev</p>
                  </li>
                </ol>
              </div>
              <div class="paragraph">
                <p>
                  而迄今为止 io uring 已经支持了
                  <a
                    href="https://github.com/axboe/liburing/blob/cf0b010a7b862ee6a44daa7dcb3f900bd757b04f/src/include/liburing/io_uring.h#L167"
                    >48 种异步操作</a
                  >，这四种操作只是冰山一角。本文希望讨论一下如何为 Seastar
                  加入一部分网络 IO 的 io_uring 支持。
                </p>
              </div>
            </div>
          </div>
          <div class="sect1">
            <h2 id="seastar-的磁盘-io">Seastar 的磁盘 IO</h2>
            <div class="sectionbody">
              <div class="paragraph">
                <p>
                  让我们先理解
                  <code>reactor_backend_uring</code> 是如何工作的。下面是
                  <code>reactor_backend_uring</code>
                  提交 IO 请求的调用路径。可以注意到，Seastar
                  是成批地提交请求的。而且请求并不是在
                  <code>poll_once()</code> 的时候创建的，它们往往在类似
                  <code>posix_file_impl::do_write_dma()</code>
                  的地方创建，并加入当前访问文件所对应的
                  <code>_io_queue</code> 队列。
                </p>
              </div>
              <div class="imageblock">
                <div class="content">
                  <img
                    src="/images/diag-b7ad16af82b7c0a669869e580471a17a.png"
                    alt="Diagram"
                    width="680"
                    height="392"
                  />
                </div>
              </div>
              <div class="paragraph">
                <p>
                  那么 <code>_io_queue</code> 是什么呢？Seastar 为了解决多 shard
                  共享磁盘 IO，同时最大化其吞吐量的问题，设计了
                  <a
                    href="https://www.scylladb.com/2021/04/06/scyllas-new-io-scheduler/"
                    >用户态的 IO 调度机制</a
                  >。避免在 shard
                  之间搞平均主义和大锅饭，导致低效和拥塞。为了在核之间统筹规划
                  IO，Seastar 为每个设备定义一个
                  <code>io_group</code>，同时让每个 shard
                  都持有和需要访问的设备对应的
                  <code>shared_ptr&lt;io_group&gt;</code>。为了安放还不能服务的
                  IO 请求，每个设备在每个shard 上的
                  <code>engine</code> 都有自己的
                  <code>io_queue</code>。因此可以看到所以如果程序部署在 32
                  核的机器上，同时有 16 块硬盘，那么每个核都会有 16 个
                  <code>io_queue</code>，分别对应自己负责访问的硬盘。
                </p>
              </div>
              <div class="paragraph">
                <p>
                  另外，也需要注意
                  <code>reactor_backend_uring::submit_io_request()</code>
                  的实现，
                </p>
              </div>
              <div class="listingblock">
                <div class="content">
                  <pre
                    class="rouge highlight"
                  ><code data-lang="c++"><span class="k">auto</span> <span class="n">sqe</span> <span class="o">=</span> <span class="n">get_sqe</span><span class="p">();</span>
<span class="k">switch</span> <span class="p">(</span><span class="n">req</span><span class="p">.</span><span class="n">opcode</span><span class="p">())</span> <span class="p">{</span>
  <span class="k">case</span> <span class="n">o</span><span class="o">::</span><span class="n">read</span><span class="p">:</span>
    <span class="o">::</span><span class="n">io_uring_prep_read</span><span class="p">(</span><span class="n">sqe</span><span class="p">,</span> <span class="n">req</span><span class="p">.</span><span class="n">fd</span><span class="p">(),</span> <span class="n">req</span><span class="p">.</span><span class="n">address</span><span class="p">(),</span> <span class="n">req</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">req</span><span class="p">.</span><span class="n">pos</span><span class="p">());</span>
    <span class="k">break</span><span class="p">;</span>
  <span class="c1">// ...</span>
<span class="p">}</span>
<span class="o">::</span><span class="n">io_uring_sqe_set_data</span><span class="p">(</span><span class="n">sqe</span><span class="p">,</span> <span class="n">completion</span><span class="p">);</span>
<span class="n">_has_pending_submissions</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span></code></pre>
                </div>
              </div>
              <div class="paragraph">
                <p><code>get_sqe()</code> 是一个循环：</p>
              </div>
              <div class="listingblock">
                <div class="content">
                  <pre
                    class="rouge highlight"
                  ><code data-lang="c++"><span class="n">io_uring_sqe</span><span class="o">*</span> <span class="n">sqe</span> <span class="o">=</span> <span class="nb">nullptr</span><span class="p">;</span>
<span class="k">for</span> <span class="p">(;;)</span> <span class="p">{</span>
  <span class="n">sqe</span> <span class="o">=</span> <span class="n">io_uring_get_sqe</span><span class="p">(</span><span class="o">&amp;</span><span class="n">_uring</span><span class="p">);</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">sqe</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">sqe</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="n">io_uring_submit</span><span class="p">(</span><span class="o">&amp;</span><span class="n">_uring</span><span class="p">);</span>
  <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="n">cqe</span> <span class="o">:</span> <span class="n">io_uring_peek_batch_cqe</span><span class="p">())</span> <span class="p">{</span>
    <span class="n">cqe</span><span class="o">-&gt;</span><span class="n">complete</span><span class="p">();</span>
    <span class="n">io_uring_cqe_seen</span><span class="p">(</span><span class="o">&amp;</span><span class="n">_uring</span><span class="p">,</span> <span class="n">cqe</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre>
                </div>
              </div>
              <div class="paragraph">
                <p>这里有两个需要注意的地方：</p>
              </div>
              <div class="olist arabic">
                <ol class="arabic">
                  <li>
                    <p>
                      IO 请求都是从 <code>io_queue</code> 里面取出来的。而
                      <code>io_queue</code> 是用户态 IO
                      调度器的一部分。显然，这个 IO 调度器并不包含网络 IO。
                    </p>
                  </li>
                  <li>
                    <p>
                      和 aio 不同，io uring 后端的
                      <code>kernel_submit_work()</code> 除了执行 submit
                      的动作，在 sqe 不够的时候也会执行
                      <code>reap_kernel_completions()</code>。
                    </p>
                  </li>
                </ol>
              </div>
              <div class="paragraph">
                <p>
                  不过笔者认为，如果 sqe 不够用，那么收割 cqe
                  有可能是无济于事的。除非内核的网络子系统会因为用户取走 cqe
                  不够快而减缓 sqe 的处理。
                </p>
              </div>
              <div class="paragraph">
                <p>
                  既然只有存储子系统的请求会走到这里，那么 Seastar
                  怎么处理网络上的 IO 请求呢？
                </p>
              </div>
            </div>
          </div>
          <div class="sect1">
            <h2 id="seastar-的网络-io">Seastar 的网络 IO</h2>
            <div class="sectionbody">
              <div class="paragraph">
                <p>
                  下面是 Seastar 写入 <code>output_stream</code> 流的调用路径：
                </p>
              </div>
              <div class="imageblock">
                <div class="content">
                  <img
                    src="/images/diag-960814248f756371b9e0604c558e73c8.png"
                    alt="Diagram"
                    width="590"
                    height="448"
                  />
                </div>
              </div>
              <div class="paragraph">
                <p>其中，<code>reactor::do_write_some()</code> 的实现类似</p>
              </div>
              <div class="listingblock">
                <div class="content">
                  <pre
                    class="rouge highlight"
                  ><code data-lang="c++"><span class="k">co_await</span> <span class="nf">writeable</span><span class="p">(</span><span class="n">fd</span><span class="p">);</span>
<span class="n">msghdr</span> <span class="n">mh</span> <span class="o">=</span> <span class="p">{</span>
  <span class="p">.</span><span class="n">msg_iov</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="n">fragment_array</span><span class="p">(),</span>
  <span class="p">.</span><span class="n">msg_iovlen</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="n">nr_frags</span><span class="p">(),</span>
<span class="p">};</span>
<span class="n">fd</span><span class="p">.</span><span class="n">sendmsg</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mh</span><span class="p">);</span></code></pre>
                </div>
              </div>
              <div class="paragraph">
                <p>
                  所以 <code>reactor::do_write_some()</code> 会等到 fd
                  可以写入的时候，再进行系统调用，确保这个
                  <code>::sendmsg()</code> 是不阻塞的。
                </p>
              </div>
              <div class="paragraph">
                <p>可以看出这两类 IO 在 Seastar 里的处理方式很不一样。</p>
              </div>
            </div>
          </div>
          <div class="sect1">
            <h2 id="如何让-seastar-的网络-io-用上-io_uring">
              如何让 Seastar 的网络 IO 用上 io_uring
            </h2>
            <div class="sectionbody">
              <div class="sect2">
                <h3 id="网卡和硬盘">网卡和硬盘</h3>
                <div class="paragraph">
                  <p>再看硬件设备的异同点：</p>
                </div>
                <div class="ulist">
                  <ul>
                    <li>
                      <p>
                        一方面，网卡有和存储类似的属性，比如说，它们都有吞吐量、队列深度这些全局的硬件指标。
                      </p>
                    </li>
                    <li>
                      <p>
                        另一方面，一般来说网卡和存储相比有高得多的吞吐。毕竟
                        40Gbps 的万兆网卡几百块就可以买到。 3100MB/s
                        的企业级固态盘的价格仍然高居不下，从数千到上万不等。这样也解释了为什么
                        Seastar 开发者为什么对用户态 IO 调度这么重视。
                      </p>
                    </li>
                    <li>
                      <p>
                        最后，一般服务器可能只会安装两块网卡。但是可能会有一个
                        36 x 3.5寸盘位的高密机箱。
                      </p>
                    </li>
                  </ul>
                </div>
                <div class="paragraph">
                  <p>
                    那么把磁盘 IO 的用户态调度器的机制套用在网络 IO
                    上是否可行呢？答案是否定的。一台服务器上可以有多个网络出口。网卡也可以支持虚拟化，比如
                    SR-IOV，或者用 bond
                    把多块物理网卡捆绑成一块逻辑网卡。为了后面讨论简单起见，我们把这些网络出口简称为网卡。操作系统通过路由表来决定特定网络包使用哪块网卡。而我们在读写网络
                    socket 的时候，分两种情况
                  </p>
                </div>
                <div class="ulist">
                  <ul>
                    <li>
                      <p>
                        读：这里我们无法预判将要读到的网络包是经由那块网卡发来的。本机路由表仅仅定义我们转发包的规则，
                        但是它没有定义交换机把数据包发给本机的哪块网卡。
                      </p>
                    </li>
                    <li>
                      <p>
                        写：路由规则是系统层面的设置。就算我们在用户态可以根据路由表来判断发出的网络包会选用那块网卡，
                        并且根据这个信息和网卡的带宽来做 shard
                        间的公平调度，这也是很麻烦的事情。
                      </p>
                    </li>
                  </ul>
                </div>
                <div class="paragraph">
                  <p>
                    因为网卡的总体吞吐能力大大超过了存储设备，同时访问特定网段的网卡只有一两块，而我们的存储子系统常常需要同时和几十块硬盘打交道。所以为网络
                    IO
                    定义用户态调度器一方面难度挺高，一方面效益也不大，并且有的场景无法覆盖。如果只有单块网卡的话，问题稍简单一些。但仍然会是个投入产出不成正比的工程。
                  </p>
                </div>
              </div>
              <div class="sect2">
                <h3 id="乐观和悲观">乐观和悲观</h3>
                <div class="paragraph">
                  <p>
                    前面得出了不需要用户态 IO 调度的结论。那么发送网络 IO 还需要
                    <code>io_queue</code> 吗？如果
                    <code>io_queue</code> 不用来实现 per-shard
                    的公平队列，那么它的意义只是在于临时保存 IO
                    请求，让我们可以在成批地构造和发送 IO 到 sq
                    里面去。新的问题来了，什么时候 <strong>发送</strong> IO
                    呢？或者说，我们应该/可以立即发送 IO 吗？有两个选择：
                  </p>
                </div>
                <div class="ulist">
                  <ul>
                    <li>
                      <p>
                        在 <code>reactor_backend_uring::write_some()</code> 里
                      </p>
                    </li>
                    <li>
                      <p>
                        在
                        <code>reactor_backend_uring::kernel_submit_work()</code>
                        里
                      </p>
                    </li>
                  </ul>
                </div>
                <div class="paragraph">
                  <p>
                    如果我们退后一步看，其实也可以乐观地用
                    <code>sendmsg(&#8230;&#8203;, MSG_DONTWAIT)</code>
                    先试试看，如果系统返回 <code>EWOULDBLOCK</code>，那么再用
                    <code>reactor::do_write_some()</code> 的方式来处理这个
                    IO。我们知道，在内核里面的读写都是有 buffer
                    的。所以如果写缓冲区大小为 4k，每次只写 512
                    字节，那么我们可以连着写 8 次都不需要检查
                    <code>POLLOUT</code> 。当然，在第 9 次的时候， 就会返回
                    <code>EWOULDBLOCK</code>
                    了。这时我们可以切换到悲观模式，一旦写请求返回了，说明内核至少消耗了一部分缓冲区，这时我们可以重新振作，回到乐观模式。乐观模式可以直接在
                    <code>reactor_backend_uring::write_some()</code>
                    直接把请求发送给内核，而悲观模式的工作则需要在
                    <code>reactor_backend_uring::kernel_submit_work()</code>
                    完成处理。
                  </p>
                </div>
                <div class="paragraph">
                  <p>
                    只要非阻塞的操作有“惯性”，那么我们就可以使用“乐观模式”和“悲观模式”的设计。因此，它也适用于其他
                    reactor backend。不过对于 io_uring 需要特别的权衡。因为
                    <code>sendmsg(&#8230;&#8203;, MSG_DONTWAIT)</code>
                    本身仍然是一次系统调用，如果我们希望使用 SQPOLL
                    模式的话，这个开销是不容忽视的。如果不采用 SQPOLL
                    模式，那么把一次
                    <code>sendmsg(&#8230;&#8203;, MSG_DONTWAIT)</code> 和两次
                    <code>io_uring_submit()</code>
                    以及相应的两次协程切换相比，哪个效率更高，延迟更低呢？笔者认为“不好说”。但是对于高性能网卡来说，很可能前者性能更好。因为它能更早地把请求交给内核。而非
                    SQPOLL 模式下，两次
                    <code>io_uring_submit()</code>
                    可是两次结结实实的系统调用。虽然这两次系统调用的开销可能可以分摊到发送的多个
                    sqe 上，但是对单个 IO 产生的延迟却是实实在在的。
                  </p>
                </div>
                <div class="paragraph">
                  <p>
                    如果不用“乐观模式”，假设我们只在
                    <code>reactor_backend_uring::kernel_submit_work()</code> 和
                    <code
                      >reactor_backend_uring::wait_and_process_events()</code
                    >
                    里面调用
                    <code>io_uring_submit()</code
                    >，那么这两个选项的延迟是相同的。毕竟，内核只能看到 submit
                    之后的 sqe。
                  </p>
                </div>
              </div>
              <div class="sect2">
                <h3 id="io_queue">io_queue</h3>
                <div class="paragraph">
                  <p>
                    从设计方面考虑，每个 <code>reactor</code> 都有自己的
                    <code>io_sink</code>，"sink" 可以理解为汇聚地。在
                    <a
                      href="https://github.com/scylladb/seastar/commit/c91d9e632a3f27610a75ed3e94b1d5d2e9131243"
                      >c91d9e6</a
                    >
                    里面，作者提到
                  </p>
                </div>
                <div class="quoteblock">
                  <blockquote>
                    <div class="paragraph">
                      <p>
                        io_uring has a lot more operation types, and we would
                        like to keep them all in the same descriptor, so they
                        can be used by the same queue.
                      </p>
                    </div>
                  </blockquote>
                </div>
                <div class="paragraph">
                  <p>
                    这里的 “descriptor” 指 <code>io_request</code>。所以 Glauber
                    当初希望把更多的（或者说所有的） io_uring 操作统一成
                    <code>io_request</code>
                    放在一个队列里面。这样的好处应该是设计更一致，如果从性能角度分析的话，大概是
                    CPU 的 icache locality 更好吧。而且
                    <code>_io_sink</code> 并非只为
                    <code>io_queue</code> 服务。<code
                      >reactor::fdatasync()</code
                    >
                    就是个例子。它直接构造 new 出来
                    <code>io_completion</code> 和
                    <code>io_request</code>，把它们扔进了
                    <code>_io_sink</code>。大家可能会担心因为在 IO
                    路径上频繁动态内存分配，是不是会造成的性能问题。那么这真的是个问题，那么这个问题早已有之。因为
                    Seastar 里面的 <code>io_request</code> 其实就是
                    <strong>new</strong> 出来的，可以看看
                    <code>posix_file_impl::do_read_dma()</code> 的实现。在把
                    <code>io_request</code> 加入
                    <code>io_queue</code> 的时候，会新建一个
                    <code>queued_io_request</code>。它就是动态分配的，里面的
                    <code>io_desc_read_write</code> 继承自
                    <code>io_completion</code>。前者告诉 reactor
                    读写操作完成的时候应该做什么。后者是一个虚基类。自然
                    <code>io_desc_read_write</code> 也是动态分配的了。所以以存储
                    IO 的标准来评判，为每一个网络IO 动态分配
                    <code>io_comlpetion</code> 和
                    <code>io_request</code> 并不是很过分的事情。不过我们在实现
                    io_uring 支持的时候，可能无法重用
                    <code>io_desc_read_write</code> 了。因为它是用户态 IO
                    调度机制的一部分，其中还包含着公平队列的实现。
                  </p>
                </div>
                <div class="paragraph">
                  <p>
                    前面的讨论基本确定了我们倾向于用
                    <code>io_completion</code> 、 <code>io_request</code> 和
                    <code>io_sink</code> 的组合来发送 uring
                    请求。但是读者是否还记得
                    <code>reactor::do_write_some()</code> 的实现呢？它先等待
                    <code>writable(fd)</code>。这事实上起到 throttle
                    的作用，如果内核来不及消化这许多 IO 的话，fd 是不会 writable
                    的。那么 io_uring 的各种操作呢？如果我们希望用 Seastar
                    编写一个异步的 API
                    网关，那么在客户端发送大量请求的时候，倘若没有内核的反馈，可能会产生海量的
                    <code>io_request</code> 堆积在
                    <code>io_sink</code>
                    里面。这对性能不仅没有帮助，反而会短时间内消耗大量内存用于保存
                    <code>io_request</code> 以及
                    payload。笔者认为，可能更好的方式应该是在
                    <code>reactor_backend_uring::write_some()</code> 中加入类似
                    <code>co_await writable(fd)</code> 的环节。但是 Avi
                    还是建议直接把请求扔给 io_uring，这样可以获得更低的延迟。
                    因为使用 io_uring 提交 sendmsg
                    请求的几个步骤基本是不阻塞的：
                  </p>
                </div>
                <div class="listingblock">
                  <div class="content">
                    <pre
                      class="rouge highlight"
                    ><code data-lang="c++"><span class="k">auto</span> <span class="n">sqe</span> <span class="o">=</span> <span class="n">io_uring_get_sqe</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ring</span><span class="p">);</span>
<span class="n">io_uring_prep_sendmsg_zc</span><span class="p">(</span><span class="n">sqe</span><span class="p">,</span> <span class="n">fd</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">msghdr</span><span class="p">,</span> <span class="n">msg_flags</span><span class="p">);</span>
<span class="n">io_uring_sqe_set_data</span><span class="p">(</span><span class="n">sqe</span><span class="p">,</span> <span class="n">i</span><span class="p">);</span>
<span class="n">io_uring_submit</span><span class="p">(</span><span class="n">ring</span><span class="p">);</span></code></pre>
                  </div>
                </div>
                <div class="paragraph">
                  <p>
                    如果使用 <code>IORING_SETUP_SQPOLL</code>，<code
                      >io_uring_submit()</code
                    >
                    甚至不用陷入内核态，从而有更低的延迟。毕竟应用程序自己是可以设计
                    back pressure 机制的。如果希望在提交请求之前等待 poll
                    的结果，用这种方式实现 back pressure
                    则会提高延迟。这个想法的出发点并没有问题，但是它加重了
                    io_uring 的负担。因为每个
                    <code>poll(2)</code>
                    调用和返回值的处理，对应用程序和内核都会是个额外的开销。
                  </p>
                </div>
                <div class="paragraph">
                  <p>
                    所以沿用之前的基于预测（speculation）的设计，用 Python
                    伪代码来写就是：
                  </p>
                </div>
                <div class="listingblock">
                  <div class="content">
                    <pre
                      class="rouge highlight"
                    ><code data-lang="python"><span class="k">async</span> <span class="k">def</span> <span class="nf">write_some</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fd</span><span class="p">,</span> <span class="n">msg</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">fd</span><span class="p">.</span><span class="n">speculation</span><span class="p">.</span><span class="n">non_block_tx</span><span class="p">.</span><span class="n">test_and_clear</span><span class="p">():</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">fd</span><span class="p">.</span><span class="n">sendmsg</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="n">MSG_DONTWAIT</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">r</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">r</span> <span class="o">==</span> <span class="n">msg</span><span class="p">.</span><span class="nb">len</span><span class="p">:</span>
        <span class="n">fd</span><span class="p">.</span><span class="n">speculation</span><span class="p">.</span><span class="n">non_block_tx</span> <span class="o">=</span> <span class="bp">True</span>
      <span class="k">return</span> <span class="n">r</span>
    <span class="k">elif</span> <span class="n">r</span> <span class="o">!=</span> <span class="o">-</span><span class="n">EAGAIN</span><span class="p">:</span>
      <span class="k">raise</span> <span class="nb">Exception</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
  <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="p">.</span><span class="n">submit_request</span><span class="p">(</span><span class="n">prep_sendmsg</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span></code></pre>
                  </div>
                </div>
                <div class="paragraph">
                  <p>
                    在这里采用了同步非阻塞和异步阻塞调用相结合的设计。如果上次的写操作完成了，没有
                    short write，则大概率这次能够进行非阻塞的写，所以直接使用
                    POSIX 非阻塞的系统调用，如果运气不好的话，就把请求发给
                    io_uring 采用阻塞的调用。需要注意，如果我们用
                    <code>O_NONBLOCK</code> 打开这个文件的话，那么
                    <code>prep_sendmsg()</code> 的 sqe 可能会返回
                    <code>-EAGAIN</code> 或者 <code>-EWOULDBLOCK</code>，而
                    <code>io_completion::complete_with()</code>
                    看到这个错误会把它当成
                    <code
                      >std::system_error(EAGAIN, std::system_category())</code
                    >
                    扔出来。这个行为和其他的 reactor
                    后端会不兼容。所以要么我们让 <code>io_completion</code>
                    能为我们网开一面，让我们有重试的机会。或者干脆用阻塞的
                    IO，即在打开文件的时候不指定
                    <code>O_NONBLOCK</code
                    >。后者要容易一些。对于普通文件的写操作，因为 write 不提供
                    <code>MSG_DONTWAIT</code> 的
                    flag，我们无法使用刚才的策略。为了不阻塞 reactor
                    所以只能使用 <code>O_NONBLOCK</code> 打开文件，POSIX 的
                    write 返回 <code>-EAGAIN</code> 的时候，等待 writable
                    之后，再提交新的写操作：
                  </p>
                </div>
                <div class="listingblock">
                  <div class="content">
                    <pre
                      class="rouge highlight"
                    ><code data-lang="python"><span class="k">async</span> <span class="k">def</span> <span class="nf">write_some</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fd</span><span class="p">,</span> <span class="nb">buffer</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">fd</span><span class="p">.</span><span class="n">speculation</span><span class="p">.</span><span class="n">non_block_tx</span><span class="p">.</span><span class="n">test_and_clear</span><span class="p">():</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">fd</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="nb">buffer</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">r</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">r</span> <span class="o">==</span> <span class="n">msg</span><span class="p">.</span><span class="nb">len</span><span class="p">:</span>
        <span class="n">fd</span><span class="p">.</span><span class="n">speculation</span><span class="p">.</span><span class="n">non_block</span> <span class="o">=</span> <span class="bp">True</span>
      <span class="k">return</span> <span class="n">r</span>
    <span class="k">elif</span> <span class="n">r</span> <span class="o">!=</span> <span class="o">-</span><span class="n">EAGAIN</span><span class="p">:</span>
      <span class="k">raise</span> <span class="nb">Exception</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
  <span class="k">await</span> <span class="bp">self</span><span class="p">.</span><span class="n">submit_request</span><span class="p">(</span><span class="n">prep_poll</span><span class="p">(</span><span class="n">fd</span><span class="p">,</span> <span class="n">POLLOUT</span><span class="p">))</span>
  <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="p">.</span><span class="n">submit_request</span><span class="p">(</span><span class="n">prep_write</span><span class="p">(</span><span class="n">fd</span><span class="p">,</span> <span class="nb">buffer</span><span class="p">))</span></code></pre>
                  </div>
                </div>
                <div class="paragraph">
                  <p>
                    笔者想，io_uring
                    的一个优势是减少系统调用，提高总体的性能。但是这种基于预测的
                    IO
                    的执行方式在理想情况下并不能减少系统调用，虽然它能在及时消耗
                    buffer 的情况下减少延迟。正如 Avi 提到的
                  </p>
                </div>
                <div class="quoteblock">
                  <blockquote>
                    <div class="paragraph">
                      <p>
                        we can have latency of 0.5ms even though data is ready
                        because the reactor will prefer to run tasks and gather
                        more I/O.
                      </p>
                    </div>
                  </blockquote>
                </div>
                <div class="paragraph">
                  <p>
                    所以只要能 inline 地发送
                    IO，我们就会直接把请求直接发送出去，而不是等 reactor
                    的工作线程把“一天”工作都完成，在下班的时候“顺路”把当天收集到的
                    IO 成批地发送出去，那样的延迟会比较高。SQPOLL
                    的引入是不是会改变这个状况呢？因为在 SQPOLL 模式下，内核的
                    SQPOLL 线程会帮我们发送 sqe。这样的话，直接 inline
                    地发送请求就可以了，而不用把 IO 请求加入队列，统一处理。
                  </p>
                </div>
                <div class="paragraph">
                  <p>
                    文中的提议已经写成了
                    <a href="https://github.com/scylladb/seastar/pull/1235"
                      >PR#1235</a
                    >，一旦这个 PR merge，那么
                    <code>IORING_OP_SEND_ZC</code> 也就不远了。
                  </p>
                </div>
              </div>
            </div>
          </div>
        </section>

        <!-- Social media shares -->

        <!-- Tag list -->

        <div class="tag-list"></div>
      </article>

      <!-- Post navigation -->

      <div id="post-nav">
        <div id="previous-post">
          <a
            alt="Exception in Seastar"
            href="/seastar/2022/10/08/exception-in-seastar.html"
          >
            <p>Previous post</p>
            Exception in Seastar
          </a>
        </div>

        <div id="next-post">
          <a
            alt="从 perftune.py 说起"
            href="/seastar/2022/09/03/seastar-perftune.html"
          >
            <p>Next post</p>
            从 perftune.py 说起
          </a>
        </div>
      </div>

      <!--Utterances-->

      <!-- Cusdis -->
      <div
        class="comments"
        id="cusdis_thread"
        data-host="https://cusdis.com"
        data-app-id="12e099bc-c554-4827-aeb8-e425c83d8176"
        data-page-id="_posts/2022-10-03-iouring-seastar.adoc"
        data-page-url="/seastar/2022/10/03/iouring-seastar.html"
        data-page-title="io_uring + Seastar"
        data-theme="auto"
      ></div>

      <script async src="https://cusdis.com/js/cusdis.es.js"></script>

      <!-- Disqus -->

      <!-- To change color of links in the page -->
      <style>
        header#main {
          background-size: cover;
          background-repeat: no-repeat;
          background-position: center;
        }
      </style>
    </div>
    <footer class="site-footer">
      <p class="text">
        Powered by <a href="https://jekyllrb.com/">Jekyll</a> with
        <a href="https://github.com/sylhare/Type-on-Strap">Type on Strap</a>
      </p>
      <div class="footer-icons">
        <ul>
          <!-- Social icons from Font Awesome, if enabled -->
        </ul>
      </div>
    </footer>
  </body>
</html>
