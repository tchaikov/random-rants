<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://blog.k3fu.xyz/feed.xml" rel="self" type="application/atom+xml" /><link href="https://blog.k3fu.xyz/" rel="alternate" type="text/html" hreflang="en" /><updated>2022-05-05T02:27:20+00:00</updated><id>https://blog.k3fu.xyz/feed.xml</id><title type="html">some random rants</title><subtitle>我的学习记录</subtitle><author><name>Kefu Chai</name><email>tchaikov@gmail.com</email></author><entry><title type="html">a bottle of ceph</title><link href="https://blog.k3fu.xyz/2022/05/04/homebrew-bottle.html" rel="alternate" type="text/html" title="a bottle of ceph" /><published>2022-05-04T00:00:00+00:00</published><updated>2022-05-04T00:00:00+00:00</updated><id>https://blog.k3fu.xyz/2022/05/04/homebrew-bottle</id><content type="html" xml:base="https://blog.k3fu.xyz/2022/05/04/homebrew-bottle.html"><![CDATA[<div class="paragraph">
<p>记录一下怎么更新 homebrew bottle。</p>
</div>
<div class="paragraph">
<p>因为有些小坑，所以又是个 howto。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>把 homebrew formula 加入 homebrew。这里注明 formula 的地址，否则 brew 缺省使用 HTTPS，而 git 会问我们要 github 的 credentials。有点麻烦。</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shellsession">$ brew tap tchaikov/ceph-client git@github.com:tchaikov/homebrew-ceph-clientbrew.git</code></pre>
</div>
</div>
</li>
<li>
<p>更新 formula</p>
<div class="ulist">
<ul>
<li>
<p>直接编辑，假设你的编辑器是全副武装的 IDE。</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shellsession">$ brew edit ceph-client</code></pre>
</div>
</div>
</li>
<li>
<p>或者进入 tap 的 repo 慢慢来</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shellsession">$ cd $(brew --repository tchaikov/homebrew-ceph-clientbrew)</code></pre>
</div>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>编译。这一步要下载编译时用的依赖，所以会很慢。</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shellsession">$ brew install --build-bottle tchaikov/ceph-clientbrew/ceph-client</code></pre>
</div>
</div>
</li>
<li>
<p>把编译好的软件包装瓶。<code>brew bottle</code> 会在当前目录生成一个 bottle，文件名类似 <code>ceph-client&#8212;&#8203;17.2.0.arm64_monterey.bottle.2.tar.gz</code>。这个命令还会很贴心地打印出使用这个 bottle 需要用到的 formula 代码片段加入，所以需要编译一下 formula。</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shellsession">$ brew bottle tchaikov/ceph-clientbrew/ceph-client
$ brew edit tchaikov/ceph-clientbrew/ceph-client</code></pre>
</div>
</div>
</li>
<li>
<p>打 tag 并更新 github，以便接下来发布。</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shellsession">$ git remote -v
me	git@github.com:tchaikov/homebrew-ceph-client.git (fetch)
me	git@github.com:tchaikov/homebrew-ceph-client.git (push)
$ git tag quincy-17.2.0-1
$ git push me master
$ git push me quincy-17.2.0-1</code></pre>
</div>
</div>
</li>
<li>
<p>发布，并上传。</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>有意思的是，如果没有指定 <code>version</code>，那么 <code>brew bottle</code> 生成的文件名和 <code>brew install</code> 期望的名字是不一致的。所以这里要修改一下：</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shellsession">$ mv ceph-client{-,}-17.2.0.arm64_monterey.bottle.1.tar.gz</code></pre>
</div>
</div>
</li>
<li>
<p>因为 GitHub 提供发布的功能，它也允许我们在发布页面上传一些文件。所以，</p>
<div class="olist lowerroman">
<ol class="lowerroman" type="i">
<li>
<p>在 github 上点击 "tags"，</p>
</li>
<li>
<p>点击刚才创建的 tag</p>
</li>
<li>
<p>点击 "Create release from tag"</p>
</li>
<li>
<p>点击 "Attach binaries by dropping them here or selecting them"，上传刚才改名后的 tar.gz 文件</p>
</li>
<li>
<p>"Publish release"!</p>
</li>
</ol>
</div>
</li>
</ol>
</div>
</li>
<li>
<p>测试一下</p>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shellsession">$ brew remove ceph-client
$ brew install tchaikov/ceph-clientbrew/ceph-client</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
如果是新建 tap，那么应该直接参考 <a href="https://brew.sh/2020/11/18/homebrew-tap-with-bottles-uploaded-to-github-releases/" class="bare">https://brew.sh/2020/11/18/homebrew-tap-with-bottles-uploaded-to-github-releases/</a> 。
</td>
</tr>
</table>
</div>]]></content><author><name>Kefu Chai</name><email>tchaikov@gmail.com</email></author><category term="homebrew" /><category term="ceph" /><summary type="html"><![CDATA[记录一下怎么更新 homebrew bottle。]]></summary></entry><entry><title type="html">auto 和 BOOST_AUTO</title><link href="https://blog.k3fu.xyz/2022/04/16/boost-auto.html" rel="alternate" type="text/html" title="auto 和 BOOST_AUTO" /><published>2022-04-16T00:00:00+00:00</published><updated>2022-04-16T00:00:00+00:00</updated><id>https://blog.k3fu.xyz/2022/04/16/boost-auto</id><content type="html" xml:base="https://blog.k3fu.xyz/2022/04/16/boost-auto.html"><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p><code>auto</code> 也有不好用的时候。</p>
</div>
<div class="paragraph">
<p>自从开始用上 C&#43;&#43;11，就喜欢上了 <code>auto</code> 关键字。类型名字太长？用 <code>auto</code>！类型不知道？用 <code>auto</code>！嗯？只是有点犯懒？用 <code>auto</code>！作为 "placeholder
type specifier"， <code>auto</code> 似乎是高手的利器，懒人的福音。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="spirit-引起的-segfault">spirit 引起的 segfault</h2>
<div class="sectionbody">
<div class="paragraph">
<p>但是笔者前两天碰到一个 segfault，而且不是总能重现。最后发觉它是滥用 <code>auto</code> 的结果。比如说，下面的的代码片段用来匹配 <a href="https://en.wikipedia.org/wiki/Binary_prefix">IEC 的前缀</a></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c++"><span class="k">struct</span> <span class="nc">iec_prefix_t</span> <span class="p">{</span>
  <span class="n">std</span><span class="o">::</span><span class="n">string_view</span> <span class="n">prefix</span><span class="p">;</span>
  <span class="kt">unsigned</span> <span class="n">order</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">static</span> <span class="k">constexpr</span> <span class="n">iec_prefix_t</span> <span class="n">iec_prefixes</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span>
  <span class="p">{</span><span class="s">"k"</span><span class="p">,</span> <span class="mi">10</span><span class="p">},</span>
  <span class="p">{</span><span class="s">"m"</span><span class="p">,</span> <span class="mi">20</span><span class="p">},</span>
  <span class="p">{</span><span class="s">"g"</span><span class="p">,</span> <span class="mi">30</span><span class="p">},</span>
  <span class="p">{</span><span class="s">"t"</span><span class="p">,</span> <span class="mi">40</span><span class="p">},</span>
<span class="p">};</span>
<span class="c1">// ...</span>
<span class="n">qi</span><span class="o">::</span><span class="n">symbols</span><span class="o">&lt;</span><span class="kt">char</span><span class="p">,</span> <span class="kt">unsigned</span><span class="o">&gt;</span> <span class="n">prefix</span><span class="p">;</span>
<span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="p">[</span><span class="n">prefix</span><span class="p">,</span> <span class="n">order</span><span class="p">]</span> <span class="o">:</span> <span class="n">iec_prefixes</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">prefix</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="n">order</span><span class="p">);</span>
<span class="p">}</span>
<span class="k">auto</span> <span class="n">postfix</span> <span class="o">=</span> <span class="n">spirit</span><span class="o">::</span><span class="n">ascii</span><span class="o">::</span><span class="n">no_case</span><span class="p">[</span><span class="n">prefix</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="o">-</span><span class="p">(</span><span class="n">qi</span><span class="o">::</span><span class="n">string</span><span class="p">(</span><span class="s">"iB"</span><span class="p">)</span> <span class="o">|</span> <span class="n">qi</span><span class="o">::</span><span class="n">string</span><span class="p">(</span><span class="s">"B"</span><span class="p">));</span>
<span class="kt">uint64_t</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="kt">unsigned</span> <span class="n">order</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="k">if</span> <span class="p">(</span><span class="n">qi</span><span class="o">::</span><span class="n">parse</span><span class="p">(</span><span class="n">s</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">s</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span> <span class="n">qi</span><span class="o">::</span><span class="n">uint_</span> <span class="o">&gt;&gt;</span> <span class="o">-</span><span class="n">postfix</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">power</span><span class="p">))</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">n</span> <span class="o">&lt;&lt;</span> <span class="n">order</span><span class="p">;</span>
<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
  <span class="k">throw</span> <span class="n">std</span><span class="o">::</span><span class="n">invalid_argument</span><span class="p">(</span><span class="s">"hmmm"</span><span class="p">);</span>
<span class="p">}</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>一切看起来岁月静好。但是却发现有时候 <code>qi::parse()</code> 有时候会出现 segfault。表达式这么可爱，能出什么错呢？stackoverflow 上有个很对口的 <a href="https://stackoverflow.com/questions/20763665/boost-spirit-v2-qi-bug-associated-with-optimization-level/20766909#20766909">问题</a>，摘录回答如下：</p>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>It&#8217;s a bug in your code, nothing wrong with the compiler or the optimization levels.</p>
</div>
<div class="paragraph">
<p>The cinch is with expression templates (like the ones used by Boost Proto, and hence by Boost Spirit).
They are <strong>only valid to the end of their enclosing full expression</strong><sup>[1]</sup></p>
</div>
<div class="paragraph">
<p>The canonical workaound is:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c++"> <span class="n">BOOST_SPIRIT_AUTO</span><span class="p">(</span><span class="n">ana</span><span class="p">,</span> <span class="o">*~</span><span class="n">qi</span><span class="o">::</span><span class="n">char_</span><span class="p">(</span><span class="sc">'*'</span><span class="p">)</span> <span class="o">&gt;</span> <span class="o">+</span><span class="n">qi</span><span class="o">::</span><span class="n">char_</span><span class="p">(</span><span class="sc">'*'</span><span class="p">));</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Spirit X3 promises to remove this wart. Slightly related, I think Protox11 also removes this
issue by being aware of references at all times.</p>
</div>
<hr>
<div class="paragraph">
<p>[1] Grep the standard for lifetime extension of temporaries. The expression templates keep
references to the literals used (the rest has value semantics anyways), but the temporaries
aren&#8217;t bound to (const) references. So they go out of scope.
<a href="http://en.wikipedia.org/wiki/Undefined_behavior">Undefined Behaviour</a> results</p>
</div>
</blockquote>
</div>
<div class="paragraph">
<p>看来是 <code>postfix</code> 指向的对象含有一些引用，被引用的对象的生命周期没能坚持很久，它们到 <code>qi::parse()</code>
的时候已经香消玉损了。这里涉及两组熟悉又陌生的概念：</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="expression-template">expression template</h2>
<div class="sectionbody">
<div class="paragraph">
<p>先看看表达式模板（expression template）是什么。它是 C&#43;&#43; 魔法师们的创造，不属于 C&#43;&#43; 标准的范畴，见 <a href="https://en.wikipedia.org/wiki/Expression_templates">wikipedia 上的条目</a>。总结下来，表达式模板有这么几个特点：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>往往使用嵌套模板的方式组织成一个树。</p>
</li>
<li>
<p>表达式通过 <code>const</code> 引用保存子表达式。为了避免复制产生的开销，更不消说有的类型不支持复制，仅仅保存引用。</p>
</li>
<li>
<p>惰性求值。只有表达式参与真正的求值的时候，才会开始计算。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>因此，</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c++"><span class="k">auto</span> <span class="n">postfix</span> <span class="o">=</span> <span class="n">spirit</span><span class="o">::</span><span class="n">ascii</span><span class="o">::</span><span class="n">no_case</span><span class="p">[</span><span class="n">prefix</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="o">-</span><span class="p">(</span><span class="n">qi</span><span class="o">::</span><span class="n">string</span><span class="p">(</span><span class="s">"iB"</span><span class="p">)</span> <span class="o">|</span> <span class="n">qi</span><span class="o">::</span><span class="n">string</span><span class="p">(</span><span class="s">"B"</span><span class="p">));</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>并不是普通的值语义的标量对象，它是一个嵌套的表达式模板实例。如下所示：</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/diag-55cacf693e6cfc618d2741427a20859a.png" alt="Diagram" width="510" height="546">
</div>
</div>
<div class="paragraph">
<p>每个操作符分别都产生了新的表达式，而这些表达式都通过 <code>const</code> 引用持有保存其子表达式的引用，从里到外的每个表达式都是临时对象。即使我们通过 <code>postfix</code> 保存了最外面的表达式，即图中的绿色方块。但是里面的所有其他表达式都在 <code>auto postfix</code> 这个语句中等号右侧的表达式求值完毕之后就析构了。更不用说 <code>qi::string("iB")</code> 它们了。难怪，在 <code>qi::parse()</code> 使用 <code>postfix</code> 的时候会碰到 segfault。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="临时对象和引用">临时对象和引用</h2>
<div class="sectionbody">
<div class="paragraph">
<p>那我们看看 C&#43;&#43; 标准（草案）的原文怎么说</p>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>The lifetime of a reference begins when its initialization is complete. The lifetime of a
reference ends as if it were a scalar object requiring storage.</p>
</div>
</blockquote>
<div class="attribution">
&#8212; ISO/IEC JTC1 SC22 WG21 N 4860
</div>
</div>
<div class="paragraph">
<p>关键是后面一句。简单说，就是引用还在，因为它只是块儿内存，只要那块内存还没有重写，引用就活着。不过……
引用毕竟是引用，它和值是两码事。因此，会不会代码犯了和下面程序类似的错误？</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c++"><span class="cp">#include &lt;iostream&gt;
#include &lt;string&gt;
</span>
<span class="k">using</span> <span class="k">namespace</span> <span class="n">std</span><span class="p">;</span>

<span class="n">string</span><span class="o">&amp;</span> <span class="n">hello</span><span class="p">()</span> <span class="p">{</span>
  <span class="n">string</span> <span class="n">s</span><span class="p">(</span><span class="s">"hello"</span><span class="p">);</span>
  <span class="k">return</span> <span class="n">s</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="k">auto</span> <span class="n">s</span> <span class="o">=</span> <span class="n">hello</span><span class="p">();</span>
  <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">s</span> <span class="o">&lt;&lt;</span> <span class="n">endl</span><span class="p">;</span>
<span class="p">}</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>GCC 碰到这种明显的错误会看不下去，</p>
</div>
<div class="listingblock">
<div class="content">
<pre>test.cc: In function ‘std::string&amp; hello()’:
test.cc:9:10: warning: reference to local variable ‘s’ returned [-Wreturn-local-addr]
    9 |   return s;
      |          ^
test.cc:8:10: note: declared here
    8 |   string s("hello");
      |          ^</pre>
</div>
</div>
<div class="paragraph">
<p>当然，有的情况下，引用可以 <a href="https://en.cppreference.com/w/cpp/language/reference_initialization#Lifetime_of_a_temporary">帮助临时对象续命</a>。但是如果不属于上面的情况，要是被引用的对象析构了，那么就算引用还是有效的，我们一样会碰到我们的老朋友——
undefined behavior。这也是这个问题在不同环境下可能没法重现的原因。因为对象即使析构，它的内存在被重写之前，数据还是保存着它生前的样子。而内存重用是我们通常没法直接控制的。</p>
</div>
<div class="paragraph">
<p>所以问题的原委已经明白了。上图中绿色方块的 <code>lhs</code> 和 <code>rhs</code> 作为引用，在对 <code>postfix</code>
赋值之后仍然是有效的，但是它们指向的对象就销毁了。为了能够把整个表达式树完整地保存下来，我们必须进行一次 <code>deep copy</code>。Spirit 的维护者 <a href="http://boost-spirit.com/home/articles/qi-example/zero-to-60-mph-in-2-seconds/">实现的 <code>BOOST_SPIRIT_AUTO</code> 宏</a>
解决的的就是这个问题。也许根据 <a href="https://www.boost.org/doc/libs/1_79_0/libs/spirit/example/qi/typeof.cpp">最新的例子</a>，我们最好用 <code>boost::spirit::qi::copy()</code>。</p>
</div>
</div>
</div>]]></content><author><name>Kefu Chai</name><email>tchaikov@gmail.com</email></author></entry><entry><title type="html">redpanda 编译记录</title><link href="https://blog.k3fu.xyz/2022/04/11/redpanda-build.html" rel="alternate" type="text/html" title="redpanda 编译记录" /><published>2022-04-11T00:00:00+00:00</published><updated>2022-04-11T00:00:00+00:00</updated><id>https://blog.k3fu.xyz/2022/04/11/redpanda-build</id><content type="html" xml:base="https://blog.k3fu.xyz/2022/04/11/redpanda-build.html"><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>在恶劣的网络环境下编译 redpanda 也得折腾。</p>
</div>
<div class="paragraph">
<p>看到 redpanda 也开始用 C&#43;&#43;20 的协程，这引起了我的好奇心。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="bleeding-edge">bleeding edge</h2>
<div class="sectionbody">
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="nv">$ </span>git clone git@github.com:redpanda-data/redpanda.git</code></pre>
</div>
</div>
<div class="paragraph">
<p>redpanda 的 <a href="https://github.com/redpanda-data/redpanda#build-manually">github 页面</a>
上有介绍，但是既然都 "live on edge" 了，那么就必须用最新的 clang 啊。debian sid
打包了 clang-15，所以需要用下面的 patch：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="diff"><span class="gh">diff --git a/install-dependencies.sh b/install-dependencies.sh
index c6370e4d3..ad328d1f9 100755
</span><span class="gd">--- a/install-dependencies.sh
</span><span class="gi">+++ b/install-dependencies.sh
</span><span class="p">@@ -26,14 +26,14 @@</span> fi

 deb_deps=(
   ccache
<span class="gd">-  clang
</span><span class="gi">+  clang-15
</span>   curl
   git
   libsnappy-dev
   libxxhash-dev
   libzstd-dev
<span class="gd">-  llvm
-  lld
</span><span class="gi">+  llvm-15
+  lld-15
</span>   pkg-config
   procps
   python3-jinja2</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="github">GitHub</h2>
<div class="sectionbody">
<div class="paragraph">
<p>为了更快地下载 github 上的 repo，如果能找到可以用的 GitHub 镜像的话，就可以修改 <code>$HOME/.gitconfig</code>，让 <code>git</code> 重写 URL 里面的路径，用镜像替代 github。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="ini"><span class="nn">[url "https://a.mirror.or.proxy/"]</span>
  <span class="py">insteadOf</span> <span class="p">=</span> <span class="s">https://github.com/</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>如果没有镜像可用，那么用自己架设的 SOCKS5 和 HTTP 代理也能抵挡一下，各家工具支持的代理设置方式不同。archlinux 甚至有 <a href="https://wiki.archlinux.org/title/Proxy_server">专门的文档</a> 说明如何设置代理。这里只记录用到的：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="c"># for curl and python (urllib3)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">all_proxy</span><span class="o">=</span>socks5://127.0.0.1:1080
<span class="c"># for cipd which respects http_proxy and https_proxy</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">http_proxy</span><span class="o">=</span>http://127.0.0.1:1081
<span class="nv">$ </span><span class="nb">export </span><span class="nv">https_proxy</span><span class="o">=</span>http://127.0.0.1:1081</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="v8">V8</h2>
<div class="sectionbody">
<div class="paragraph">
<p>因为 redpanda 使用 Chrome/ 的 V8 引擎来 <a href="https://redpanda.com/blog/wasm-architecture/">执行 WASM</a>，这个依赖为墙内的开发者带来了更大的挑战。因为 www.chromium.org 也被官方认证了。而作为一个大型项目，
Chrome 使用 <a href="https://www.chromium.org/developers/how-tos/install-depot-tools/">depot-tools</a>
来辅助其代码 checkout 流程。笔者租有一个墙外的 VPS，用它来下载必须的依赖。下面的命令是在 VPS 上执行的：</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ DEPOT_TOOLS_DIR=/var/depot_tools
$ sudo DEPOT_TOOLS_DIR=${DEPOT_TOOLS_DIR} ./install-dependencies.sh</pre>
</div>
</div>
<div class="paragraph">
<p>执行完之后，<code>/var/depot_tools</code> 的大小大约为 734M。原样复制到本地。VPS
上的目录和本地应该可以不一样，设置好之后命令中的 <code>DEPOT_TOOLS_DIR</code> 环境变量就行。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="编译">编译</h2>
<div class="sectionbody">
<div class="paragraph">
<p>在编译的时候， 需要下载 v8 的代码，不知道为何 <code>gclient</code> 会 hang，长时间没有动静。只能直接调用 <code>gclient.py</code>。同时，把原来的 git 地址改成 gitee 上的镜像，在国内访问它的速度很快。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="diff"><span class="gh">diff --git a/cmake/oss.cmake.in b/cmake/oss.cmake.in
index 53856c61d..f8f6b7998 100644
</span><span class="gd">--- a/cmake/oss.cmake.in
</span><span class="gi">+++ b/cmake/oss.cmake.in
</span><span class="p">@@ -351,8 +351,8 @@</span> set(v8_flags
 ExternalProject_Add(v8
 INSTALL_DIR @REDPANDA_DEPS_INSTALL_DIR@
 DOWNLOAD_COMMAND
<span class="gd">-  COMMAND @DEPOT_TOOLS_DIR@/gclient configure https://github.com/v8/v8.git
-  COMMAND @DEPOT_TOOLS_DIR@/gclient sync -r e04bb9be8542b166c4dda1a77bfb1c46552afdd8
</span><span class="gi">+  COMMAND python3 @DEPOT_TOOLS_DIR@/gclient.py configure https://gitee.com/mirrors/V8.git
+  COMMAND python3 @DEPOT_TOOLS_DIR@/gclient.py sync -v -r e04bb9be8542b166c4dda1a77bfb1c46552afdd8
</span> PATCH_COMMAND ""
 CONFIGURE_COMMAND
   COMMAND cd &lt;SOURCE_DIR&gt; # Is used for run gn inside v8 dir</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>$ cd redpanda
$ CC=clang-15 CXX=clang++-15 DEPOT_TOOLS_DIR=/var/depot_tools \
    -DCMAKE_BUILD_TYPE=Debug</pre>
</div>
</div>
<div class="paragraph">
<p>因为 gitee 把 repo 的名字改成了大写。编译 v8 的时候会找不到代码。所以得纠正这个错误：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="shell"><span class="nv">$ </span><span class="nb">mv </span>redpanda/build/deps_build/v8-prefix/src/<span class="o">{</span>V8,v8<span class="o">}</span></code></pre>
</div>
</div>
</div>
</div>]]></content><author><name>Kefu Chai</name><email>tchaikov@gmail.com</email></author><category term="redpanda" /><category term="build" /><category term="debian" /><summary type="html"><![CDATA[在恶劣的网络环境下编译 redpanda 也得折腾。]]></summary></entry><entry><title type="html">Seastar 和 SPDK</title><link href="https://blog.k3fu.xyz/2021/08/28/spdk-seastar.html" rel="alternate" type="text/html" title="Seastar 和 SPDK" /><published>2021-08-28T00:00:00+00:00</published><updated>2021-08-28T00:00:00+00:00</updated><id>https://blog.k3fu.xyz/2021/08/28/spdk-seastar</id><content type="html" xml:base="https://blog.k3fu.xyz/2021/08/28/spdk-seastar.html"><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>当 C++ 遇上 SPDK。</p>
</div>
<div id="toc" class="toc">
<div id="toctitle" class="title"></div>
<ul class="sectlevel1">
<li><a href="#seasetar-中的-dpdk">Seasetar 中的 DPDK</a></li>
<li><a href="#spdk">SPDK</a>
<ul class="sectlevel2">
<li><a href="#初始化">初始化</a></li>
<li><a href="#reactor_run">reactor_run</a></li>
</ul>
</li>
<li><a href="#seastar-框架下-spdk-的线程">Seastar 框架下 SPDK 的线程</a></li>
<li><a href="#spdk-的-then">SPDK 的 <code>then()</code></a></li>
<li><a href="#spdk-在-seastar-中的形态">SPDK 在 Seastar 中的形态</a>
<ul class="sectlevel2">
<li><a href="#另外一个-reactor">另外一个 reactor？</a></li>
<li><a href="#典型的用例">典型的用例</a></li>
</ul>
</li>
</ul>
</div>
<div class="paragraph">
<p>这两天在学习 SPDK。对于存储软件的开发者来说，它是很好的基础设施。但是这种把回调函数和 context
作为参数，传给异步调用的模式让我有一朝返回解放前的感觉。联想到 Rust 和 Python 语言中的 async/await
语法，再加上两年 seastar 的开发者加入的
<a href="https://github.com/scylladb/seastar/commit/de56cd1dfe8eab6a2718d62b950c912574c4b27d">coroutine 支持</a>，作为 C&#43;&#43; 程序员不得不重新审视一下，我们是不是也能用新的语法，把异步的 SPDK C&#43;&#43; 程序写得更赏心悦目，易于维护呢？Seastar 作为 C&#43;&#43; 异步编程框架中不可忽视的一员，同时提供了 future/promise 和
C++20 的异步编程模型，如果加上 SPDK 肯定会如虎添翼，成为一个更好的平台。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="seasetar-中的-dpdk">Seasetar 中的 DPDK</h2>
<div class="sectionbody">
<div class="paragraph">
<p>先看看 Seastar 是怎么集成 DPDK 的吧。</p>
</div>
<div class="paragraph">
<p>在 <code>smp::get_options_description()</code> 里面，为 DPDK 的 <code>--huge-dir</code> 注册了 "hugepages" 的命令行选项。</p>
</div>
<div class="paragraph">
<p>在 <code>smp::configure()</code> 里面，CPU 核的设置 <code>allocation</code> 经过几次转换，还是作为命令行，传给了 <code>rte_eal_init()</code>:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><code>dpdk::eal::init()</code></p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p><code>rte_eal_init()</code></p>
</li>
<li>
<p>在每个 RTE 核上运行之前交给 <code>create_thread()</code> 的 lambda。这个 lambda 暂且叫做
<code>reactor_run</code> 吧。</p>
</li>
</ol>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>其中，<code>reactor_run</code> 负责初始化 reactor 线程，和执行调度到的任务：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>设置线程名字</p>
</li>
<li>
<p>分配自己的 hugepage</p>
</li>
<li>
<p>分配 io queue</p>
</li>
<li>
<p>设置 smp message queue</p>
</li>
<li>
<p><code>reactor::do_run()</code></p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>注册所有的 poller。请注意，poller 在各自的构造函数里面，新建一个 task。它们用 task
来把自己加到 <code>reactor._pollers</code> 里面去。poller 可以用来定期等待消息，并处理消息。比如：</p>
<div class="ulist">
<ul>
<li>
<p><code>smp_poller</code> 用来接收其他 reactor 发来的消息</p>
</li>
<li>
<p>aio 或者 epoll 等到的消息</p>
</li>
<li>
<p><code>reactor::signals</code> 检查 POSIX signal，并调用 signal handler</p>
</li>
<li>
<p>低精度的 timer</p>
</li>
</ul>
</div>
</li>
<li>
<p>成批执行 task。Seastar 允许开发者把一组任务 <a href="http://docs.seastar.io/master/group__execution-stages.html">一起执行</a>。</p>
</li>
<li>
<p>轮询所有的 poller</p>
</li>
<li>
<p>根据是否有遗存的工作决定是否进入休眠模式</p>
</li>
</ol>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect1">
<h2 id="spdk">SPDK</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="初始化">初始化</h3>
<div class="paragraph">
<p>这里通过分析 SPDK 的初始化过程，关注它的设置，以及调度方式，希望更好地设计 Seastar
和 SPDK 沟通的方式，比如如何初始化，如何和 SPDK 传递消息。SPDK 关心的设置是 DPDK <code>rte_eal_init()</code>
的超集，除了 DPDK 的相关设置，它还有很多 SPDK 特有的设置 <code>spdk_env_opts</code> ，比如</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>no_pci</code></p>
</li>
<li>
<p><code>num_pci_addr</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>每个 SPDK app 都需要执行 <code>spdk_app_start()</code>：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><code>app_setup_env(spdk_app_opts)</code></p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p><code>spdk_env_init(spdk_env_opts)</code></p>
<div class="olist lowerroman">
<ol class="lowerroman" type="i">
<li>
<p><code>rte_eal_init(argc, argv)</code>: 参数是根据 <code>spdk_env_opts</code> 构造的。</p>
</li>
<li>
<p>PCI 相关的初始化</p>
</li>
</ol>
</div>
</li>
</ol>
</div>
</li>
<li>
<p><code>spdk_reactors_init()</code></p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p><code>spdk_mempool_create()</code>: 分配内存池</p>
</li>
<li>
<p>为每个核初始化 reactor，设置下面的设施</p>
<div class="ulist">
<ul>
<li>
<p>event ring buffer</p>
</li>
<li>
<p>event fd</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</li>
<li>
<p>新建一个 <code>app_thread</code>，并把 <code>bootstrap_fn</code> 调度到该 thread 上执行</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p><code>bootstrap_fn()</code></p>
<div class="olist lowerroman">
<ol class="lowerroman" type="i">
<li>
<p>解析给出的 json 文件，里面包含一系列子系统的配置</p>
</li>
<li>
<p>初始化 RPC 服务</p>
</li>
<li>
<p>连接 RPC 服务，挨个加载子系统</p>
</li>
</ol>
</div>
</li>
</ol>
</div>
</li>
<li>
<p><code>spdk_reactors_start()</code>: 在每个 reactor 上执行 <code>reactor_run</code></p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="reactor_run">reactor_run</h3>
<div class="paragraph">
<p>在 <code>reactor_run</code> 中：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>批量地处理 <code>reactor&#8594;events</code></p>
</li>
<li>
<p>调用所有 spdk_thread 的 poller</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>批量处理 <code>thread&#8594;messages</code></p>
</li>
<li>
<p>依次调用 <code>thread&#8594;active_pollers</code></p>
</li>
<li>
<p>依次调用 <code>thread&#8594;timed_pollers</code></p>
</li>
</ol>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>请注意，spdk 会利用 poller 实现定时器和定期执行执行操作的功能。后者把 reactor 作为
worker thread，执行非阻塞的常规任务。比如 <code>vdev_worker</code> 和 <code>vdev_mgmt_worker</code>。这个用法和 Seastar 的 <code>reactor::io_queue_submission_pollfn</code> 相似。但是 Seastar
目前没有把注册 poller 的功能作为公开的 API 提供出来。如果把这个 poll 的任务定义成
task，在退出之前再次调度它自己，那么这种实现可能会降低 Seastar 任务调度的性能。因为在这个 poller 注销之前，它重复地新建和销毁任务，并把任务加入和移出 reactor 的任务列表。这会浪费很多 CPU cycle。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="seastar-框架下-spdk-的线程">Seastar 框架下 SPDK 的线程</h2>
<div class="sectionbody">
<div class="paragraph">
<p>这里结合 Seastar 框架，通过对比两者的线程模型。进一步探索一些可能的实现方式，我们可能会需要回答下面的问题，然后分别解决。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>如何管理多个用户层面的任务</p>
</li>
<li>
<p>如何发起一个异步调用</p>
</li>
<li>
<p>如何知道一个异步调用完成了</p>
</li>
<li>
<p>如何传递消息</p>
<div class="ulist">
<ul>
<li>
<p>不同 core 是直接如何通信的。</p>
</li>
<li>
<p>不同任务之间是直接如何通信的。</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>每个 core 都有自己的 MPSC (multiple producer single consumer) 消息队列，用于接收发给自己的消息。和 Seastar smp 调用对应的逻辑对应着看，可以发现</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>spdk_event_call()</code> 等价于 <code>seastar::smp::submit_to()</code></p>
</li>
<li>
<p><code>event_queue_run_batch()</code> 等价于 <code>smp::poll_queues()</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>前面解释 <code>reactor_run</code> 的逻辑的时候提到一个概念叫做 <code>spdk_thread</code>。它是 SPDK 中的用户线程。不同的 <code>spdk_thread</code> 之间通过接受方线程的消息队列来互相通信。用户线程消息队列的类型和 core 的消息队列类型和大小相同。<code>spdk_thread_send_msg()</code> 是用来往特定线程发送消息的。值得注意的是，SPDK 内部很多地方都使用了 <code>spdk_thread</code>，比如
bdev 模块就把 <code>spdk_bdev_io</code> 和一个 <code>spdk_thread</code> 相对应，实现 IO 的序列化。所以我们如果要让 Seastar 能更好的支持 SPDK 的话，就必须实现这个机制。</p>
</div>
<div class="paragraph">
<p>对于 SPDK 来说，<code>spdk_thread</code> 是一个工作协程，用来承载不同的业务。很多时候被用来并序列化并执行各种操作，它属于一个特定的 core。不过它可以根据调度算法动态地迁移到另一个
core。作为运行在所有 core 上的调度器，这个服务可以在 <code>seastar::sharded&lt;&gt;</code>
的框架下实现。不过这个调度器和 Seastar 的原生调度算法还有一些区别:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>seastar::sharded&lt;&gt;</code> 既可以在单个 core 上启动，也可以同时在所有 core 上一起
启动。</p>
</li>
<li>
<p><code>spdk_thread</code> 可以根据调度算法动态迁移。<code>spdk_thread</code> 一般来说属于 <strong>一个</strong>
core 的，但是根据它的 <code>cpumask</code>，一个 <code>spdk_thread</code> <strong>可以</strong> 根据 CPU 的负载
迁移到 <code>cpumask</code> 包含的的任意一个 core。这一点 Seastar 尚无支持。</p>
</li>
<li>
<p>因为 <code>spdk_thread</code> 自己有消息队列、poller 等基础设施，我们可以把它视为一个逻辑的
reactor。这个特性在 Seastar 目前还没有与之对应的实现。</p>
</li>
<li>
<p>每个 core 都维护着一组 <code>spdk_thread</code>。SPDK 甚至用 thread local storage 跟踪
其中一个。这个很像进程中的一组线程。<code>spdk_get_thread()</code> 返回的就是被跟踪的
那个 <code>spdk_thread</code>。目前 Seastar 的 reactor 并没有对应的概念，但是我们可以用
一个 <code>seastar::sharded&lt;&gt;</code> 服务来保存对应 core 上的所有 <code>spdk_thread</code>。</p>
</li>
<li>
<p>允许动态地注册和注销 poller。SPDK 中有两种 poller。一种是系统级的，负责
保证 SPDK 事件系统和 reactor 的基本运作。另一种是用户级的，它允许实现具体功能
的模块自己定期轮询业务相关的事件。这些用户级的 poller 就是注册在前面提到的
<code>spdk_get_thread()</code> 返回的线程中的。参见 <code>spdk_poller_register()</code> 和
<code>spdk_poller_unregister()</code> 的实现。如果继续沿着刚才的思路往前，我们可以把
一组 <code>spdk_thread</code> 保存在，比如说，<code>seastar::sharded&lt;spdk::ThreadGroup&gt;</code> 里面，
让 <code>spdk::ThreadGroup</code> 来为它管理的 <code>spdk_thread</code> 服务。它会用
<code>reactor::poller::simple()</code> 来注册自己的 <code>do_complete()</code> 函数，后者遍历
所有的 <code>spdk_thread</code> 的 poller。也允许应用程序在任意时刻为指定的 <code>spdk_thread</code>
添加 poller。这个做法和 virtio 中 <code>vring&lt;&gt;</code> 的实现相同。</p>
</li>
<li>
<p>同时支持中断模式和轮询模式。这是 SPDK 最近加入的一个新特性，甚至允许应用的 poller
工作在可定制的中断模式。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>节能、提高 CPU 的使用率和负载均衡，这些作为一个总体的设计目标，SPDK 做得相对比较深入。它根据线程的统计数据，比如说闲忙的时间比 (<code>spdk_thread_stats</code>)，来决定如何调度，Seastar 仅在 reactor 的实现里面通过调用 <code>pure_check_for_work()</code>
来判断 CPU 当下是否有工作要做，如果没有的话，就进入浅层的睡眠模式。笔者认为，这也许不仅仅是工程量多少的问题。也可能是因为 Seastar 对自身的定位，它提供了基础的异步编程模型，异步调用，以及基本的 IO 调度，但是它并不希望干涉用户业务在不同
shard 上的分布，而是把这个问题留给应用的开发者。</p>
</div>
<div class="paragraph">
<p>要在 Seastar 的框架下实现 <code>spdk_thread</code> 的这些高级特性是完全有可能的：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>根据负载动态调度工作协程：不仅仅 <code>spdk_thread</code> 需要统计自己的关于调度的统计
信息，每个 <code>spdk::ThreadGroup</code> 也需要统计各自的 <code>idle_tsc</code> 和 <code>busy_tsc</code>。
并提供接口供调度器查询，作为负载均衡的依据，然后在 shard 间调度任务。</p>
</li>
<li>
<p>和 SPDK 的 reactor 类似，<code>spdk::ThreadGroup</code> 也要保存一个 "leader" thread，
后者负责常规的 poller 注册和注销工作。</p>
</li>
<li>
<p><code>spdk::ThreadGroup</code> 启动的时候需要向 reactor 注册自己的总 poller，负责调用非
定时的 poller。</p>
</li>
<li>
<p>在新注册 poller 的时候，需要按照 poller 是否有周期区别处理。</p>
<div class="ulist">
<ul>
<li>
<p>如果 poller 指定了周期，那么需要新建 <code>seastar::timer</code>，并在 <code>spdk::ThreadGroup</code>
中维护一个 map，方便在运行的时候根据 <code>spdk_poller*</code> 找到 <code>seastar::timer</code> 暂停
或者注销。</p>
</li>
<li>
<p>如果是没有周期的 poller，那么直接加入当前 <code>spdk::ThreadGroup</code> 的 leader thread。
让后者的 poller 来调用新注册的 poller。这种分层的设计也方便管理对象的生命周期和统计
运行时指标。</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>在 SPDK 里面，要发起一个异步调用最典型的方式，类似下面的代码:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="n">rc</span> <span class="o">=</span> <span class="n">spdk_bdev_write</span><span class="p">(</span><span class="n">hello_context</span><span class="o">-&gt;</span><span class="n">bdev_desc</span><span class="p">,</span>
                     <span class="n">hello_context</span><span class="o">-&gt;</span><span class="n">bdev_io_channel</span><span class="p">,</span>
                     <span class="n">hello_context</span><span class="o">-&gt;</span><span class="n">buff</span><span class="p">,</span>
                     <span class="mi">0</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span>
                     <span class="n">write_complete</span><span class="p">,</span> <span class="n">hello_context</span><span class="p">);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>这段代码摘自 <code>examples/bdev/hello_world/hello_bdev.c</code>。这里以 bdev 的 NVMe 后端为例：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>从 <code>hello_context&#8594;bdev_io_channel</code> 的 cache 或者 bdev 的内存池分配一个
<code>spdk_bdev_io</code></p>
</li>
<li>
<p>用给定的参数设置这个 <code>spdk_bdev_io</code>，这样这个 I/O 就知道需要写的数据位置，长度，甚至
回调函数的函数指针和参数也保存在这个 I/O 里面了。</p>
</li>
<li>
<p>往 <code>nvme_qpair</code> 的提交列表的末尾添加新的 I/O。</p>
</li>
<li>
<p>通过修改提交队列末尾的 door bell，告诉 <code>nvme_qpair</code>，提交列表里多了一个新的 I/O。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>那么我们怎么知道 NVMe 设备完成了这个写操作呢？下面的函数处理指定的 queue pair
上所有完成了的 I/O 请求。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="kt">int32_t</span> <span class="nf">spdk_nvme_qpair_process_completions</span><span class="p">(</span><span class="k">struct</span> <span class="n">spdk_nvme_qpair</span> <span class="o">*</span><span class="n">qpair</span><span class="p">,</span>
                                            <span class="kt">uint32_t</span> <span class="n">max_completions</span><span class="p">);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>这个做法很像 <a href="https://man7.org/linux/man-pages/man2/io_getevents.2.html">io_getevents()</a>，都是从完成列表收割完成了的 I/O 请求。这个过程很像播种和收割。提交请求就是播种，检查完成了的请求就像是收割。让作物成熟的魔法师就是轮询模式的驱动 (polling mode driver)。</p>
</div>
<div class="paragraph">
<p>既然 SPDK 用 <code>spdk_thread</code> 实现用户协程，那么协程之间要协作的话，该怎么做呢？就是前面提到的"发送消息"。消息保存在大小为 65535 的一个 ring buffer 里面。顺便提一下，其实 Seastar 也有类似的数据结构，称为 <code>seastar::circular_buffer_fixed_capacity</code>。如果有必要的话，我们甚至可以把 SPDK 的 event 和 thread 子系统完全换成 Seastar 的实现。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="spdk-的-then">SPDK 的 <code>then()</code></h2>
<div class="sectionbody">
<div class="paragraph">
<p>回调函数是 C 语言实现异步编程一个很简单直接的方式，但是它似乎和 Seastar 的 <code>future&lt;&gt;</code>
格格不入。SPDK 和 DPDK 一脉相承，有着深层的血缘关系，我们是不是可以照着
<code>seastar::net::qp&lt;&gt;</code> 实现 SPDK 支持呢？看上去这种基于成对的
submission 和 completion queue 的抽象也适用于很多 SPDK 的场景。先比较一下基于流的操作和基于块的操作有什么异同：</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bdev</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>net::qp</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">发送</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">读写指令</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">发给对方的包</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">接收</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">设备状态</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">对方发来的包</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">等待</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">特定写指令的完成</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">发送的进度</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">等待</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">特定读指令返回的数据</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">下一个接收的报文</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>因为 bdev 需要跟踪特定请求的状态而不是一个 <strong>进度</strong>，所以我们无法使用 <code>seastar::stream</code>
定义 bdev 的读写接口。更好的榜样应该是 <code>seastar::file</code>。每个 <code>posix_file_impl</code>
都有一个 <code>_io_queue</code> 的引用，同一 <code>devid</code> 的所有 <code>_io_queue</code> 指向 reactor
统一维护的同一个 queue。这些 queue 用 <code>devid</code> 来索引。SPDK 作为专业的底层设施自然也有对应的设计。需要理解的是 <code>io_sink</code>、<code>io_request</code> 和 <code>io_completion</code> 这些组件是如何互相协作的。</p>
</div>
<div class="paragraph">
<p>还有个问题，SPDK 是一个有丰富接口的工具集，它有多个模块。每个模块都有自己的一组回调函数。光 <code>bdev</code> 就有 11 种回调函数：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="k">typedef</span> <span class="nf">void</span> <span class="p">(</span><span class="o">*</span><span class="n">spdk_bdev_remove_cb_t</span><span class="p">)(</span><span class="kt">void</span> <span class="o">*</span><span class="n">remove_ctx</span><span class="p">);</span>
<span class="k">typedef</span> <span class="nf">void</span> <span class="p">(</span><span class="o">*</span><span class="n">spdk_bdev_event_cb_t</span><span class="p">)(</span><span class="k">enum</span> <span class="n">spdk_bdev_event_type</span> <span class="n">type</span><span class="p">,</span>
                                     <span class="k">struct</span> <span class="n">spdk_bdev</span> <span class="o">*</span><span class="n">bdev</span><span class="p">,</span>
                                     <span class="kt">void</span> <span class="o">*</span><span class="n">event_ctx</span><span class="p">);</span>
<span class="k">typedef</span> <span class="nf">void</span> <span class="p">(</span><span class="o">*</span><span class="n">spdk_bdev_io_completion_cb</span><span class="p">)(</span><span class="k">struct</span> <span class="n">spdk_bdev_io</span> <span class="o">*</span><span class="n">bdev_io</span><span class="p">,</span>
                                           <span class="n">bool</span> <span class="n">success</span><span class="p">,</span>
                                           <span class="kt">void</span> <span class="o">*</span><span class="n">cb_arg</span><span class="p">);</span>
<span class="k">typedef</span> <span class="nf">void</span> <span class="p">(</span><span class="o">*</span><span class="n">spdk_bdev_wait_for_examine_cb</span><span class="p">)(</span><span class="kt">void</span> <span class="o">*</span><span class="n">arg</span><span class="p">);</span>
<span class="k">typedef</span> <span class="nf">void</span> <span class="p">(</span><span class="o">*</span><span class="n">spdk_bdev_init_cb</span><span class="p">)(</span><span class="kt">void</span> <span class="o">*</span><span class="n">cb_arg</span><span class="p">,</span> <span class="kt">int</span> <span class="n">rc</span><span class="p">);</span>
<span class="k">typedef</span> <span class="nf">void</span> <span class="p">(</span><span class="o">*</span><span class="n">spdk_bdev_fini_cb</span><span class="p">)(</span><span class="kt">void</span> <span class="o">*</span><span class="n">cb_arg</span><span class="p">);</span>
<span class="k">typedef</span> <span class="nf">void</span> <span class="p">(</span><span class="o">*</span><span class="n">spdk_bdev_get_device_stat_cb</span><span class="p">)(</span><span class="k">struct</span> <span class="n">spdk_bdev</span> <span class="o">*</span><span class="n">bdev</span><span class="p">,</span>
                                             <span class="k">struct</span> <span class="n">spdk_bdev_io_stat</span> <span class="o">*</span><span class="n">stat</span><span class="p">,</span>
                                             <span class="kt">void</span> <span class="o">*</span><span class="n">cb_arg</span><span class="p">,</span> <span class="kt">int</span> <span class="n">rc</span><span class="p">);</span>
<span class="k">typedef</span> <span class="nf">void</span> <span class="p">(</span><span class="o">*</span><span class="n">spdk_bdev_io_timeout_cb</span><span class="p">)(</span><span class="kt">void</span> <span class="o">*</span><span class="n">cb_arg</span><span class="p">,</span> <span class="k">struct</span> <span class="n">spdk_bdev_io</span> <span class="o">*</span><span class="n">bdev_io</span><span class="p">);</span>
<span class="k">typedef</span> <span class="nf">void</span> <span class="p">(</span><span class="o">*</span><span class="n">spdk_bdev_io_wait_cb</span><span class="p">)(</span><span class="kt">void</span> <span class="o">*</span><span class="n">cb_arg</span><span class="p">);</span>
<span class="k">typedef</span> <span class="nf">void</span> <span class="p">(</span><span class="o">*</span><span class="n">spdk_bdev_histogram_status_cb</span><span class="p">)(</span><span class="kt">void</span> <span class="o">*</span><span class="n">cb_arg</span><span class="p">,</span> <span class="kt">int</span> <span class="n">status</span><span class="p">);</span>
<span class="k">typedef</span> <span class="nf">void</span> <span class="p">(</span><span class="o">*</span><span class="n">spdk_bdev_histogram_data_cb</span><span class="p">)(</span><span class="kt">void</span> <span class="o">*</span><span class="n">cb_arg</span><span class="p">,</span> <span class="kt">int</span> <span class="n">status</span><span class="p">,</span>
                                            <span class="k">struct</span> <span class="n">spdk_histogram_data</span> <span class="o">*</span><span class="n">histogram</span><span class="p">);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>不过其中常用的可能只有:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c"><span class="k">typedef</span> <span class="nf">void</span> <span class="p">(</span><span class="o">*</span><span class="n">spdk_bdev_io_completion_cb</span><span class="p">)(</span><span class="k">struct</span> <span class="n">spdk_bdev_io</span> <span class="o">*</span><span class="n">bdev_io</span><span class="p">,</span>
                                           <span class="n">bool</span> <span class="n">success</span><span class="p">,</span>
                                           <span class="kt">void</span> <span class="o">*</span><span class="n">cb_arg</span><span class="p">);</span>
<span class="k">typedef</span> <span class="nf">void</span> <span class="p">(</span><span class="o">*</span><span class="n">spdk_bdev_get_device_stat_cb</span><span class="p">)(</span><span class="k">struct</span> <span class="n">spdk_bdev</span> <span class="o">*</span><span class="n">bdev</span><span class="p">,</span>
                                             <span class="k">struct</span> <span class="n">spdk_bdev_io_stat</span> <span class="o">*</span><span class="n">stat</span><span class="p">,</span>
                                             <span class="kt">void</span> <span class="o">*</span><span class="n">cb_arg</span><span class="p">,</span> <span class="kt">int</span> <span class="n">rc</span><span class="p">);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>前者用来处理一个完成了的 I/O，后者用来获取块设备的统计信息。回到刚才提到的 <code>spdk_bdev_write()</code>。对应的 Seastar 风格的一个 <code>bdev</code> 定义可能像这样:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c++"><span class="k">class</span> <span class="nc">bdev</span> <span class="p">{</span>
  <span class="k">explicit</span> <span class="n">bdev</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">name</span><span class="p">);</span>
  <span class="o">~</span><span class="n">bdev</span><span class="p">();</span>
  <span class="n">future</span><span class="o">&lt;&gt;</span> <span class="n">write</span><span class="p">(</span><span class="kt">uint64_t</span> <span class="n">pos</span><span class="p">,</span> <span class="k">const</span> <span class="kt">void</span><span class="o">*</span> <span class="n">buffer</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">len</span><span class="p">);</span>
  <span class="n">future</span><span class="o">&lt;&gt;</span> <span class="n">read</span><span class="p">(</span><span class="kt">uint64_t</span> <span class="n">pos</span><span class="p">,</span> <span class="kt">void</span><span class="o">*</span> <span class="n">buffer</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">len</span><span class="p">);</span>
  <span class="n">future</span><span class="o">&lt;</span><span class="n">io_state</span><span class="o">&gt;</span> <span class="n">stat</span><span class="p">();</span>
<span class="p">};</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>这个接口和 <code>seastar::file</code> 对应，忽略了 io channel 这些 SPDK 独有的机制。问题是</p>
</div>
<div class="ulist">
<ul>
<li>
<p>是否需要使用 SPDK 的回调函数实现异步调用呢？</p>
</li>
<li>
<p>是的话，如何实现？</p>
</li>
<li>
<p>不是的话，又怎么处理？</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>对于第一个问题，笔者认为，如果没有必要，还是应当尽量使用 SPDK 的方法，而不是自己开发一套机制替代它，这样的好处显而易见：因为 SPDK 的公开方法相对稳定，这样能减少跟踪上游带来的维护成本，把对 SPDK 的改动减少到最小，同时也增加了这个改动进入 SPDK 和 Seastar 上游的机会。但是新的问题出现了：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>这个回调函数是什么？</p>
<div class="ulist">
<ul>
<li>
<p>我们可以把回调函数定义成为一个 <code>bdev</code> 的静态成员函数，便于访问它的私有成员。</p>
</li>
<li>
<p>回调函数应该能调用 <code>_pr.set_value(res)</code>。其中，<code>_pr</code> 是和返回的 <code>future&lt;&gt;</code> 对应的 <code>promise&lt;&gt;</code>。</p>
</li>
</ul>
</div>
</li>
<li>
<p>回调函数的参数呢？这个参数至少要让我们能定位到 <code>_pr</code>。在 AIO 后端的实现里面，
当它在 poller 里面收集到完成了的事件之后，依次调用事件对应的 <code>completion&#8594;complete_with()</code>
函数。下面是从 Seastar 摘录的相关代码：</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c++"><span class="n">r</span> <span class="o">=</span> <span class="n">io_pgetevents</span><span class="p">(</span><span class="n">_polling_io</span><span class="p">.</span><span class="n">io_context</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">tsp</span><span class="p">,</span> <span class="n">active_sigmask</span><span class="p">);</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">!=</span> <span class="kt">unsigned</span><span class="p">(</span><span class="n">r</span><span class="p">);</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">auto</span><span class="o">&amp;</span> <span class="n">event</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
  <span class="k">auto</span><span class="o">*</span> <span class="n">desc</span> <span class="o">=</span> <span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="n">kernel_completion</span><span class="o">*&gt;</span><span class="p">(</span><span class="kt">uintptr_t</span><span class="p">(</span><span class="n">event</span><span class="p">.</span><span class="n">data</span><span class="p">));</span>
  <span class="n">desc</span><span class="o">-&gt;</span><span class="n">complete_with</span><span class="p">(</span><span class="n">event</span><span class="p">.</span><span class="n">res</span><span class="p">);</span>
<span class="p">}</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>而 <code>io_completion</code> 则会调用 <code>io_completion::complete(res)</code>。后者由 <code>io_completion</code> 的子类各自实现。以 <code>io_desc_read_write</code> 为例，它从 <code>io_completion</code> 继承，并负责与 fair_queue 沟通，也保存了 <code>_pr</code>。在 <code>io_desc_read_write::complete()</code> 里，</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c++"><span class="n">_pr</span><span class="p">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">res</span><span class="p">);</span>
<span class="k">delete</span> <span class="k">this</span><span class="p">;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>如果不使用回调函数的话，我们其实也需要模仿现有 Seastar 中对 aio 的支持，自己实现一个基于队列的轮询机制。我们以写文件为例，看看 Seastar 的 AIO 后端的实现吧。在
<code>posix_file_impl::do_write_dma()</code> 中，它调用 <code>engine().submit_to_write()</code>：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><code>io_queue::queue_request()</code></p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>构造一个 <code>unique_ptr&lt;queued_io_request&gt;</code> 对象</p>
</li>
<li>
<p>把 <code>queued_io_request::_fq_entry</code> 加入 <code>io_queue::fair_queue</code> 队列。通过这个 <code>_fq_entry</code> 是可以找到包含它的 <code>queued_io_request</code> 对象，并顺藤摸瓜，找到 <code>kernel_completion</code></p>
</li>
<li>
<p>返回 <code>queued_req&#8594;get_future()</code></p>
</li>
</ol>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>然后开始了接力比赛，接力棒就是 I/O 请求：</p>
</div>
<div class="olist arabic">
<ol class="arabic" start="1">
<li>
<p>第一棒：把 I/O 请求从 io queue 取出，经由按照它们所属类型的权重分配的公平队列，
加入 <code>io_sink::pending_io</code>。</p>
</li>
</ol>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/diag-460d1ba5c270c5ae9ff19e8d1243380c.png" alt="Diagram" width="740" height="322">
</div>
</div>
<div class="olist arabic">
<ol class="arabic" start="2">
<li>
<p>第二棒：从 <code>io_sink::pending_io</code> 取出 I/O 请求，把这些请求加入 AIO
的 <code>io_context</code> 队列，换句话说，就是把请求加入 submission queue。</p>
</li>
</ol>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/diag-67c69f3e87d29c2e406ce2e101590a16.png" alt="Diagram" width="590" height="350">
</div>
</div>
<div class="olist arabic">
<ol class="arabic" start="3">
<li>
<p>第三棒: 使用 <code>io_pgetevents()</code> 系统调用，读取 completion
queue 里面的异步 I/O 事件。</p>
</li>
</ol>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/diag-2665e81ec1e665e8d6e3bb14417ebc11.png" alt="Diagram" width="590" height="266">
</div>
</div>
<div class="paragraph">
<p>事实上，Seastar 的 I/O 子系统用了 5 个 poller</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/diag-8b9e6634f14d093843230d10ffd3822b.png" alt="Diagram" width="390" height="378">
</div>
</div>
<div class="paragraph">
<p>请注意，这五个 poller 的执行顺序影响着请求的延迟。因为后面一个
poller 的输入可能就是前一个 poller 的输出。这样同时也有助于减小内存子系统的压力，因为请求在 queue 里面积压的数量和时间越长，就意味着有越多的内存不可用。而这些内存有相当部分是按照下面存储介质的块对齐的，可能会有更多的内部碎片。所以尽早地释放它们，也更有利于提高系统的性能。这里有两个 <code>reap_kernel_completions_pollfn</code>
是希望一个 poller 能及早地释放 I/O queue 里面的 I/O 占用的内存空间；而让另一个 poller 能处理那些立即返回的 I/O 请求。</p>
</div>
<div class="paragraph">
<p>如果 Seastar 使用 SPDK 作为其存储栈，可能也需要对应的 poller：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><code>smp_pollfn</code>: 处理其他 reactor 发来的 I/O。它们可能也会访问当前
core 负责的 bdev。</p>
</li>
<li>
<p><code>reap_spdk_completions_pollfn</code>: 尽早地处理完成了的 I/O 请求，
减轻内存子系统的压力，也减小延迟。</p>
</li>
<li>
<p><code>io_queue_submission_pollfn</code>: 按照不同优先级把 I/O 入列</p>
</li>
<li>
<p><code>spdk_submit_work_pollfn</code>: 把 I/O 从队列里面取出，提交给 SPDK</p>
</li>
<li>
<p><code>reap_spdk_completions_pollfn</code>: 调用 <code>spdk_thread_poll()</code>
收集完成了的请求。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>当然，我们也可以从简处理</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>不用 <code>smp_pollfn</code>。即不支持跨 shard 发送 IO 请求，每个 shard 都用自己的 io channel。</p>
</li>
<li>
<p>不用第一个 <code>reap_spdk_completions_pollfn</code>。因为我们觉得这是个优化，以后慢慢加。</p>
</li>
<li>
<p>不用 <code>io_queue_submission_pollfn</code>，因为 SPDK bdev 层有自己基于 token bucket 的 QoS。</p>
</li>
<li>
<p>不用 <code>spdk_submit_work_pollfn</code>，既然不用 Seastar 的 fair queue，那么也不用从 io_queue
里捞 I/O 请求了。</p>
</li>
<li>
<p>只保留 <code>reap_spdk_completions_pollfn</code>。把一切都交给 SPDK。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>现在我们应该能回答刚才的问题了：</p>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>回调函数的参数呢？</p>
</div>
</blockquote>
</div>
<div class="paragraph">
<p>只要我们能把 I/O 请求包装成某种类似 <code>io_completion</code> 的类型，让它</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>能跟踪当初调用异步操作时，返回的 <code>promise&lt;&gt;</code> 以及</p>
</li>
<li>
<p>能包含在回调函数的参数 <code>cb_arg</code> 中，以便在 I/O 完成的时候，
通知对应的 <code>_pr</code> ，并且更新必要的统计信息。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>就可以了。这里有两个思路：</p>
</div>
<div class="olist arabic">
<ol class="arabic" start="1">
<li>
<p>让 <code>spdk_bdev_io</code> 包含 SPDK 版的 <code>io_completion</code>。在回调函数里
通过 <code>spdk_bdev_io</code> 引用对应的 <code>io_completion</code>。但是 <code>spdk_bdev_io</code>
更多的是作为 SPDK 开放给模块的实现者的接口，而非给应用开发者的接口。
注意到 <code>bdev.h</code> 中，不管是读还是写操作，I/O 的接口基本只有两类</p>
<div class="ulist">
<ul>
<li>
<p><code>void *buf</code>、<code>uint64_t offset</code> 和 <code>uint64_t nbytes</code></p>
</li>
<li>
<p><code>iovec iov[]</code>、<code>uint64_t offset</code> 和 <code>uint64_t nbytes</code></p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>上层应用在发送请求的时候是没有机会接触到 <code>spdk_bdev_io</code> 的，更遑论在它后面的 <code>driver_ctx</code> 中夹带"私货"了。况且 <code>driver_ctx</code>
的本意是让 bdev 的下层驱动加入自己 context，并不是提供给上层应用的。这条路走不通。</p>
</div>
<div class="olist arabic">
<ol class="arabic" start="2">
<li>
<p>在发送 I/O 请求的时候单独构造 SPDK 版的 <code>io_completion</code>，把它
作为 <code>cb_arg</code> 交给 SPDK。在回调函数里还原 <code>io_completion</code>，
再如前所述，做相应的处理。</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect1">
<h2 id="spdk-在-seastar-中的形态">SPDK 在 Seastar 中的形态</h2>
<div class="sectionbody">
<div class="paragraph">
<p>这里希望讨论 SPDK 在 Seastar 框架中的角色，以及呈现的接口是什么样子的。</p>
</div>
<div class="sect2">
<h3 id="另外一个-reactor">另外一个 reactor？</h3>
<div class="paragraph">
<p>前面关于 poller 的讨论引出了一个问题，即</p>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>我们能重用 Seastar 的这几个 poller 吗？</p>
</div>
</blockquote>
</div>
<div class="paragraph">
<p>这个问题在一定程度上等价于：</p>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>我们需要实现一个基于 SPDK 的 Seastar reactor 吗？</p>
</div>
</blockquote>
</div>
<div class="paragraph">
<p>在阅读 Seastar reactor 实现的时候，可能会注意到，
<code>reactor_backend_selector</code> 就是用来根据 <code>--reactor-backend</code>
命令行选项来选择使用的 reactor 后端的。这种类似插件的框架允许我们可以实现一个新的后端。虽然我们能够在 SPDK 的框架下</p>
</div>
<div class="ulist">
<ul>
<li>
<p>加入 poller，并使用非阻塞的调用</p>
</li>
<li>
<p>使用 aio 读写普通的文件</p>
</li>
<li>
<p>使用 <code>sock</code> 模块</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>把上面这些功能组合起来，足以实现一个功能完备的 <code>reactor_backend</code>。但是我们也可以保留 Seastar 的 reactor，像 DPDK 那样另外再注册
<code>spdk::ThreadGroup</code> 的 poller。牵涉面小，而且工作量也少些。对于两者的集成这可能是更稳妥的第一步。也许这也是 SPDK 支持在
Seastar 中更合适的定位&#8212;&#8203;即提供块设备的访问，而非作为通用的基础设施提供文件系统的访问。这两者有共性，但是也有一些不一样的地方。比如说文件系统可以用 <code>open_directory()</code>
和 <code>list_directory()</code> 来枚举一个目录下的所有文件，更进一步，块设备的枚举方式根据块设备的类型各自不同。SPDK 提供 <code>spdk_nvme_probe()</code>
来列举所有的 NVMe 设备，用 <code>spdk_bdev_first()</code> 和 <code>spdk_bdev_next()</code>
来找出所有的块设备。另外，为了提高并发，SPDK 引入了 io channel 的概念，它也很难直接映射到 Seastar 基于文件系统的 IO 体系里面。所以比较好的办法还是先把 SPDK
在 Seastar 下实现成相对独立的模块，而不是试图把它实现成为一种和 AIO 和 epoll
并列的通用异步后端。另外，在初期最大程度保留 SPDK 的基础设施，最小侵入的实现可能是比较稳妥的途径。</p>
</div>
</div>
<div class="sect2">
<h3 id="典型的用例">典型的用例</h3>
<div class="paragraph">
<p>我们用假象中的 Seastar + SPDK 重写 <code>examples/bdev/hello_world</code> 试试看</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c++"><span class="k">namespace</span> <span class="n">bpo</span> <span class="o">=</span> <span class="n">boost</span><span class="o">::</span><span class="n">program_options</span><span class="p">;</span>

<span class="n">seastar</span><span class="o">::</span><span class="n">logger</span> <span class="nf">spdk_logger</span><span class="p">(</span><span class="s">"spdk_demo"</span><span class="p">);</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">ac</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">av</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">seastar</span><span class="o">::</span><span class="n">app_template</span> <span class="n">seastar_app</span><span class="p">;</span>
    <span class="n">seastar_app</span><span class="p">.</span><span class="n">add_positional_options</span><span class="p">({</span>
        <span class="p">{</span> <span class="s">"bdev"</span><span class="p">,</span> <span class="n">bpo</span><span class="o">::</span><span class="n">value</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&gt;</span><span class="p">(),</span> <span class="s">"bdev"</span><span class="p">,</span> <span class="mi">1</span> <span class="p">},</span>
    <span class="p">});</span>
    <span class="n">spdk</span><span class="o">::</span><span class="n">app</span> <span class="n">spdk_app</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">seastar_app</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">ac</span><span class="p">,</span> <span class="n">av</span><span class="p">,</span> <span class="p">[</span><span class="o">&amp;</span><span class="p">]</span> <span class="p">{</span>
        <span class="k">auto</span> <span class="n">bdev_name</span> <span class="o">=</span> <span class="n">seastar_app</span><span class="p">.</span><span class="n">configuration</span><span class="p">()[</span><span class="s">"bdev"</span><span class="p">].</span><span class="n">as</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&gt;</span><span class="p">();</span>
        <span class="k">return</span> <span class="n">spdk_app</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">seastar_app</span><span class="p">.</span><span class="n">configuration</span><span class="p">(),</span> <span class="p">[</span><span class="n">bdev_name</span><span class="p">]</span> <span class="p">{</span>
            <span class="k">auto</span> <span class="n">dev</span> <span class="o">=</span> <span class="n">spdk</span><span class="o">::</span><span class="n">block_device</span><span class="o">::</span><span class="n">open</span><span class="p">(</span><span class="n">bdev_name</span><span class="p">);</span>
            <span class="kt">uint32_t</span> <span class="n">block_size</span> <span class="o">=</span> <span class="n">dev</span><span class="p">.</span><span class="n">block_size</span><span class="p">();</span>
            <span class="kt">size_t</span> <span class="n">buf_align</span> <span class="o">=</span> <span class="n">dev</span><span class="p">.</span><span class="n">memory_dma_alignment</span><span class="p">();</span>
            <span class="k">auto</span> <span class="n">buf</span> <span class="o">=</span> <span class="n">spdk</span><span class="o">::</span><span class="n">dma_zmalloc</span><span class="p">(</span><span class="n">block_size</span><span class="p">,</span> <span class="n">buf_align</span><span class="p">);</span>
            <span class="k">return</span> <span class="n">dev</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">buf</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span> <span class="n">buf</span><span class="p">.</span><span class="n">size</span><span class="p">()).</span><span class="n">then</span><span class="p">([</span><span class="o">&amp;</span><span class="p">]</span> <span class="p">{</span>
                <span class="n">memset</span><span class="p">(</span><span class="n">buf</span><span class="p">.</span><span class="n">get_write</span><span class="p">(),</span> <span class="mh">0xff</span><span class="p">,</span> <span class="n">buf</span><span class="p">.</span><span class="n">size</span><span class="p">());</span>
                <span class="k">return</span> <span class="n">dev</span><span class="p">.</span><span class="n">read</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">buf</span><span class="p">.</span><span class="n">get_write</span><span class="p">(),</span> <span class="n">buf</span><span class="p">.</span><span class="n">size</span><span class="p">());</span>
            <span class="p">}).</span><span class="n">then</span><span class="p">([</span><span class="o">&amp;</span><span class="n">buf</span><span class="p">]</span> <span class="p">{</span>
                <span class="n">temporary_buffer</span><span class="o">&lt;</span><span class="kt">char</span><span class="o">&gt;</span> <span class="n">good</span><span class="p">{</span><span class="n">buf</span><span class="p">.</span><span class="n">size</span><span class="p">()};</span>
                <span class="n">memset</span><span class="p">(</span><span class="n">good</span><span class="p">.</span><span class="n">get_write</span><span class="p">(),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">good</span><span class="p">.</span><span class="n">size</span><span class="p">());</span>
                <span class="k">if</span> <span class="p">(</span><span class="kt">int</span> <span class="n">where</span> <span class="o">=</span> <span class="n">memcmp</span><span class="p">(</span><span class="n">good</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span> <span class="n">buf</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span> <span class="n">buf</span><span class="p">.</span><span class="n">size</span><span class="p">());</span>
                    <span class="n">where</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
                    <span class="n">spdk_logger</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="s">"buf mismatches at {}!"</span><span class="p">,</span> <span class="n">where</span><span class="p">);</span>
                <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
                    <span class="n">spdk_logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"buf matches!"</span><span class="p">);</span>
                <span class="p">}</span>
            <span class="p">}).</span><span class="n">finally</span><span class="p">([</span><span class="n">buf</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">buf</span><span class="p">)]</span> <span class="p">{</span> <span class="p">});</span>
        <span class="p">}).</span><span class="n">handle_exception_type</span><span class="p">([</span><span class="o">&amp;</span><span class="p">]</span> <span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">system_error</span><span class="o">&amp;</span> <span class="n">e</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">spdk_logger</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="s">"error while writing/reading {}"</span><span class="p">,</span> <span class="n">e</span><span class="p">.</span><span class="n">what</span><span class="p">());</span>
        <span class="p">});</span>
    <span class="p">});</span>
<span class="p">}</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>其中，<code>spdk::app::run()</code> 会初始化 SPDK app 的运行时。比如说</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>调用 <code>rte_eal_init()</code></p>
</li>
<li>
<p>启动 SPDK 的工作协程调度器</p>
</li>
<li>
<p>启动 RPC 服务</p>
</li>
<li>
<p>加载各个子系统</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>它还会负责 SPDK 的清理工作。</p>
</div>
<div class="paragraph">
<p><code>spdk::bdev</code> 将会是一个 <code>seastar::sharded&lt;&gt;</code> 服务。<code>spdk::do_with_bdev()</code>
则是 <code>spdk</code> 提供的一个 helper，它负责初始化 <code>bdev</code> 实例，在合适的时机调用
<code>bdev::start()</code> 和 <code>bdev::stop()</code>，把根据第一个参数初始化完成好的 <code>bdev</code>
实例传给自己的另外一个参数，由后者使用 <code>bdev</code>。虽然这里以 bdev 模块为例，将来
Seastar 和 SPDK 的集成并不会局限于 bdev 模块。</p>
</div>
</div>
</div>
</div>]]></content><author><name>Kefu Chai</name><email>tchaikov@gmail.com</email></author><category term="c++" /><category term="spdk" /><category term="seastar" /><summary type="html"><![CDATA[当 C++ 遇上 SPDK。]]></summary></entry><entry><title type="html">从 metaslabs allocator 说起</title><link href="https://blog.k3fu.xyz/2021/05/27/alloc-fs.html" rel="alternate" type="text/html" title="从 metaslabs allocator 说起" /><published>2021-05-27T00:00:00+00:00</published><updated>2021-05-27T00:00:00+00:00</updated><id>https://blog.k3fu.xyz/2021/05/27/alloc-fs</id><content type="html" xml:base="https://blog.k3fu.xyz/2021/05/27/alloc-fs.html"><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>系统设计里面有很多开放问题。解决问题的策略是基于经验不断演进的。</p>
</div>
<div class="paragraph">
<p>ceph 的 bluestore 有好几种 allocator。其中的 AvlAllocator 基本就是 ZFS 的 df (Dynamic Fit) Block Allocator 的 C++ 移植版。所以要清楚 AvlAllocator，就绕不开 ZFS 的前辈。</p>
</div>
<div class="paragraph">
<p>那么什么是 <a href="https://github.com/openzfs/zfs/blob/60ffc1c460e4cdf3c3ca12c8840fd0675a98ed0d/module/zfs/metaslab.c#L1666">df allocator</a> 呢？它和 metaslab 又有什么关系呢？故事要从 slab allocator 说起。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="slab-allocator">slab allocator</h2>
<div class="sectionbody">
<div class="paragraph">
<p>我们知道 allocator 设计需要解决的问题就是在高效分配内存空间的同时最小化碎片。如果我们使用 first-fit 在空闲列表里面找指定大小的空闲块，搜索是快了，但是它可能产生更大的内部碎片。best-fit 虽然看上去很好，而且它会产生很小的内部碎片，这些碎片就像下脚料一样，很难利用了，因此性能其实也不见得就能改进很多。buddy 算法中所有的内存块都按照二的幂向上取整，这样方便搜索和方便回收，和合并伙伴内存块。但是这样也会造成相当的碎片，而且在频繁地内存分配和回收的时候，积极地合并策略也会浪费 CPU cycle。</p>
</div>
<div class="paragraph">
<p>根据观察，系统里面经常会分配释放特定大小的内存块，比如说一个异步的分布式系统里面可能会分配大量的 mutex 来细粒度地管理它的 inode，每次构造和析构都对应着内存子系统的分配内存和释放内存的操作。有一个解决的办法就是维护一个专门的列表，保存特定大小的 extent。加入刚才说的 mutex 大小是 43 字节，那么我们可能就会用一个列表保存一系列大小为 43 字节的内存块。这样分配和释放这样大小的内存的速度就是 O(1) 的。这种列表根据具体的应用场景可以有好几个，要是 inode 的大小是固定的话，inode 也可以有个专门的列表。但是这样处理也带来了问题，到底应该为这种专用列表分配多少内存呢？还有一个重要的问题，就是内核里面频繁地创建和析构内核对象本身也会耗费大量的 CPU 资源，这种开销甚至比为这些对象分配内存的开销还要高。slab allocator 应运而生。</p>
</div>
<div class="paragraph">
<p>slab allocator 最初是 Jeff Bonwick 为 Solaris 内核设计的，后来这个算法也用到了 zfs 和其他操作系统里面。slab 算法中的每个 slab，都对应着一类固定大小的对象。比如说 slab#1 就专门服务大小为 14 bytes 的对象，slab#2 对应 23 bytes 对象。在这个基础上，我们还有专门类型的 slab，比如专门提供 inode 的 slab，或者专门提供 mutex 的 slab，它们可以省去初始化和销毁对应类型对象的开销。每个 slab 由一个或多个物理地址连续的内存页构成。slab 从这一系列内存页为给定大小的对象分配内存。“专用列表”的思想其实是一种 cache，用来缓存特定大小内存块的分配信息。<code>kmem_cache</code> 中的 <code>slab_partial</code> 是一个 slab 的双向链表，其中每个元素都是一个 slab。当某个 slab 所有的 对象都回收的时候，这个 slab 就从 <code>slabs_partial</code> 移动到了 <code>slabs_free</code> 里面去，如果一个 slab 里面所有的页都分配了，那么这个 slab 就会加入 <code>slabs_full</code>。分配内存的时候先从 <code>slabs_partial</code> 里面找，找不到的时候才看 <code>slabs_free</code>。这样分配对象的时候更高效一些。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/diag-14afd5907efc8e5a56152af0db936dc3.png" alt="Diagram" width="1150" height="294">
</div>
</div>
<div class="paragraph">
<p>如果你在看的是 Linux，很可能你看的版本里面的 slab 已经<a href="https://lwn.net/Articles/565097/">改</a><a href="https://lwn.net/Articles/629152/">进</a><a href="https://lwn.net/Articles/564381/">很多</a>，不大一样了。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="metaslab-allocator">metaslab allocator</h2>
<div class="sectionbody">
<div class="paragraph">
<p>ZFS 作为当初所说的终极文件系统，包揽了从文件系统，卷管理系统，到块设备管理的所有工作。它引入了一个概念叫做 zpool，所以不管是裸设备还是 raid 设备都可以一股脑地扔到这个池子里，交给 ZFS 全权管理。所以 ZFS 的 allocator 要分配一个 extent 有三步：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>选择设备 (dynamic striping): 目标是让各个设备的空间使用率尽量平均。为了达成这个目标</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>稍微倾向于选择使用率低的设备</p>
</li>
<li>
<p>如果其他因素都差不多，那么用 round-robin。但是粒度需要合适。因为如果粒度大了，比如每次都分个 1GB，那么顺序读写的时候，请求都会往一个设备上招呼，设备间的并发性就没法用上了。但是粒度太小也不好，比如说分了 4KB，就找下一个设备了，那么 buffer 和 cache 的效果就会大打折扣。zfs 发现 512K 是个比较合适的值。</p>
</li>
<li>
<p>ZFS 的数据在刷到数据盘之前，会先以 ZIL (ZFS Intent Log) 的形式先落盘。这有点像 bluestore 里面 journal 的设计。ZFS 希望能通过引入这个 write cache 的机制，让写操作的数据先保存在比较快的设备 (SLOG) 上，之后再刷到目标设备，这样客户请求可以更快地完成。在需要低延迟低大量写数据时，就会使用 round-robin 调度设备，用类似扫射的方式，充分利用多设备的带宽。</p>
</li>
<li>
<p>striping 的策略可以根据数据的类型不同而不同。比如大块的顺序访问，小的随机访问，生命周期比较短的数据，比如刚才说的 ZIL，还有 dnode 这种保存 metadata 的数据。其中 dnode 有些类似普通文件系统里面的 inode。这些都是值得进一步挖掘和研究的地方。</p>
</li>
<li>
<p>如果发现有设备性能不好，就应该尽量不使用它。</p>
</li>
</ol>
</div>
</li>
<li>
<p>选择 metaslab: 每个设备都被切分成多个的区域，每个区域就是一个 slab。slab 的数量一般在 200 个左右。为什么是 200 个？其实也没有做很多分析。所以这个数字可能不是最优的。metaslab 0 在最靠外的磁道上，metaslab 200 在磁盘最靠里的磁道。每个 metaslab 都有个对应的 space map 用来跟踪 metaslab 的空闲空间。space map 是一个日志，记录着分配和回收的操作。所以分配空间的时候就会在 space map 最后面加一条记录，说明分配了哪个 extent，回收的时候也类似。需要注意的是，如果 space map 还不在内存里面，就需要从硬盘的 space map 日志重建。</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>我们假设磁盘的扇区在磁道上分布基本是均匀的，而磁盘转动的角速度是恒定的。所以在外圈柱面 (cyliner) 的数据分布会比内圈的数据分布更密集，比例就是磁道的半径。<a href="https://en.wikipedia.org/wiki/Logical_block_addressing">LBA 的寻址模式</a>下，地址越低的 LBA 地址，对应的柱面就越靠外面。所以为了访问速度考虑，我们更希望用 LBA 地址更低的 metaslab。</p>
</li>
</ol>
</div>
</li>
<li>
<p>选择 block: ZFS 确定 metaslab 之后，就会从这个 metaslab 里面分配 block 或者说 extent。它首先从磁盘上读取对应的 space map，然后重放它的分配和回收记录，用来更新内存里面用来表示空闲空间的 b-tree，树里面的节点对应空闲的 extent，树按照 extent 的 offset 排序。有了这个树就可以高效地分配连续的空间。同时它也是一个压缩 space map 的手段。如果分配和回收的操作很多互相抵消了，换句话说，如果树的规模很小，那么 ZFS 会重建硬盘上的 space map，把它更新成内存里面那个更小的版本。space map 的设计有这么几个好处</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>不需要初始化。一开始的时候，树里面只有一个 extent，表示整个设备是空闲的。</p>
</li>
<li>
<p>伸缩性好。无论管理的空间多大，内存里面会缓存 space map 的最后一个 block。这一点是 bitmap 望尘莫及的。</p>
</li>
<li>
<p>性能没有痛点(pathology)，即不会因为特定的使用模式造成性能急剧降低。不管是分配和回收的模式怎样，space map 的更新都很迅速。不管是 B-tree 还是 bitmap，在随机回收的时候，对数据结构的更新也是随机的，而且会产生很多写操作。虽然我们可以推迟更新下面的数据结构，把最近释放的 extent 保存在一个列表里面，等到这个列表太大了，再把它排序压缩，写回下面的 B-tree 或 bitmap，以期更好的性能，和写操作的局部性。但是 space map 在这方面基本没有影响，因为它本身就是个 free list。它记录 free 的方式就是写日志。</p>
</li>
<li>
<p>pool 很满或者很空的时候，space map 的都很快。不像 bitmap 在很满的时候搜索空闲块会更花时间。</p>
</li>
</ol>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>其实还有第四步，如果 metaslab 里面没有能满足的 range，就选择一个新的 metaslab。然是如果根本没有能满足要求的 metaslab，而且也检查过了所有的设备。ZFS 就开始 gang！“gang” 的意思就是把这个大的请求拆解成多个不连续的小的请求，希望它们合起来能满足要求。所谓“gang”也有点三个臭皮匠顶一个诸葛亮的意思。但是这是 allocator 的最后一招了。不到万不得已，allocator 不会 gang，因为这样会产生非常多的碎片。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/diag-3fe849d4c2745b53fb3abc79e22872ac.png" alt="Diagram" width="610" height="602">
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
早先 ZFS 早期使用 AVL 树来保存 space map，但是后来因为 AVL 树太耗费内存了，每个节点都需要额外用 48 byte 保存 AVL 树需要的信息，每个 extent 都有自己的节点，所以对于海量的小 extent，这样的开销是巨大的。所以 ZFS 后来<a href="https://www.illumos.org/issues/11971">改用</a>了 b-tree。至于为什么一开始选择 AVL。其实也没有什么特别的考虑，主要是作者在实现 metaslab allocator 的时候，Solaris 内核里面已经有 AVL 树了，所以就用了它。理论上说，红黑树也是可以用的。只要它里面的元素是有序的就行。
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="space-map">space map</h3>
<div class="paragraph">
<p>space map 在内存里面由 <code>ms_tree</code> 和 <code>ms_size_tree</code> 表示。其中 “ms” 是 MetaSlab 的缩写。两者保存的是同样的信息。</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>ms_tree</code> 中的空闲空间是按照它们的地址排序的。这样方便合并相邻的 extent。</p>
</li>
<li>
<p><code>ms_size_tree</code> 则是按照大小排序的。这样可以根据需要 extent 的大小来搜索。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>在 Paul Dagnelie 的 <a href="https://www.youtube.com/watch?v=LZpaTGNvalE">Metaslab Allocation Performance</a> 里面提到，为了减少内存的压力，甚至可以在 <code>ms_size_tree</code> 里面保存部分的 range。因为对于比较小的 alloc 请求来说，顺着 cursor 找，一般来说很容易在放弃之前找到足够大的 extent。所以只要 <code>ms_tree</code> 里面能找到就够了。让 <code>ms_size_tree</code> 保存比较大的 range，那些 extent 才是比较难找到的。</p>
</div>
</div>
<div class="sect2">
<h3 id="选择-rangeextentblock-的策略">选择 range/extent/block 的策略</h3>
<div class="paragraph">
<p>这些策略使用 cursor 记录上次分配的位置，希望下次分配的时候，用 first-fit 的策略从上次分配的位置开始找，希望能紧接着在上次 extent 的后面分配新的空间。这样当大量写入数据的时候，下层的块设备能把这些地址连续的写操作合并起来，达到更好的性能。这对于磁盘是很有效的优化策略，对 SSD 可能也能改进性能。毕竟，谁不喜欢顺序写呢。</p>
</div>
<div class="sect3">
<h4 id="cf-cursor-fit-allocator">CF (Cursor Fit) Allocator</h4>
<div class="paragraph">
<p>这个算法只用了两个 cursor。</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>根据 <code>ms_size_tree</code> 找到最大的一个 metaslab</p>
</li>
<li>
<p>让 <code>cursor</code> 和 <code>cursor_end</code> 分别指向 metaslab 的两端</p>
</li>
<li>
<p>每次分配新的空间都往前移动 <code>cursor</code>，直到 <code>cursor_end</code>。这表示 slab 里面的空间用完了，这时候就找一个新的 slab。</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="df-dynamic-fit-allocator">DF (Dynamic Fit) Allocator</h4>
<div class="paragraph">
<p>所谓 “dynamic” 是指算法会根据具体情况动态地在 best-fit 和 first-fit 两个算法中选择。这个算法用一个 cursor 指向上次分配 extent 结束的地方。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>如果 slab 的剩余空间小于设定值，就根据需要 extent 的大小，找够大的就行。</p>
</li>
<li>
<p>如果剩余空间还比较大，为了局部性，首先继续上次结束的地方搜索。搜索的范围由 <code>metaslab_df_max_search</code> 限定，如果超过这个大小还找不到，就退化成按照大小搜索。只要找到和需要大小相同或者更大的 extent 就行。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>每次分配到 extent，都会推进 <code>ms_lbas[bits_of_alignment]</code> 让它指向新分配 extent 结束的位置。这样相同对齐要求的 extent 就会从相邻的位置分配出来，不过这并不能防止其他对齐大小的 extent 也出现在同一区域中。</p>
</div>
</div>
<div class="sect3">
<h4 id="ndf-new-dynamic-fit-clump-allocator">NDF (New Dynamic Fit / clump) Allocator</h4>
<div class="paragraph">
<p>clump，即“扎堆”。其实这个名字更能说明这个算法的用意。它希望主动地为请求的大小选择成倍的更大的空间，预期接下来会出现多个相同大小的请求。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>先在 <code>ms_tree</code> 里面找 <code>[cursor, cursor+size)</code> 的 extent，如果找到足够大的 extent。就把 <code>cursor</code> 往前移动 <code>size</code></p>
</li>
<li>
<p>找不到的话，就在 <code>ms_size_tree</code> 里面先找大小为 2<sup>metaslab_ndf_clump_shift</sup> 倍 <code>size</code> 的 range，等找着了，就把 <code>cursor</code> 指向它，以它作为新的基地，发展成为这种对齐 extent 扎堆的地方。当然，新“基地”的大小是按照当前 slab 的最大空闲空间为上限的。</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="bluestore-里的-avl-allocator">bluestore 里的 Avl Allocator</h2>
<div class="sectionbody">
<div class="paragraph">
<p>AvlAllocator 基本上是 ZFS 的 DF Allocator 较早版本的 C++ 移植。它继续用 AVL tree 来保存 space map。但是不同之处在于，bluestore 里面的 AvlAllocator 并没有 <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSGangBlocks">gang</a> 的机制。所以 AvlAllocator 必须自己实现它。</p>
</div>
</div>
</div>]]></content><author><name>Kefu Chai</name><email>tchaikov@gmail.com</email></author><category term="fs" /><summary type="html"><![CDATA[系统设计里面有很多开放问题。解决问题的策略是基于经验不断演进的。]]></summary></entry><entry><title type="html">Log-strucutured Filesystem 和垃圾收集</title><link href="https://blog.k3fu.xyz/2021/05/16/gc-fs.html" rel="alternate" type="text/html" title="Log-strucutured Filesystem 和垃圾收集" /><published>2021-05-16T00:00:00+00:00</published><updated>2021-05-16T00:00:00+00:00</updated><id>https://blog.k3fu.xyz/2021/05/16/gc-fs</id><content type="html" xml:base="https://blog.k3fu.xyz/2021/05/16/gc-fs.html"><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>垃圾需要分类处理，有用的东西更应该分类。</p>
</div>
<div id="toc" class="toc">
<div id="toctitle" class="title"></div>
<ul class="sectlevel1">
<li><a href="#引子">引子</a></li>
<li><a href="#zoned-storage-和-degragmentation">Zoned Storage 和 degragmentation</a></li>
<li><a href="#f2fs">F2FS</a>
<ul class="sectlevel2">
<li><a href="#greedy">Greedy</a></li>
<li><a href="#cost-benefit">Cost-Benefit</a></li>
<li><a href="#cat">CAT</a></li>
<li><a href="#atgc">ATGC</a></li>
</ul>
</li>
<li><a href="#zonefs">ZoneFS</a></li>
<li><a href="#btrfs">Btrfs</a></li>
<li><a href="#spdk-ftl">SPDK FTL</a></li>
<li><a href="#lsm_zgc">LSM_ZGC</a>
<ul class="sectlevel2">
<li><a href="#问题">问题</a></li>
<li><a href="#方案">方案</a></li>
</ul>
</li>
<li><a href="#gc-的评估">GC 的评估</a></li>
<li><a href="#seastore">SeaStore</a>
<ul class="sectlevel2">
<li><a href="#cache">Cache</a></li>
<li><a href="#journal">Journal</a></li>
<li><a href="#segmentcleaner">SegmentCleaner</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="引子">引子</h2>
<div class="sectionbody">
<div class="paragraph">
<p>SeaStore 是 Crimson 使用的存储引擎。它的目标是</p>
</div>
<div class="ulist">
<ul>
<li>
<p>高性能</p>
</li>
<li>
<p>全异步</p>
</li>
<li>
<p>支持 ZNS 和高性能的存储介质比如 PMEM</p>
</li>
<li>
<p>支持异构存储</p>
</li>
<li>
<p>兼容 Ceph 现有的 object store 的语义</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>可以看出来，SeaStore 很像一个文件系统。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>文件名就是 object store 里面 object 的 object id</p>
</li>
<li>
<p>文件的内容就是 object 对应的数据</p>
</li>
<li>
<p>文件的 xattr 和各种属性，就类似 object 的 omap 和 xattr</p>
</li>
<li>
<p>当然文件还支持快照，这个和 object 的快照也很相似</p>
</li>
<li>
<p>类似的还有 mount、umount 和 fsck 这类操作</p>
</li>
<li>
<p>和文件系统一样，SeaStore 也有碎片的问题，所以我们也需要 defrag</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>文件系统的设计可能有好多方面</p>
</div>
<div class="ulist">
<ul>
<li>
<p>它像数据库: 需要高效地执行查询和修改的操作。对不同性质的访问模式也可以有不同的优化策略。</p>
</li>
<li>
<p>它像 allocator: 需要有效地管理空间。比如说，分配空闲空间，跟踪使用的空间，释放不用了的区域。</p>
</li>
<li>
<p>它也有 cache: 需要利用不同性质的存储介质，比如说利用低延迟的存储作为缓存，而用大容量的存储保存冷数据。</p>
</li>
<li>
<p>它像调度器: 需要在服务前台请求的同时，也能兼顾后台的任务。所谓磨刀不误砍柴工。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>所以一篇文章很难讨论到所有的问题。我们先从垃圾收集说起。为什么？因为笔者正好有一本 <a href="https://book.douban.com/subject/1157908/">《垃圾收集》</a>。有点拿着榔头找钉子的意思吧。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="zoned-storage-和-degragmentation">Zoned Storage 和 degragmentation</h2>
<div class="sectionbody">
<div class="paragraph">
<p>先说说“钉子”。目前 SeaStore 主要针对的存储介质叫 <a href="https://zonedstorage.io/introduction/zns/">Zoned Namespaces SSD</a>。ZNS flash 和 <a href="https://zonedstorage.io/introduction/smr/">叠瓦盘(SMR)</a> 都属于 Zoned Storage。后者因为读写性能不彰，消费级市场上大家避之不及。但是如果作为冷存储，性价比还是很高的。要是能在应用层结合性能更好的存储介质一起使用，综合下来性价比可能还会更好。但是它最大的问题在于，不支持原地 (in-place) 修改的，所有的修改操作都通过 copy-on-write 实现。整个磁盘被分成好几个区域 (zone)，每个区域都只能添加数据，不能重写已经写入的数据。但要是已经写入的数据被删除了，我们就要回收它们占用的空间。要是需要修改的话，就得复制一份新的。同样，也需要在复制完毕后，回收原来数据占据的磁盘空间。回收的时候，最少必须清除整个 zone。就像用活页笔记本记笔记，每页纸都从头写到尾，如果写坏了，想改一下呢？只能把那一页撕掉，换一张纸重新誊一遍。小块儿的橡皮擦在这里是不能使用的。</p>
</div>
<div class="paragraph">
<p>为了帮助理解问题，还需要提一下 SSD 的访问模式。一块 SSD 板卡上一般有多块 NAND 存储芯片，这些芯片通过一定数量的 channel 连接到控制器芯片。所以 SSD 最小的并发单元就是就是单块 NAND 芯片，最大的并发数就是 NAND 芯片的数量。因为无法向一块 NAND 芯片同时发送多个请求。存储领域我们喜欢说 LUN (logical unit number)，在这里我们也把特定的 NAND 用 LUN 来表示。一个 channel 由多个 LUN 共享。而每个 NAND flash LUN 由高到低分成不同的层级</p>
</div>
<div class="ulist">
<ul>
<li>
<p>channel. channel 之间不共享资源，可以充分并发。</p>
<div class="ulist">
<ul>
<li>
<p>LUN. 连接到相同 channel 的不同 LUN 之间可能会有数据依赖的问题，这一定程度上影响并发。</p>
<div class="ulist">
<ul>
<li>
<p>plane: 一个芯片有 2 个 或者 4 个 plane。对某个 page 进行写操作的时候，需要对挂在不同 plane 的相同地址的 page 同时写。换句话说，一个 4k 的 page 事实上是映射到不同 plane 的 page 的。</p>
<div class="ulist">
<ul>
<li>
<p>block: 一般是 512 page。它是 flash 擦除操作的最小单位。</p>
<div class="ulist">
<ul>
<li>
<p>page: 由四个 sector 构成，加上额外 (out-of-band) 的空间，用来保存映射本身的信息。sector 的大小一般是 4 KB。写操作的的时候，必须按照 page 在 block 里的顺序写。 每个 sector 由多个 cell 构成。而每个 cell 按照芯片的不同存储的比特数量也不一样。比如说 SLC 芯片是一个比特，MLC 是两个比特，TLC 三个，QLC 四个。这里需要解释一下 page pairing 的设计。根据 cell 保存比特的数量，由对应个数的 page 瓜分。换句话说，一个 QLC cell 对应着四个 paired page。只有所有的 page 都写好了，这次写操作才能算完成。所以对于一块有 4 个 plane 的 QLC 来说，每次写操作都必须同时写 4 个 plane，每个 plane 都因为 QLC cell 写操作的单位就是</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c++"><span class="n">min_bytes_per_write</span> <span class="o">=</span> <span class="mi">4</span> <span class="cm">/* 4 planes, 1 page per plan */</span> <span class="o">*</span>
                      <span class="mi">4</span> <span class="cm">/* 4 paired page for each cell */</span> <span class="o">*</span>
                      <span class="mi">4</span> <span class="cm">/* 4 sectors per page */</span> <span class="o">*</span>
                      <span class="mi">4</span><span class="n">_KB</span> <span class="cm">/* 4KB per sector */</span>
                    <span class="o">=</span> <span class="mi">256</span><span class="n">_KB</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>因此，flash 上的物理地址就由 channel, LUN, plane, block, page 和 sector 构成。读的单位是 sector，而写的单位则是 page。</p>
</div>
<div class="paragraph">
<p>顺便说一下，PMEM 的组织就相对扁平，它直接由多个 sector 构成。</p>
</div>
<div class="paragraph">
<p>早在 Zoned Storage 出现之前，因为磁盘的机械特性，大家就已经开始思考怎么把随机写转化为顺序写了，以期提高存储系统的性能。很自然的想法就是把 metadata 和 data 作为 log 顺序地写入磁盘。这也是 log-structured filesystem 中 log 的由来。虽然 LSF 解决了随机写的问题，它也带来了随机读的问题。举个例子，我们在磁盘上保存了一个很大的文件，一开始的时候，文件在磁盘上是顺序写入的，所以它的物理地址是连续的。磁盘在顺序读取整个文件的时候不需要很多次寻道，所以 IO 会很快，带宽仅仅受限于磁盘的转速和磁盘接口的传输速度。但是随着时间流逝，用户先后在文件的不同位置作了一些修改。因为这些修改一样，也是作为 log 顺序写入磁盘的，它们的位置和文件原来的位置差得很远了。所以如果要顺序读取文件的话，</p>
</div>
<div class="ulist">
<ul>
<li>
<p>这个读请求就可能会在逻辑地址翻译成物理地址的时候被拆分成为很多小的读请求，这极大影响了顺序访问的性能。</p>
</li>
<li>
<p>更不用说因为地址映射表大小增长带来的额外开销。</p>
</li>
<li>
<p>如果寻址是按照块对齐的，那么大量的数据片也会造成内部碎片。比如说，如果有的数据只有 7k，要是磁盘的块大小是 4k，那么最后那 3k 很可能就浪费掉了。</p>
</li>
<li>
<p>损害了读写的局部性。让系统没有办法根据局部性进行优化。通常文件的读写都有一些局部性，文件系统可能会在应用要求读取某个文件开始的 4k 的时候，就把开始的 4M 都读进来了。它估计你很可能接下来也会读这 4M，索性我都读进来好了。反正</p>
<div class="ulist">
<ul>
<li>
<p>闲着也是闲着</p>
</li>
<li>
<p>这 4M 的物理地址是连续的，所以干脆一起读了</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>记得小时候一个乐趣就是看 MSDOS 下面 <code>defrag</code> 程序不断移动的游标和闪动的小砖块。到现在 youtube 甚至还能找到一些怀旧的视频。它的作用差不多就是把同一文件保存在磁盘相邻的块。以减少磁头磁盘寻道的时间，同时通过把数据排列得更紧凑，把内部碎片挤掉，腾出来一些空闲空间来。可以说<a href="https://en.wikipedia.org/wiki/Defragmentation">碎片整理</a>是一种特定的<a href="https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)">垃圾收集</a>。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="f2fs">F2FS</h2>
<div class="sectionbody">
<div class="paragraph">
<p>f2fs 的 GC 算法解决的问题就是找出一个牺牲的 segment，把里面的有效块保存下来，然后回收它。f2fs 的 GC 分为前台和后台。只有当空闲空间不够了，才会执行前台 GC。前台 GC 要求短平快，这样能最小限度地减少用户应用的卡顿。后台 GC 则更关注总体的效能，它是内核线程定期唤醒的时候执行的。请注意，f2fs 其实并不会手动迁移有效块，它在选出要回收的 segment 之后，把其中所有的有效块都读取到内存的 page cache 里面，然后把它们标记成 dirty。这样，内核在清 cache 的时候，就会顺便把这些需要保存的有效块也一并写入新的 segment 了。这样不仅能减轻对前台的压力，也可以把小的写请求合并起来。另外，值得注意的是，f2fs 同时使用六个 log 区域，分别用来保存冷热程度不同的数据。它甚至把数据分为 cold, warn 和 hot 数据。它由三种 block</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>inode block</p>
</li>
<li>
<p>direct node: 用来保存数据块的地址。它的温度就比 indirect node 高。</p>
</li>
<li>
<p>indirect node: 用来保存 node 本身的 id。这个 id 用来定位另外一个 node。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>f2fs 修改数据会更新数据块的地址，为了能让 inode 找到新的数据，它需要更新索引数据块的 direct node，因此 direct node 就是温度更高的 block。它的修改更频繁。</p>
</div>
<div class="paragraph">
<p>f2fs 设计 GC 思路是让牺牲 segment 的代价最小，同时收益最高。评价策略有下面几种。其中 greedy 和 cost-benefit 是很经典的算法。</p>
</div>
<div class="sect2">
<h3 id="greedy">Greedy</h3>
<div class="paragraph">
<p>有效块的个数。所以有效块最少的 segment 就是牺牲品。当 GC 在前台运行时，f2fs 就使用 greedy 策略来选择回收的 segment，这样需要读写的有效块数量最小，所以对用户请求的影响也最小。</p>
</div>
</div>
<div class="sect2">
<h3 id="cost-benefit">Cost-Benefit</h3>
<div class="paragraph">
<p>cost-benefit 算法最早是 <a href="https://people.eecs.berkeley.edu/~brewer/cs262/LFS.pdf">The Design and Implementation of a Log-Structured File System</a> 一文中提出的。论文中设计的 Sprite LFS 文件系统当空闲 segment 的数量低于给定阈值(一般是几十)的时候就会开始 GC，直到空闲 segment 的总数超过另外一个阈值(一般取50到100)。理想情况下的分布应该双峰形的，两个大头分别是有效数据很少的 segment 和有效数据很多的 segment。前者是热数据，后者是冷数据。有效数据比例靠近 50% 的 segment 很少。这种分布对于 GC 来说是比较省心的。因为在回收的时候不需要迁移很多数据。但是使用 greedy 算法的模拟实验结果出乎意料，和局部性更低的测试相比，局部性高的测试产生的分布更差：大量的 segment 都聚集在中间。论文里面分析，使用 greedy 算法的话，只有在一个 segment 的有效数据比例在所有 segment 中最低的时候，它才会被选中回收。这样几轮 GC 之后，所有 segment 的有效数据比例都会降到回收阈值以下，甚至用来保存冷数据的 segment 的有效数据比例也是如此。但是冷数据 segment 使用率是比较坚挺的，它下降得比较慢。可以类比一个收藏家用来保存藏品的储藏室，除非收藏家突然改变了喜好，否则藏品是很少变化的。而冷数据本身也是有惯性的。所以，含有冷数据的 segment 即使大量保有无效数据，但是因为其稳定的使用率，不会被选中回收。</p>
</div>
<div class="paragraph">
<p>根据这个观察，论文认为，cold segment 里面的空闲空间其实比 hot segment 里面的空闲空间更有价值。为什么呢？我们可以反过来看，因为和那些很快被修改得体无完肤的 hot segment 相比，cold segment 中的无效数据很难迅速增长。它在系统里面会保持相对较高的使用率更长的时间，我们不得已只能去不停地回收那些 hot segment。它们就像离村庄很近的耕地，因为比较近，所以大家都会更喜欢耕种它们。而埋藏在 cold segment 里面的空闲空间，就更难回收。这导致 cold segment 的使用率慢慢地降低，但是无法回收。这些顽固的 cold segment 的比例在一个访问局部性比较强的系统中可能会很高。因为在那种访问模式下，cold segment 中的冷数据的地位更难以撼动。请注意，这里说的局部性强指的是，重复修改的数据只占硬盘中所有数据的一小部分，绝大部分数据是不变的。如果局部性差的话，所有数据被修改的概率基本上是均等的。如果 GC 很积极地回收使用率低的 hot segment 的话，这样虽然当时迁移的成本很低，但是迁移之后当时被迁移的有效数据很快就被修改了，成为了新的无效数据。所以与其不断地迁移这种 hot segment，不如把它放一会儿，等养“肥”了，再 GC 不迟。这样反而效果更好，效率更高。那时候的有效数据的比例会更低。打个比方，就像一条运动裤已经有点脏了，另外一件衣服上面只有一个墨点，如果明天还要踢一场球，那么你说今天是洗裤子还是洗衣服呢？要不今天还是先洗衣服，明天就穿这条裤子踢球，等踢完球再洗裤子吧。</p>
</div>
<div class="paragraph">
<p>为了能让 GC 更积极地回收这些 cold segment，我们必须在政策上倾斜，让 GC 觉得回收 cold segment 是更有利可图的。所以论文里面把 segment 里面的最新的数据的年龄也作为参数一起计算，segment 越老，那么它里面的的空闲空间至少也经历了那么长的时间。我们把它们解放出来的收益就是两者之积。用公式表达就是：</p>
</div>
<div class="stemblock">
<div class="content">
\[\frac{benefit}{cost} = \frac{(1-u) \times age}{1 + u}\]
</div>
</div>
<div class="paragraph">
<p>其中</p>
</div>
<div class="ulist">
<ul>
<li>
<p>u 表示有效块在 section 中所占比例</p>
</li>
<li>
<p>age 表示 section 中所有 segment 中，最近一次修改的时间。这个数字越大，意味着这个 segment 越 "cold"。用这个时间来估计</p>
</li>
<li>
<p>1 - u 表示回收该 section 获得的收益，因为通过这次回收，能得到的空闲空间是 1 - u。</p>
</li>
<li>
<p>1 + u 表示开销。1 表示我们需要读取整个被回收的 segment，u 表示我们需要往另外一个 segment 写入其中 u 那么多的数据。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>论文中的模拟实验表示，这样的策略可以使 segment 在使用率上呈现双峰分布或者哑铃状分布。即低使用率的 segment 和高使用率的 segment 都比较多，中间 segement 很少。这样的分布比较适合 GC。如果再能根据冷热数据进行聚类那么 GC 就会更高效。</p>
</div>
<div class="paragraph">
<p>f2fs 在最初的 cost-benefit 上稍加改进，它用来计算 \(\frac{benefit}{cost}\) 的 age 并不是 segment 里面 section 最大的那个，而是里面所有 section age 的平均值。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><span class="k">def</span> <span class="nf">get_cost_benefit_cost</span><span class="p">(</span><span class="n">superblock</span><span class="p">,</span> <span class="n">segment_index</span><span class="p">):</span>
    <span class="n">usable_segs_per_section</span> <span class="o">=</span> <span class="n">superblock</span><span class="p">.</span><span class="n">get_usable_segs</span><span class="p">(</span><span class="n">segment_index</span><span class="p">)</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">superblock</span><span class="p">.</span><span class="n">seg_per_sec</span> <span class="o">*</span> <span class="n">segment_index</span>
    <span class="n">mtime</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">superblock</span><span class="p">.</span><span class="n">seg_entries</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">mtime</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">start</span><span class="p">,</span> <span class="n">usable_segs_per_section</span><span class="p">))</span>
    <span class="n">mtime</span> <span class="o">/=</span> <span class="n">usable_segs_per_section</span>
    <span class="n">valid_blocks</span> <span class="o">=</span> <span class="n">superblock</span><span class="p">.</span><span class="n">seg_entries</span><span class="p">[</span><span class="n">segment_index</span><span class="p">].</span><span class="n">valid_blocks</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">valid_blocks</span> <span class="o">/</span> <span class="n">log2</span><span class="p">(</span><span class="n">super_block</span><span class="p">.</span><span class="n">blocks_per_segment</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
    <span class="n">age</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">-</span> <span class="mi">100</span> <span class="o">*</span> <span class="p">(</span><span class="n">mtime</span> <span class="o">-</span> <span class="n">superblock</span><span class="p">.</span><span class="n">min_mtime</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">superblock</span><span class="p">.</span><span class="n">max_mtime</span> <span class="o">-</span> <span class="n">superblock</span><span class="p">.</span><span class="n">min_mtime</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">UINT_MAX</span> <span class="o">-</span> <span class="p">((</span><span class="mi">100</span> <span class="o">*</span> <span class="p">(</span><span class="mi">100</span> <span class="o">-</span> <span class="n">u</span><span class="p">)</span> <span class="o">*</span> <span class="n">age</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">100</span> <span class="o">+</span> <span class="n">u</span><span class="p">))</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>用公式表示，</p>
</div>
<div class="stemblock">
<div class="content">
\[\begin{align}
age &amp;= 100 \times (1 - \frac{mtime_j - \min_{\forall i \in segs}mtime_i}{\max_{\forall i \in segs}mtime_{i} - \min_{\forall i \in segs}mtime_{i}}) \\
cost &amp;= UINT\_MAX - \frac{(1-u) \times age}{1 + u}
\end{align}\]
</div>
</div>
<div class="paragraph">
<p>其中</p>
</div>
<div class="ulist">
<ul>
<li>
<p>age 表示候选的 segment 在所有 segment 中最老的和最年轻的中的位置，按照百分比计算。如果 segment 很久没有修改，是很冷的那个，那么它的值接近 100。</p>
</li>
<li>
<p>cost 表示回收 segment 的收益。如果有效数据的比例越高，那么 cost 的值就越大；mtime 越 大，age 越小，cost 越大。</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="cat">CAT</h3>
<div class="paragraph">
<p>Cost Age Times，这个算法基于 cost-benefit，它同时关注 flash block 的 wear leveling 问题。但是 ZNS SSD controller 已经帮我们处理了，所以这里不考虑这类算法。</p>
</div>
</div>
<div class="sect2">
<h3 id="atgc">ATGC</h3>
<div class="paragraph">
<p><a href="https://lwn.net/Articles/828027/">ATGC</a> (Age Threshold based Garbage Collection) 是华为的开发者提出的算法，用来改进 f2fs 的 GC 效果 (effect) 和性能 (efficiency)。分成三步：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>先选希望回收的 segment，即 source victim:</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>先根据候选 segment 来确定一个阈值，如果 0 表示最年轻的 segment 的年龄，100 表示最老的。如果阈值是 80 的话，那么就候选者就进一步限制在 [80, 100] 这个区间里面。</p>
</li>
<li>
<p>如果 segment 的年龄小于预设定的阈值，那么就不再考虑把它回收。因此可以避免回收太年轻的 segement，这种 segment 往往更新更频繁。</p>
</li>
<li>
<p>在这个更小的范围里面选择有效块最少的 segment。这样可以减少迁移数据，降低迁移的成本。</p>
</li>
</ol>
</div>
</li>
<li>
<p>再选要写入的 segment，即 destination victim:</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>以源 segment 的年龄为中心，以设置的值为半径，划定一个区间。尽量选择那些年龄和 source 相近的 segment 作为目标。这样他们的更新频率可能更相近，有助于保持冷热数据的分离和聚类。</p>
</li>
<li>
<p>在划定的区域里面，选择有效块最多的 segment。倘若选择有效块最少的 segment，那么最合适的 segment 就是源 segment 了。</p>
</li>
</ol>
</div>
</li>
<li>
<p>使用 SSR (slack space recycling) 把有效块从从源 segment 迁移到目标 segment。</p>
</li>
</ol>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
f2fs 除了顺序写日志 (normal logging)之外，还能在空间不够的时候往无效的空间直接写 (threaded logging)，写进去的日志串起来一样用。这样虽然把顺序写变成了随机写，但是可以避免 GC 带来的卡顿，要是选择的 segment 有很大的空闲空间，也能顺序写一阵。这种随机写的做法就叫做 SSR。
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="zonefs">ZoneFS</h2>
<div class="sectionbody">
<div class="paragraph">
<p>ZoneFS 没有 GC 一说。它里面每个 zone 对应一个文件。如果是 conventional zone，那么目录名字就是 <code>cnv</code>，如果是 sequential zone 的话，目录名字就是 <code>seq</code>。sequential zone 因为需要确保发射的顺序性，所以只支持 DIO。如果 DIO 写的位置不是 wptr 的位置，它干脆返回 <code>EINVAL</code>。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/diag-094e47049fe295ce106612dcceb22069.png" alt="Diagram" width="140" height="182">
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="btrfs">Btrfs</h2>
<div class="sectionbody">
<div class="paragraph">
<p>因为我们的目标是支持 flash，而 flash 本质上是不支持原地 (in-place) 修改的，所以所有的修改操作都通过 copy-on-write 实现。这也正是 SeaStore 的设计很大程度上受到了 Btrfs 影响的原因。而且最近 Btrfs 也开始加入对 zoned 设备的<a href="https://lwn.net/Articles/853308/">支持</a>。</p>
</div>
<div class="paragraph">
<p><mark>TODO</mark></p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="spdk-ftl">SPDK FTL</h2>
<div class="sectionbody">
<div class="paragraph">
<p>SPDK 的 FTL 中每个 band 相当于 相当于 f2fs 里的 segment，在 GC 的时候，也需要进行评估</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><span class="k">class</span> <span class="nc">Band</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">prep_write</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># ...
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">dev</span><span class="p">.</span><span class="n">seq</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">seq</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dev</span><span class="p">.</span><span class="n">seq</span>

    <span class="o">@</span><span class="nb">property</span>
    <span class="k">def</span> <span class="nf">age</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">dev</span><span class="p">.</span><span class="n">seq</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">seq</span>

    <span class="k">def</span> <span class="nf">calc_merit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">threshold_valid</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">usable_blocks</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>
        <span class="k">if</span> <span class="n">threshold_valid</span><span class="p">:</span>
            <span class="n">valid_blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">usable_blocks</span> <span class="o">-</span> <span class="n">threshold_valid</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">valid_blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lba_map</span><span class="p">.</span><span class="n">num_valid</span>
        <span class="n">invalid_blocks</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">usable_blocks</span> <span class="o">-</span> <span class="n">valid_blocks</span>
        <span class="n">valid_ratio</span> <span class="o">=</span> <span class="n">invalid_blocks</span> <span class="o">/</span> <span class="p">(</span><span class="n">valid_blocks</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">valid_ratio</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">age</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>用公式表示</p>
</div>
<div class="stemblock">
<div class="content">
\[\begin{align}
age_{i} &amp;= \max_{\forall j \in bands}seq_{j} - seq_{i} \\
merit_{i} &amp;= \frac{(1-u_{i}) \times age_{i}}{u_{i}}
\end{align}\]
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="lsm_zgc">LSM_ZGC</h2>
<div class="sectionbody">
<div class="paragraph">
<p>比较原始的 GC 算法可能仅仅关注 zone 里面有效数据的比例，如果一个 zone 里面的有效数据超过一定比例，我们可能就希望保留它，而回收那些充斥着垃圾数据的 zone。<a href="https://www.usenix.org/system/files/hotstorage20_paper_choi_0.pdf">LSM_ZGC 一文</a> 提出的 GC 算法希望解决下面几个</p>
</div>
<div class="sect2">
<h3 id="问题">问题</h3>
<div class="ulist">
<ul>
<li>
<p>冷热数据分离。因为将来在进行另一次 GC 的时候，也会根据数据的性质进行选择 zone。如果一个 zone 里面的冷数据或者热数据的比例是压倒性的多数，那么就可以更容易地决定这个 zone 的处理方式。比如说，如果是绝大多数是冷数据，那么可以放心地把数据搬到冷存储上。要是绝大多数是无效数据，那么这个 zone 就是很好的回收对象。反之，如果 zone 的使用率是 50%，那么做 GC 的时候就难以取舍了。</p>
</li>
<li>
<p>GC 的时候，如果被选中回收的 zone 使用率很高，那么保存有效数据的开销会很大。因为典型的 zone 的大小是 256MB 或者 512MB，所以即使允许用户 IO 抢占后台的 GC 任务，GC 对总体性能产生的影响也会很明显。</p>
</li>
<li>
<p>大量 4k 大小读请求和相对大的读请求相比，后者的性能要比前者要好很多。我们假设后者是 8K 到 128K 的IO。原因是，连续地址的读请求可以充分利用 ZNS SSD 内部的并发能力。因为文中说，一个 zone 里面的数据会被分散到不同 channel 连接的 LUN 上，所以读取更大的读操作就能更好地利用同时使用多个 channel 带来的并发性。但是我认为，使用更大的读操作是一种利用 inter-channel 并发的简便的方式。但是这并不等于说，发送多个分散的小的读操作的并发就不好了。这样做的缺点应该是请求的个数更多了。因为处理多个请求产生的开销也因而增加。但是要得到比较好的性能也需要权衡，如果 64MB 的区间里面，有效的数据只有 4K，那么就没有必要坚持读取所有 64MB 的数据了。</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="方案">方案</h3>
<div class="paragraph">
<p>按照在文中的设置，一个 zone 大小为 1GB，一个 segment 为 2MB，一个 block 为 4KB。这些设定很大程度上借用了 f2fs 的磁盘布局。为了提高读操作的效率，如果一个 segment 里面有效的 block 个数小于 16，那么就仅仅读取有效数据，否则就读取整个的 segment。</p>
</div>
<div class="paragraph">
<p>我把这个思路叫做“大浪淘沙”。每个 zone 都处于下面四种状态中的一个。刚落盘的数据在 C0，以 segment 为单位统计，如果某一个 segment 的数据使用次数超过事先设定的阈值 threshold<sub>cold</sub>，所有保存在这种 segment 中的有效数据都被收集到 C1C_zone，其他 segment 中的有效数据则悉数放到 C1H_zone 中。等到下一次 GC 的时候，无论是 C1H_zone 还是 C1C_zone 中，只要数据仍然有效，我们就把它们当作冷数据，一起放到 C2_zone。因为他们都经历了两次 GC 试炼，并且存活了下来。论文的作者期望通过这样的筛选机制，能够有效地区分不同生命周期的数据。其中，请注意，在这里，“冷数据”并不是指访问频次很低的数据，而是很少被修改或者删除的数据。它们经得起时间的考验，历久而弥坚。我们常说的 WORM (write once read many) 设备保存的就是冷数据。就是而热数据则是那种很快失效的数据，这种数据经常修改，它们生命周期很短，转瞬即逝，如同朝露一般。可以说，CPU 寄存器里面的数据就是热数据。所以我们在第一次 GC 的时候会借助保存数据的机会，先把冷热数据初步分开。这样如果要找热数据富集的牺牲品 zone 的时候，可以更容易地找到这样的 zone。但是第二次 GC 的时候就不再关注它们的使用频次了，而只是单纯地把第一代的幸存者都收集在一起。它们都被搬运过一次，而且顺利地活到了第二次 GC。所以它们完全有资格升级成“二级冷数据”。论文认为，第一代幸存者的生存周期相似，所以它们的空间局部性很可能也更好。比如说 leveldb 里面，同一个 SSTable 里面数据的访问频次可能不同，但是它们的生命周期是相同的，读写模式也一致。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/diag-cc5ce0511ab793e146a79ac5fd9c7695.png" alt="Diagram" width="1050" height="236">
</div>
</div>
<div class="paragraph">
<p>我们还可以更进一步。让经过冷热数据区分后活下来的 C2_zone 数据，升级进入 C3_zone。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/diag-b92a6e8c5c6f5c96230e0f564b67e4f2.png" alt="Diagram" width="974" height="59">
</div>
</div>
<div class="paragraph">
<p>这样通过多次淘汰，我们就可以把数据分出三六九等，有的数据经历了很多次 GC 都巍然不动，有的数据最多只能到 C1H_zone 状态就黯然退场。前者都保存在同一个 zone 里面，所以 GC 的时候就不会因为它们和其他热数据挤在一起，而在腾地方的时候被迫迁移它们，因此就减少了不必要的开销。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="gc-的评估">GC 的评估</h2>
<div class="sectionbody">
<div class="paragraph">
<p>看过这几个算法。试图总结一下怎么评估一个 GC 算法。我们常说，“多快好省”。这里面蕴含着好几个指标。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>多和好。这里说的是“效用”，即 effectiveness。有时我们也说 efficacy，在这里不区分它们两个。即一个过程的产出情况。</p>
<div class="ulist">
<ul>
<li>
<p>多：GC 的一个产出就是释放出来的空间。</p>
</li>
<li>
<p>好：另一个产出，可能是迁移出来数据对数据访问的友好性。比如说，如果迁移出来的数据能根据访问特性很好地聚类，那么局部性可能就会更好。如果把并发性考虑进去，适当地条带 (striping) 化，也能提高大规模顺序读的性能。</p>
</li>
</ul>
</div>
</li>
<li>
<p>快和省。这里说的是“效率”，即 efficiency。就是说投入怎么样。如果让系统长时间停顿，等待 GC，那么这个投入就比没有卡顿的系统高了。所以说迁移数据的时机和迁移的数据量都和效率息息相关。之前“洗裤子”的例子就是在短期的多和好和长期的快和省之间取得一个平衡。如果只关注短期收益，而忽视长期的总体效益，那么这个算法的总体性能也很难提高。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>如果只是考虑“多”和“省”，如果把 GC 看成一个下金蛋的鸡，我们可以用下面的公式计算养鸡的长期利润</p>
</div>
<div class="stemblock">
<div class="content">
\[profit = revenue - cost\]
</div>
</div>
<div class="paragraph">
<p>对应到 GC，就是</p>
</div>
<div class="stemblock">
<div class="content">
\[profit = reclaimed - migrated\]
</div>
</div>
<div class="paragraph">
<p>如果让 GC 从一个老化的 (aged) 的存储系统开始，能让系统完成大量的读写删访问，其中写入的数据大大超过系统的空闲空间，那么这个过程中的产生的收益，应该能表征 GC 的性能了。当然，为了理解 GC 的行为产生的效果，也应该佐以数据分布和留存空闲空间大小的统计来评估某一时刻存储系统的健康情况。</p>
</div>
<div class="paragraph">
<p>整个系统的性能可能还是得看系统在特定负载下的延迟和吞吐量。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="seastore">SeaStore</h2>
<div class="sectionbody">
<div class="paragraph">
<p>因为 SeaStore 当前的目标是支持 ZNS。对它来说，每一张活页纸就是一个 segment。为了理解 SeaStore 怎么做垃圾收集，首先需要知道 SeaStore 里面的 journal 是什么。</p>
</div>
<div class="sect2">
<h3 id="cache">Cache</h3>

</div>
<div class="sect2">
<h3 id="journal">Journal</h3>
<div class="paragraph">
<p>Journal 就是日志，也就是 log-structured filesystem 里面的 log。在任意时刻，SeaStore 总是指定一个特定的 segment 作为当时写 journal 的专用 segment。</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
ZNS 是支持同时打开多个 zone 的。这样让我们可以按照写入数据的不同特性，选择不同的 zone，这样可以避免因为不同生命周期的数据相互交错，导致在 GC 的时候投鼠忌器，难以权衡。但是 SeaStore 现在为了简单起见，还没有利用这个特性。
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="segmentcleaner">SegmentCleaner</h3>
<div class="sect3">
<h4 id="gc-的时机">GC 的时机</h4>
<div class="ulist">
<ul>
<li>
<p>mount 的时候，会扫描 journal 映射的地址空间。这确定了空闲空间的大小，借这个机会，就会看看是不是应该运行 GC。</p>
</li>
<li>
<p>在 IO 事务提交完成时。这时，事务产生的 journal 会减少可用空间。所以也可能需要进行 GC。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>先定义几个 ratio:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>reclaimable ratio: 可回收空间和无效空间之比。</p>
<div class="ulist">
<ul>
<li>
<p>可回收空间指的是非可用空间除去被有效数据占用的，剩下的那部分。</p>
</li>
<li>
<p>非可用空间就是总空间减去可用空间。</p>
</li>
</ul>
</div>
</li>
<li>
<p>available ratio: 即可用空间和总空间的比例。可用空间是下面几项之和</p>
<div class="ulist">
<ul>
<li>
<p>空闲 segment 的总大小。也就是空闲 segment 的个数 * segment 的大小</p>
</li>
<li>
<p>当前 segment 的剩余空间。正在用来记 journal 的 segment 就是所谓的“当前” segment。</p>
</li>
<li>
<p>GC 扫描的进度。SegmentCleaner 在 GC 时候会逐一扫描 journal 的所有记录块，它认为扫描过的块都是恢复“自由身”了的可用空间。</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="gc-的条件只要满足下面的条件之一就触发-gc">GC 的条件，只要满足下面的条件之一，就触发 GC</h4>
<div class="ulist">
<ul>
<li>
<p>空闲空间不够了。需要同时满足下面的条件，才能称为空间不够</p>
<div class="ulist">
<ul>
<li>
<p><code>available_ratio</code> &lt; <code>available_ratio_gc_max</code></p>
</li>
<li>
<p><code>reclaimable_ratio</code> &gt; <code>reclaim_ratio_gc_threshhold</code></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="gc-的手段">GC 的手段</h4>
<div class="paragraph">
<p>在上面提到的 GC 时机，seastore 会判断是否满足 GC 的条件，当条件满足的时候，就触发 GC，这时 <code>Segment::gc_reclaim_space()</code> 会扫描以往 journal 分离其中的有效数据，把它们作为 transaction 写到新的 journal 中去。为了避免长时间地阻塞客户端请求，每次扫描的空间大小由 <code>reclaim_bytes_stride</code> 限制，而且我们维护着一个 cursor 记录着上次扫描结束的位置。每次扫描都从上次结束的地方继续。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><span class="n">extents</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">scan_cursor</span> <span class="o">=</span>
    <span class="n">journal</span><span class="p">.</span><span class="n">scan_extents</span><span class="p">(</span><span class="n">victim_segment</span><span class="p">.</span><span class="n">body</span><span class="p">,</span>
                         <span class="n">start</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">scan_cursor</span><span class="p">,</span>
                         <span class="n">step</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">reclaim_bytes_stride</span><span class="p">)</span>
<span class="n">txn</span> <span class="o">=</span> <span class="n">Transaction</span><span class="p">()</span>
<span class="k">for</span> <span class="n">extent</span> <span class="ow">in</span> <span class="n">extents</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">extent</span><span class="p">.</span><span class="n">alive</span><span class="p">:</span>
        <span class="k">continue</span>
    <span class="n">txn</span><span class="p">.</span><span class="n">rewrite_extent</span><span class="p">(</span><span class="n">extent</span><span class="p">)</span>
<span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">scan_cursor</span><span class="p">.</span><span class="n">is_complete</span><span class="p">:</span>
    <span class="n">txn</span><span class="p">.</span><span class="n">release_segment</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">scan_cursor</span><span class="p">.</span><span class="n">segment</span><span class="p">)</span>
<span class="bp">self</span><span class="p">.</span><span class="n">txn_mgr</span><span class="p">.</span><span class="n">submit_transaction</span><span class="p">(</span><span class="n">txn</span><span class="p">)</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="gc-的问题">GC 的问题</h4>
<div class="paragraph">
<p>从改进 GC 效率和性能的角度出发，可以从这么几个方面改进</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>记录数据在产生、访问和修改删除过程中产生的统计信息。</p>
<div class="ulist">
<ul>
<li>
<p>跟踪有效数据和无效数据。能迅速地枚举一个 segment 中所有的有效数据。</p>
</li>
<li>
<p>辨别冷热数据。这个需求是上一个的强化形式。即能保存数据块被修改的时间。如果数据经历多次 GC 并存活至今，那么也需要能记录它被 GC 的次数及其年龄。</p>
</li>
<li>
<p>按照数据在应用层面的属性重排或者聚类，提高读写性能。比如说，如果一个对象被分成多个块，那么这些块的物理地址最好也是连续的。</p>
</li>
</ul>
</div>
</li>
<li>
<p>按照数据的特性分开保存</p>
<div class="ulist">
<ul>
<li>
<p>前提是能同时写多个 journal。</p>
</li>
<li>
<p>在选择目标 segment 的时候，LSM_ZGC 和 f2fs 的 ATGC 都主张把类似的数据通过一定的特征进行聚类。</p>
</li>
</ul>
</div>
</li>
<li>
<p>更有效地迁移有效数据。</p>
<div class="ulist">
<ul>
<li>
<p>读的模式：LSM_ZGC 提供了一个思路，让我们有选择地大批量地顺序读，而不总是仅仅读取有效数据。</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>]]></content><author><name>Kefu Chai</name><email>tchaikov@gmail.com</email></author><category term="ceph" /><summary type="html"><![CDATA[垃圾需要分类处理，有用的东西更应该分类。]]></summary></entry><entry><title type="html">ceph::common::PerfCounter 和 seastar::metrics</title><link href="https://blog.k3fu.xyz/2021/05/10/metrics.html" rel="alternate" type="text/html" title="ceph::common::PerfCounter 和 seastar::metrics" /><published>2021-05-10T00:00:00+00:00</published><updated>2021-05-10T00:00:00+00:00</updated><id>https://blog.k3fu.xyz/2021/05/10/metrics</id><content type="html" xml:base="https://blog.k3fu.xyz/2021/05/10/metrics.html"><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>成年人还是得做选择。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="seastarmetrics">seastar::metrics</h2>
<div class="sectionbody">
<div class="paragraph">
<p><a href="http://docs.seastar.io/master/group__metrics.html">seastar::metrics</a> 是 seastar 提供的一套机制，用来监控系统的动态指标。</p>
</div>
<div class="sect2">
<h3 id="label">label</h3>
<div class="paragraph">
<p>在 <code>seastar::metrics</code> 里面，每个指标都有自己的标签。举个例子吧，假设 seastore 能够管理多个存储设备，每个设备都有自己的 IO 队列。而作为一个存储系统，我们可能会关心好多指数</p>
</div>
<div class="ulist">
<ul>
<li>
<p>total_bytes: 写入设备的数据量</p>
</li>
<li>
<p>total_operations: 读写请求的总个数</p>
</li>
<li>
<p>queue_length: 当前的读写队列长度</p>
</li>
<li>
<p>delay: 总的延迟</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>问题在于，每个设备我们都需要监控这同一组数据。如果按照面向对象的思路，那么就是每个对象都有一组属性，而且每个对象都有自己的名字或者索引。</p>
</div>
<div class="paragraph">
<p>另外对于 seastar 应用来说，每个 shard 都是一个相对独立处理的单元，独立结算，自负盈亏。如果我们希望监控一个 sharded service，那么这个服务在每个 shard 都有一组自己的数据。Sesastar 甚至为每一个 <a href="http://docs.seastar.io/master/structseastar_1_1metrics_1_1impl_1_1metric__definition__impl.html">metric_definition_impl</a> 都强制加上了 <code>shard_label</code>，所以每个 metric 从一出生，它标签上的"shard"就是当时 reactor 的 shard id，如果当时 reactor 还没有运行，那么 shard 就是 "0"。但是如果要自己设置 <code>shard_label</code> 的话，也可以用 seastar 提供的 <code>shard_label</code>。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c++"><span class="n">label</span> <span class="nf">shard_label</span><span class="p">(</span><span class="s">"shard"</span><span class="p">);</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>其中 <code>label</code> 是一个 functor 类，它可以用来构造 <code>label_instance</code> 实例。后者才是真的 label。</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c++"><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="nc">T</span><span class="p">&gt;</span>
<span class="n">instance</span> <span class="nf">operator</span><span class="p">()(</span><span class="n">T</span> <span class="n">value</span><span class="p">)</span> <span class="k">const</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">label_instance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">forward</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">(</span><span class="n">value</span><span class="p">));</span>
<span class="err">}</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>通过为 metrics 贴上多个标签，我们可以更方便地管理和查询这些指数。而且不用因为把数据聚合起来而丢失重要的信息。seastar 在把 metrics 导出到监控系统的时候，也把 label 一起导出了。它</p>
</div>
<div class="ulist">
<ul>
<li>
<p>使用 prometheus <a href="https://prometheus.io/docs/practices/naming/#labels">labels</a></p>
</li>
<li>
<p>把 label 编码成 collected 的 <a href="https://collectd.org/wiki/index.php/Naming_schema#Plugin_instance_and_type_instance">type instance</a> 字段里面。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>将来，如果我们决定使用 <code>seastar::metrics</code> 的话，甚至可能会用不同的 label 在不同的维度来标记同一个监控的指数</p>
</div>
<div class="ulist">
<ul>
<li>
<p>不同 CPU shard 上的监控数据</p>
</li>
<li>
<p>不同 pg 的监控数据</p>
</li>
<li>
<p>不同存储设备的监控数据</p>
</li>
<li>
<p>不同网卡或者网络设备的监控数据</p>
</li>
<li>
<p>不同网络连接的监控数据，比如说连接到 peer osd 的心跳或者网络延迟。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>比如说，当我们注意到出现多个 slow request 的时候，首先会看这些请求在不同维度上的相关性，如果所有的请求都和某个 replica osd 有关，那么我们可能就能猜测 primary 和这个 osd 的连接是不是有问题。</p>
</div>
</div>
<div class="sect2">
<h3 id="名字">名字</h3>
<div class="paragraph">
<p>metric 的名字由 group 和 name 构成。一组逻辑上相关的 metric 组成一个 group，比如说 seastore 的所有指数的 group 可能就是 "seastore"。加上一个名字空间方便管理。内存方面的监控则用 "memory" 作为 group 的名字。</p>
</div>
</div>
<div class="sect2">
<h3 id="数据的类型">数据的类型</h3>
<div class="paragraph">
<p><code>seastar::metrics</code> 大体是按照 <a href="https://prometheus.io/docs/concepts/metric_types/">Prometheus 的几种指标的类型</a> 和 <a href="https://collectd.org/wiki/index.php/Data_source#Data_source_types">collectd 的数据类型</a> 来实现的。</p>
</div>
<div class="paragraph">
<p>它定义了下面几类指标：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>counter: 单调递增的整数。要是发现某个 counter 变小了，唯一的解释就是它溢出了。比如说，从启动到现在 cache miss 的请求数量。</p>
</li>
<li>
<p>gauge: 测量值。和 <code>counter</code> 不同，<code>guage</code> 支持浮点，它的值允许减小。比如说</p>
<div class="ulist">
<ul>
<li>
<p>系统的音量</p>
</li>
<li>
<p>某个队列的总延迟</p>
</li>
<li>
<p>当前 onode 的缓存大小</p>
</li>
</ul>
</div>
</li>
<li>
<p>derive: 和 <code>gauge</code> 相比，<code>derive</code> 更像 <code>counter</code> 一些。它仅仅支持整型，但是它允许读数减小。它叫 "derive" 的原因并不是这个指标是由其他指标导出 (derive) 的，而是因为，很多时候我们关心的是这个数值的变化量 (derivative)，或者说读数对时间的导数。</p>
<div class="ulist">
<ul>
<li>
<p>当前正在处理的请求个数</p>
</li>
</ul>
</div>
</li>
<li>
<p>histogram: 一个指标的直方图。比如说，</p>
<div class="ulist">
<ul>
<li>
<p>请求的延迟的分布</p>
</li>
<li>
<p>请求大小的分布</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>为了和 <a href="https://collectd.org/documentation/manpages/types.db.5.shtml">collectd 的类型</a> 对应上，<code>seastar::metrics</code> 还定义了一些方便的函数，用来设置基于这些类型。比如，<code>make_total_bytes()</code>，它的功用就是在为 collectd 导出监控数据的时候，为对应的指标设置 <code>total_bytes</code> 的数据类型。</p>
</div>
</div>
<div class="sect2">
<h3 id="数据的来源">数据的来源</h3>
<div class="paragraph">
<p><code>make_gauge()</code> 这些函数让我们提供一个变量的引用，或者给出一个函数返回要监控的数据。事实上前者也是通过包装一个 lambda 来实现的。</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="cephcommonperfcounters">ceph::common::PerfCounters</h2>
<div class="sectionbody">
<div class="paragraph">
<p><code>ceph::common:PerfCounters</code> 使用 <code>PerfCounters</code> 来管理一组 perf counter，</p>
</div>
<div class="sect2">
<h3 id="名字-2">名字</h3>
<div class="paragraph">
<p>因为 <code>ceph::common::PerfCounters</code> 不是统一管理的，每个 perfcounter 在构造的时候都设定了一个字符串，作为它的名字。在导出 perfcounter 的时候，把所有的 perfcounter 被放在以 <code>PerfCounters::get_name()</code> 为名的大对象里面。每个 perfcounter 分别打印自己的信息。</p>
</div>
</div>
<div class="sect2">
<h3 id="数据的类型-2">数据的类型</h3>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 25%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">none</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">u64</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">time</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">longrunavg</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">histogram</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">time</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="数据的来源-2">数据的来源</h3>
<div class="paragraph">
<p>每个 <code>PerfCounters</code> 都有一个 <code>std::vector&lt;&gt;</code> ，用于保存对应的 perf counter，通过预先定义好的索引来更新和访问 vector 里面对应的值。</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ceph</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">seastar</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PerfCountersCollection</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">metric group</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="3"><p class="tableblock">add_u64_counter()</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">make_counter()</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">make_derive()</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">make_gauge()</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PerfCountersBuilder</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">metric_groups</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PerfCounters</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">idx</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">metric_id?</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>总体上 <code>PerfCounters</code> 和 <code>metrics</code> 两个功能相当，而且前者内置了一些功能</p>
</div>
<div class="ulist">
<ul>
<li>
<p>对 counter 加上优先级。优先级有点像 Python 的 logging level。它决定了不同情况下，输出 perfcounter 的详尽程度。如果是 <code>CRITICAL</code> 的 perfcounter 的话，一般来说都会打印出来，或者发给 prometheus, influxdb 这些 mgr module。</p>
</li>
<li>
<p>支持设置自定义的字符串作为监控指标的单位，在打印 perfcounter 的时候，可以打印自定义的单位。</p>
</li>
<li>
<p>如果一个 perfcounter 有 <code>LONGRUNAVG</code> 属性，那么还会统计平均值。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>但是 <code>PerfCounters</code> 缺少 label 的支持，而且其实现是基于 <code>std::atomic&lt;&gt;</code> 的，在读写 perfcounter 的时候对性能也有负面的影响。</p>
</div>
</div>
</div>
</div>]]></content><author><name>Kefu Chai</name><email>tchaikov@gmail.com</email></author><category term="ceph" /><summary type="html"><![CDATA[成年人还是得做选择。]]></summary></entry><entry><title type="html">QoS 和 dmClock</title><link href="https://blog.k3fu.xyz/2021/04/24/dmclock.html" rel="alternate" type="text/html" title="QoS 和 dmClock" /><published>2021-04-24T00:00:00+00:00</published><updated>2021-04-24T00:00:00+00:00</updated><id>https://blog.k3fu.xyz/2021/04/24/dmclock</id><content type="html" xml:base="https://blog.k3fu.xyz/2021/04/24/dmclock.html"><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>QoS，而且是分布式的。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="qos">QoS</h2>
<div class="sectionbody">
<div class="paragraph">
<p>如果一个服务有多个服务对象，那么就得分轻重缓急。但是也不能因为有些服务对象不重要，就完全不顾它们。举个例子，就算平时工作再忙，上个月的报销单也应该及时填啊。那么怎么实现 QoS 呢？还是用报销单的例子，那么我们定个规矩吧：每天至少用半小时时间填报销，要是做不完的话，那么就明天继续做。在执行之前，我们需要先引入几个概念:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>任务：也就是要做的事情。每件事情都有它的优先级，还有它要花费的时间。</p>
</li>
<li>
<p>任务列表：要是任何时候，手里面只有一件事情，我们可能就不用操心 QoS 了。但是现实是，很多时候别说不同优先级的，就是同一优先级的任务都可能同时有好几件。我们一般按照先到先服务的原则，把它们放到队列里面，挨个处理。</p>
</li>
<li>
<p>分类：把要做的事情按照优先级分成几种。</p>
</li>
<li>
<p>计量：每个任务需要的时间都不一样，如果只是处理会议的邀请，那么可能只需要几秒钟就能做出回应。但是如果是分析一个新的编译错误，可能就得花半个小时。</p>
</li>
<li>
<p>调度：接下来该从哪个队列里做哪个任务呢？</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>我们还需要继续细化刚才的规定，这半个小时时间是排在什么时候呢？要不下午一点开始吧。对应到刚才的概念就是</p>
</div>
<div class="ulist">
<ul>
<li>
<p>任务：每天的工作，比如处理信件，填报表单，当然还有调试程序。</p>
</li>
<li>
<p>任务列表：每件工作按照先后顺序记到小本本上。做完一件就划掉一件。有新的工作就记在最后面。</p>
</li>
<li>
<p>分类：工作分成两类：一类是平时的工作，另一类是低优先级的维护工作，比如说报销。</p>
</li>
<li>
<p>计量：对列表里的工作根据工作量一一进行评估。</p>
</li>
<li>
<p>调度：现在到一点了吗？还没到，那么看看“正事儿“列表里面下一项是什么？到了的话，看看另外一个列表有没有东西，没有的话，就先做正事儿。反过来也是这样，就是如果今天正好没有其他事情的话，即使没有到一点钟，那么也不妨把积攒的报销单填了。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>所以对我们来说，每当要开始下一个任务的时候，要回答的问题就是，我应该看哪个任务列表呢？刚才的设计定义的算法是一种比基础的优先级队列 （priority queue）调度更复杂的算法。它不仅仅为不同性质的任务定义了具有两个优先级的队列，而且为了防止低优先级任务得不到执行，还为它们保留了最小的带宽。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="clock">Clock</h2>
<div class="sectionbody">
<div class="paragraph">
<p>在说 mClock 之前，我们先说说几个指标：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>weight (share) ：这个类型的任务能使用多少比例的资源。如果一个系统里面需要进行数据迁移，那么它可以占用的带宽比例就可以很高。</p>
</li>
<li>
<p>reservation：这个类型的任务最少能保证得到多少资源。如果系统里面需要有低延迟的应用，比如说远程桌面或者交互式的网络游戏，那么就必须保证最低的带宽。但是这种应用需要的 weight 可能就相对低一些。</p>
</li>
<li>
<p>limit: 使用资源的上限。比如说刚才说的数据迁移的应用，它可能就需要设定一个上限，在资源吃紧的情况下，防止它挤占其它应用的带宽。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>刚才的算法里面只支持前两个指标。mClock 的目标是同时支持这三个参数。论文前面列举了一些算法，这些算法解决的问题分为三类：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>按照应用指定的权重分配带宽</p>
</li>
<li>
<p>除了按照比例分配带宽之外，还能照顾对于延迟比较敏感的应用</p>
</li>
<li>
<p>除了按照比例分配带宽，照顾延迟，还能预留最低的带宽</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>但是 mClock 不仅仅能支持这些功能之外，还支持指定上限，并且能根据资源的容量动态地进行调整。比如说，一个系统它接入的是一个网络存储，因为分布式的存储系统和本地存储相比有着更多的变数和不确定性，那么这个系统能获得的存储的带宽可能就是动态的。根据网络系统的设置，以及存储系统提供给它的带宽而定。</p>
</div>
<div class="paragraph">
<p>mClock 先从 tag-based 调度算法开始。 标签是指每当调度器看到一个新的请求，就会给它贴一个标签。标签上有几个之后要用到的数字。这个很像是去饭馆吃饭时，拿到的预约单号。当调度器需要决定谁是下个幸运儿的时候，它就检查每个请求上标签。每个客户端都有自己的权重 \(w_i\) 。我们用权重的倒数就可以构成一个等差数列，</p>
</div>
<div class="stemblock">
<div class="content">
\[1/w_i, 2/w_i, 3/w_i, .., n/w_i\]
</div>
</div>
<div class="paragraph">
<p>在服务端，当请求到达的时候，就根据请求所属的客户端为请求打上标签。同一客户端发来的请求构成了这个数列。权重越大客户端对应的序列分布越密集。下图中有蓝黄和绿三个客户端，它们的权重分别为 1/2，1/3 和 1/6。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/diag-24e6f884f67150da9bbfe1e0eaa73663.png" alt="Diagram" width="650" height="378">
</div>
</div>
<div class="paragraph">
<p>如果标签小于当前时间就按照先小后大的顺序依次处理，那么在单位时间里面，客户端得到处理的请求个数所占比例也就是它分到的权重。</p>
</div>
<div class="paragraph">
<p>我们还可以从完全公平调度（Complete Fairness Scheduling）算法的角度来进一步理解。CFS 的调度对象是进程。它按照 RUNNABLE 进程的虚拟时钟从小到大排序，时间靠前的进程先调度，靠后的后调度。每个进程都有自己的虚拟时钟。内核定期按照物理时钟的节拍推进所有的虚拟时钟。各进程时间流逝的速度是不一样的，优先级高的进程时钟就走得慢，低的走得快些。这样，CFS 就能直接调度排在最前面的进程。顺便说一下，Linux 中的 CFS 调度器是用红黑树来管理这些 RUNNABLE 进程的，树的键就是虚拟时钟的值。</p>
</div>
<div class="paragraph">
<p>另外，由于时间早的会先调度，所以如果谁的时钟停摆很久，如果它的标签一开始就比它优先级高的其他人低好多，那么一旦开始发送请求，接下来就会因为自己的时钟读数比其他人都小而连续抢占资源，导致发生饥饿。因此 mClock 论文里面说的 global virtual time 或者 virtual time 也就是为了解决这个问题。全局时钟要求所有的客户端时钟不管客户端是不是正在发出请求，都不断地往前推进。确保不会有人中途加入，打乱其他人的步调。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="mclock">mClock</h2>
<div class="sectionbody">
<div class="paragraph">
<p><a href="https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Gulati.pdf">mClock</a> 把这个想法推而广之，既然我们要支持 reservation 和 limit，为什么不能用他们来计算 tag 呢？我想这也是 mClock 的名字的由来，multiple clocks。于是在处理每个请求的时候，都会给他们设定三个 tag：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>\(\mathit{R_i}^{r}\)</p>
</li>
<li>
<p>\(\mathit{L_i}^{r}\)</p>
</li>
<li>
<p>\(\mathit{P_i}^{r}\)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>其中，</p>
</div>
<div class="ulist">
<ul>
<li>
<p>R 代表 reservation</p>
</li>
<li>
<p>L 代表 limit</p>
</li>
<li>
<p>P 则是 priority, weight 或者是 proportional</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>以 \(\mathit{R_i}^{r}\) 为例，用下面的递推公式计算：</p>
</div>
<div class="stemblock">
<div class="content">
\[\mathit{R_i}^{r} = max \{\mathit{R_i}^{r-1}+\frac{1}{\mathit{r_i}}, \mathit{t}\}\]
</div>
</div>
<div class="paragraph">
<p>其中， \(\mathit{r_i}\) 就是第 i 个客户端的 reservation 值。相邻 tag 的距离就是 \(\frac{1}{r_i}\)。而 \(\mathit{t}\) 是当前的时间。</p>
</div>
<div class="paragraph">
<p>那么刚才说的 global virtual time 的问题怎么解决呢？因为新客户端的上一个标签无据可查，而且枚举 <strong>所有</strong> 的客户端，定时遍历每个人的时钟，挨个更新它们的三个 tag，对系统可能也是个负担。论文采取的办法是，把所有人的 P 和当前时间对齐。</p>
</div>
<div class="paragraph">
<p>写成 C++ 代码，可能就是这样：</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code data-lang="c++"><span class="kt">void</span> <span class="nf">request_arrival</span><span class="p">(</span><span class="n">request_t</span> <span class="n">r</span><span class="p">,</span> <span class="kt">time_t</span> <span class="n">t</span><span class="p">,</span> <span class="n">vm_t</span> <span class="n">i</span><span class="p">)</span>
<span class="p">{</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">vm</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">was_idle</span><span class="p">())</span> <span class="p">{</span>
    <span class="c1">// tag adjustment</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">P_tags</span><span class="p">.</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
      <span class="k">auto</span> <span class="n">min_P_tag</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">min_element</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">begin</span><span class="p">(</span><span class="n">P_tags</span><span class="p">),</span> <span class="n">std</span><span class="o">::</span><span class="n">end</span><span class="p">(</span><span class="n">P_tags</span><span class="p">));</span>
      <span class="k">for</span> <span class="p">(</span><span class="k">auto</span><span class="o">&amp;</span> <span class="n">vm</span> <span class="o">:</span> <span class="n">active_vm</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">P_tags</span><span class="p">[</span><span class="n">vm</span><span class="p">.</span><span class="n">id</span><span class="p">]</span> <span class="o">-=</span> <span class="o">*</span><span class="n">min_P_tag</span> <span class="o">-</span> <span class="n">t</span><span class="p">;</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="c1">// tag assignment</span>
  <span class="n">R_tags</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">max</span><span class="p">(</span><span class="n">R_tags</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">reservation</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">t</span><span class="p">);</span>
  <span class="n">L_tags</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">max</span><span class="p">(</span><span class="n">L_tags</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">limit</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">t</span><span class="p">);</span>
  <span class="n">P_tags</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">max</span><span class="p">(</span><span class="n">P_tags</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">weight</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">t</span><span class="p">);</span>
  <span class="n">schedule_request</span><span class="p">();</span>
<span class="p">}</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>为什么对 \(\mathit{P_i}^{r}\) 特殊处理呢？我们假设直接使用当前的时间作为新人或者刚开始 active 的客户端的  \(\mathit{P_i}^r\)。那么对其他客户端来说，它们发出第一个请求的时候，\(\mathit{P_i}^{r}\) 也是当前的系统时刻，但是当客户端持续地发出请求，随着时间推移，根据各自的权重不同，你我的时间开始差得越来越多，贫富差距慢慢显现。但是新来的客户端横空出现打破了这个均衡，它的 \(\mathit{P_i}^{r}\) 不是根据之前的 \(\mathit{P_i}^{r-1}\) 推算出来的，而是直接使用的当前时间。虽然它的优先级可能并不高，但是它在一段时间之内凭借它的暂时的“后发优势“，无缘无故地打败了很多甚至优先级比他更高的老前辈，直到它的权重慢慢地把一开始的 P 慢慢抵消，一切恢复正常。mClock 算法为了解决这个问题，转而以最新的系统时钟调整其他老革命的 P，让所有的 P 按照时间轴平移，令最小的 P 等于系统时间。这样新加入的 P 就不会干扰现有的秩序了。因为 P 标签有累计的效应，所以这里仅仅调整它。</p>
</div>
<div class="paragraph">
<p>有了三个 tag，那么到底以谁为准呢？调度器有两种决策模式，并根据当前情况在两者之间切换：</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>基于约束的决策：调度器先看看有没有人的 R 小于当前时间，要是有的话，就直接调度最小 R 的请求。一旦所有的 R tag 大于当前时间，就脱离基于约束的决策模式，进入基于权值的模式。</p>
</li>
<li>
<p>基于权值的决策：这时候所有人的 reservation 都已满足。调度器开始按照权重来分配资源。它先把资源用量还没有超过上限的人找出来，他们的 L 比当前时间小。然后从中找出 P 最小的。调度 \(vm_{i}\) 的请求的时候，除了让它的最前面的请求出列，还需要把 \(vm_{i}\) 其他还在队列里面的请求的 R 都减去 \(1/r_{i}\)。这样可以保持相邻 R 的差仍然是 \(1/r_{i}\)。否则，我们想象一下，如果一个客户端很长一段时间它的请求都是用基于权值的决策调度的，那么它的 R tag 就会非常大。一旦系统的资源吃紧，它会立即得不到应该有的 reservation。为什么？只是因为它一直因为权重得到了很多服务，但是这笔账不应该算在 reservation 头上。所以我们每次因为权重调度请求，都需要把这个客户端的还没调度的请求的 R tag 都往前移动一格。确保这个客户端的 reservation 不会受到影响。</p>
</li>
</ol>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/diag-06cb45f5e7e3fc832d67ce5752d92d6d.png" alt="Diagram" width="480" height="308">
</div>
</div>
<div class="sect2">
<h3 id="mclock-为存储系统做的一些改进">mClock 为存储系统做的一些改进</h3>
<div class="sect3">
<h4 id="突发情况">突发情况</h4>
<div class="paragraph">
<p>有些客户端可能会稳定地发送读写请求，但是也有那种平时不动声色，突然狮子大开口的角色。有时候请求会陡然增加，我们叫做 burst。比如说有的客户端每个晚上会为文件建立索引，但它白天却悄无声息，这时候我们希望感谢它之前高风亮节为大家节省资源，给它个行个方便，让它一开始的 \(\mathit{P_i}^{r}\) 小一些。</p>
</div>
<div class="stemblock">
<div class="content">
\[\mathit{P_i}^{r} = max \{\mathit{P_i}^{r-1}+\frac{1}{\mathit{r_i}}, t - \frac{\sigma_{i}}{w_i}\}\]
</div>
</div>
<div class="paragraph">
<p>这个 \(\sigma_{i}\) 可以每个人都不一样，我们暂且把它叫做"先人后己奖励奖"吧，专门用来补偿把带宽让给别人的人，让他们在有急需的时候也能感受到 QoS 的温暖。论文后面也提到，如果这个奖金太高，会因为扰乱权重分配的决策，导致细水长流式的客户的高延迟。</p>
</div>
</div>
<div class="sect3">
<h4 id="读写有别">读写有别</h4>
<div class="paragraph">
<p>在存储系统里面，写的延迟往往比读请求要高。但是我们没办法取巧，把同一个客户端的请求乱序执行。比如，把读请求放到写请求之前乱序执行未导致读到不一致的数据。</p>
</div>
</div>
<div class="sect3">
<h4 id="大小有别">大小有别</h4>
<div class="paragraph">
<p>IO 请求有的大，有的小，不能等同视之。因为我们不追求绝对的延迟数值，比如说一个 4k 的读请求需要多少毫秒。我们希望得3到的是一个比例，即大小为 S 的 IO 请求产生的延迟相当于多少个单位大小的 IO 请求。</p>
</div>
<div class="stemblock">
<div class="content">
\[1 + \frac{S}{T_{m} + B_{peak}}\]
</div>
</div>
<div class="paragraph">
<p>论文大概计算了一下，其中 \(T_{m}\) 表示机械动作产生的延迟，假设每次随机读写都要求机械磁盘的悬臂产生移动到对应的磁道，磁盘都需要转动到需要读写的扇区。而 \(B_{peak}\) 是磁盘最高的读写速度。</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="dmclock">dmClock</h2>
<div class="sectionbody">
<div class="paragraph">
<p>分布式的场景下，每个服务器需要了解两件事情</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>你从所有服务器总共获得了多少服务</p>
</li>
<li>
<p>其中，你通过 reservation 获得了多少服务</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>为了让服务器知道客户端的服务情况，客户端在发送请求的时候也会顺带着发送</p>
</div>
<div class="ulist">
<ul>
<li>
<p>\(\rho_{i}\) 最近请求到当前请求之间，因为基于约束的决策获得的服务数量。其实也就是因为 reservation 获得的服务数量。</p>
</li>
<li>
<p>\(\delta_{i}\) 最近请求到当前请求之间，获得了多少服务。</p>
</li>
</ul>
</div>
<div class="stemblock">
<div class="content">
\[\mathit{R_i}^{r} = max \{\mathit{R_i}^{r-1}+\frac{\rho_{i}}{\mathit{r_i}}, \mathit{t}\} \\
\mathit{L_i}^{r} = max \{\mathit{L_i}^{r-1}+\frac{\delta_{i}}{\mathit{l_i}}, \mathit{t}\} \\
\mathit{P_i}^{r} = max \{\mathit{P_i}^{r-1}+\frac{\delta_{i}}{\mathit{w_i}}, \mathit{t}\}\]
</div>
</div>
<div class="paragraph">
<p>下面是之前介绍的单机版递推公式：</p>
</div>
<div class="stemblock">
<div class="content">
\[\mathit{R_i}^{r} = max \{\mathit{R_i}^{r-1}+\frac{1}{\mathit{r_i}}, \mathit{t}\}\]
</div>
</div>
<div class="paragraph">
<p>可以发现，我们把 1 换成了 \(\rho_i\)。这个思路和之前是一脉相承的。有点像一个大型的合作性的公寓，每家都有个户主负责向提供交各种费用水费、电费、煤气费。但是户主们并不是各自为政，只要交的总金额足够支付整个公寓的账单就行，当然，家里面有的时候没有流动资金，所以紧张的话，有的人可以少交有的人也可以多交。但是户主和户主之前缺少有效的沟通方式，好在自来水公司它们都有明细账，所以户主在缴费的时候可以查看之前的账目。这里户主就像分布式系统里面提供服务的节点，各项费用的账单就像不同性质的客户请求。缴费的过程就是处理客户请求。借用刚才的示意图，我们以 100 块钱为单位，如果公寓上个月加起来交了 200 块钱电费，那么电力公司这次就应该把付账的进度条往前推进 2 个单位。所以图里面的有两个请求就用虚线表示了，它们代表在其他服务器处理过的请求。</p>
</div>
<div class="imageblock">
<div class="content">
<img src="/images/diag-ce864186a97ebc129f2d101826de62d3.png" alt="Diagram" width="480" height="308">
</div>
</div>
<div class="paragraph">
<p>公式里的 \(\rho_{i}\) 和 \(\delta_{i}\) 就是这里的"2"。这两个系数表示因为不同原因，自从上次从这个服务器处理请求，这个客户端一共从不同服务器获得了多少服务。很明显，\(\delta_{i}\) 应该总是大于等于 \(\rho_{i}\)。如果是单机的话，两个参数就退化成 1 了。</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="dmclock-在-ceph-中的应用">dmClock 在 Ceph 中的应用</h2>
<div class="sectionbody">
<div class="paragraph">
<p>因为 dmClock 是一个通用的算法，Ceph 并没有把直接集成在自己的 repo 里面，而是单独实现了高度模板化的 <a href="https://github.com/ceph/dmclock">dmClock 库</a>。这样其他应用也能使用它。dmClock 库基本忠实地实现了论文中的算法。开始之前，请大家注意，目前 Ceph 正在使用的并不是 dmClock 而是 mClock。</p>
</div>
<div class="sect2">
<h3 id="osd-中的-qos">OSD 中的 QoS</h3>
<div class="paragraph">
<p>OSD 需要处理多种请求，有的请求优先级比较低，比如后台的数据恢复，有的请求优先级比较高，比如说前台客户发来的读写请求。而 OSD 的处理能力有限，又希望有一定的 QoS 能力。就需要设计一个能兼顾不同优先级需求的调度器。我们把不同类型的请求看成不同的客户端，在 <code>OpSchedulerItem</code> 就定义了下面几种请求</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>client_op</code></p>
</li>
<li>
<p><code>peering_event</code></p>
</li>
<li>
<p><code>bg_snaptrim</code></p>
</li>
<li>
<p><code>bg_recovery</code></p>
</li>
<li>
<p><code>bg_scrub</code></p>
</li>
<li>
<p><code>bg_pg_delete</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>以 <code>bg</code> 开头的请求都是后台的请求，它们保证系统的正常运行，但是优先级相对于前面两类请求就要低一些。而且，每个 <code>OpSchedulerItem</code> 都有自己的 priority 和 cost。所以调度器调度的对象就是 <code>OpSchedulerItem</code> 了。但是可能和大家猜测的不同，OSD 用来实现 QoS 的调度器却不是全局唯一的。它是 <code>OSDShard</code> 的成员变量。而 <code>OSDShard</code> 则是 OSD 的执行单位，它维护着一个队列。队列里面的元素就是被安排执行的请求。每个 shard 都负责一个或者多个 PG，每当有请求到达，都会用请求对应的 PG 作为 key 找到对应的 shard，让 shard 决定什么时候执行它。而这个决定就是由调度器做出的。所以有多少个 <code>OSDShard</code> 就有多少个调度器，它们分别为各自负责的一组 PG 调度请求。</p>
</div>
<div class="paragraph">
<p>我们有两个调度器</p>
</div>
<div class="sect3">
<h4 id="classedopqueuescheduler">ClassedOpQueueScheduler</h4>
<div class="paragraph">
<p>这个调度器很像 <a href="https://en.wikipedia.org/wiki/Low-latency_queuing">Low-latency queuing</a>。它基于 WeightedPriorityQueue 实现，简称 WPQ。它的设计和大家熟知的 Weighted Fair Queueing 调度器很像。WPQ 维护着多个子队列，每个队列有自己的优先级。在调度的时候，队列按照优先级享有对应的权重，被选中的机会就是权重的大小。选好队列之后，再随机选择队列里面的请求。请求的 cost 越低，被选中的可能性越大。但是这个设计可能太“公平“了，但是对于低延迟的请求响应可能就不够及时。所以除了这个为普通优先级服务的加权公平队列之外，调度器还另外定义了一个单独的 WPQ，为低延迟的应用提供了严格优先级的服务。只有严格优先级队列里面的请求处理完了，它才会开始检查普通优先级的队列。</p>
</div>
</div>
<div class="sect3">
<h4 id="mclockscheduler">mClockScheduler</h4>
<div class="paragraph">
<p>前面提到一个 OSD 有多个调度器，但是它们共享除了系统线程之外所有的资源，而且缺少有效的隔离措施。所以在设置预留值的时候是按照假设的介质提供最大带宽按照 shard 的数量平均下来计算的。和 <code>ClassedOpQueueScheduler</code> 类似，<code>mClockScheduler</code> 定义了一个 "immediate" 队列，它提供为高优先级的客户端先进先出的服务。只有这个队列没有元素的情况下，才会转用基于 mClock 的队列。为了方便测试，现在预定义了三种 QoS 模式，分别为三大类请求设置了对应的参数：</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">QoS模式</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">服务类型</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">预留</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">权重</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">上限</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="3"><p class="tableblock">偏重客户性能</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">client</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">50%</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">inf</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">recovery</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">25%</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">100%</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">best effort</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">25%</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">inf</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="3"><p class="tableblock">均衡型</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">client</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">40%</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">100%</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">recovery</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">40%</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">150%</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">best effort</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">20%</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">inf</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top" rowspan="3"><p class="tableblock">集中精力 recovery 型</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">client</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">30%</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">80%</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">recovery</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">60%</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">200%</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">best effort</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1%</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">inf</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p><code>mClockScheduler</code> 中，很重要的一个函数是 <code>mClockScheduler::ClientRegistry::get_info()</code>，它负责把请求按照他们的 <code>get_scheduler_class()</code> 分门别类，套用上面配置的 <code>res</code>, <code>wgt</code> 和 <code>lim</code> 参数。</p>
</div>
<div class="ulist">
<ul>
<li>
<p>MOSDOp:</p>
<div class="ulist">
<ul>
<li>
<p><code>CEPH_MSG_OSD_OP</code> 或者 <code>CEPH_MSG_OSD_BACKOFF</code>: client。这一类所有的请求都用 <code>default_external_client_info</code></p>
</li>
<li>
<p>其他: immediate</p>
</li>
</ul>
</div>
</li>
<li>
<p>PG 操作</p>
<div class="ulist">
<ul>
<li>
<p>pg delete: background_best_effort</p>
</li>
<li>
<p>pg scrub: background_best_effort</p>
</li>
<li>
<p>pg snaptrim: background_best_effort</p>
</li>
<li>
<p>pg peering: immediate</p>
</li>
<li>
<p>pg recovery:</p>
<div class="ulist">
<ul>
<li>
<p>高优先级的就是: immediate</p>
</li>
<li>
<p>低优先级就是: background_recovery</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="客户端和服务端协作的-dmclock">客户端和服务端协作的 dmClock</h3>
<div class="paragraph">
<p>社区也曾推进 dmClock 在 Ceph 的应用。在 2018 年的 Cephalocon 上， SK 电信的工程师向我们分享了他们做的 <a href="https://www.slideshare.net/ssusercee823/implementing-distributed-mclock-in-ceph#6">工作</a>。甚至他们的改进曾经进入了 master，但是后来被 <a href="https://github.com/ceph/ceph/pull/21398">revert</a> 了，剩下的 <a href="https://github.com/ceph/ceph/pull/19340">PR</a> 到现在三年多过去了，没有进展。</p>
</div>
</div>
</div>
</div>]]></content><author><name>Kefu Chai</name><email>tchaikov@gmail.com</email></author><category term="ceph" /><summary type="html"><![CDATA[QoS，而且是分布式的。]]></summary></entry><entry><title type="html">大批量发送增量 osdmap 对性能的影响</title><link href="https://blog.k3fu.xyz/2021/03/29/flatten-osdmaps.html" rel="alternate" type="text/html" title="大批量发送增量 osdmap 对性能的影响" /><published>2021-03-29T00:00:00+00:00</published><updated>2021-03-29T00:00:00+00:00</updated><id>https://blog.k3fu.xyz/2021/03/29/flatten-osdmaps</id><content type="html" xml:base="https://blog.k3fu.xyz/2021/03/29/flatten-osdmaps.html"><![CDATA[<div class="paragraph">
<p>补丁太多了的话，加起来大小可能会比最终的版本更大。</p>
</div>
<div class="paragraph">
<p>在 Ceph 里面，osdmap 是一个很重要的数据。比如说，</p>
</div>
<div class="ulist">
<ul>
<li>
<p>集群的拓扑</p>
</li>
<li>
<p>集群里每个数据池的 crush 规则，甚至还有</p>
</li>
<li>
<p>一个屏蔽列表，集群会拒绝向在列表里面的客户端提供服务</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>但是正因为 osdmap 包含了太多信息，在集群里面传递完整的 osdmap 会耗费很多带宽，而且编解码完整版本的 osdmap 也加大了对 CPU 的压力。为了缓解这个压力，我们选择仅仅发送变化的那部分。在 monitor 上，每次 osdmap 有变化，我们不仅仅保存了最新完整版本的 osdmap，也会保存它的增量部分&#8201;&#8212;&#8201;我们用专门的对象保存这个部分，即 <code>OSDMap::Incremental</code>，有时候干脆叫它 inc map。所以当客户端找 monitor 要 osdmap 的时候，也会告诉对方自己手里面 osdmap 的版本 <code>m</code>，如果 monitor 的最新版 osdmap 的版本是 <code>n</code>，那么它就会把 <code>m..n</code> 的所有 inc map 都发给客户端。</p>
</div>
<div class="paragraph">
<p>但是有时候也会适得其反，因为积少成多，要是有很多的 inc map，为了发送这些 inc map，对 monitor 甚至客户端，累加起来的开销和发送一个完整 osdmap 比起来可能会更高。而且，需要注意的是，<code>Monitor::ms_dispatch()</code> 是在一个全局大锁里面执行的。很多其他操作也需要这个锁。所以我们应该尽量避免长时间地持有它，否则会造成很高的延迟。</p>
</div>
<div class="paragraph">
<p>要解决这个问题，有下面几个思路：</p>
</div>
<div class="ulist">
<ul>
<li>
<p>在 monitor 一侧</p>
<div class="ulist">
<ul>
<li>
<p>减少 monitor 对 osdmap 的更新频次。primary osd 会根据情况要求产生 pgtemp，但是 monitor 也可以主动地批次生成 pgtemp。</p>
</li>
<li>
<p>分期分批地发送 inc map。这样可以缓解因为长时间占用全局锁造成的延迟。</p>
</li>
</ul>
</div>
</li>
<li>
<p>在 osd 一侧</p>
<div class="ulist">
<ul>
<li>
<p>减少 osd 对 osdmap 的请求。如果 osd 发现自己落后太多，就直接找 monitor 要完整的最新版 osdmap。而不是要求获得增量版本。减轻 monitor 的负担。</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="paragraph">
<p>但是 <code>n</code> 版的 osdmap 是不是真的能替代 <code>m</code> 版 osdmap 加上中间的 <code>m..n</code> 的 inc map 呢?</p>
</div>]]></content><author><name>Kefu Chai</name><email>tchaikov@gmail.com</email></author><category term="ceph" /><summary type="html"><![CDATA[补丁太多了的话，加起来大小可能会比最终的版本更大。]]></summary></entry><entry><title type="html">方程式赛车和读写请求</title><link href="https://blog.k3fu.xyz/2021/03/14/lap-n-race.html" rel="alternate" type="text/html" title="方程式赛车和读写请求" /><published>2021-03-14T00:00:00+00:00</published><updated>2021-03-14T00:00:00+00:00</updated><id>https://blog.k3fu.xyz/2021/03/14/lap-n-race</id><content type="html" xml:base="https://blog.k3fu.xyz/2021/03/14/lap-n-race.html"><![CDATA[<div class="paragraph">
<p>请求 client.io-42 在第三圈超过了 client.io-17！</p>
</div>
<div class="paragraph">
<p>前阵子在思考在 Ceph 里面为什么要顺序执行读写。简单说，和 CPU 的顺序执行模型一样，这个模型更容易理解和使用。顺便跑题一下，对于"人工智能是什么"一直有个争论。其中有两派:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>弱人工智能，即表现上的人工智能。 <a href="https://en.wikipedia.org/wiki/Chinese_room">中文房间</a> 中文房间和 <a href="https://en.wikipedia.org/wiki/Turing_test">图灵测试</a> 就是两个比较有名的测试，通过它们就是一定程度上的弱人工智能。这种人工智能能解决一个特定问题领域上的问题。 现在说的机器学习就是一种弱人工智能。</p>
</li>
<li>
<p>强人工智能，即机理上的人工智能，或者说通用人工智能。这种人工智能需要具有知识表示，推理，规划，学习，自然语言处理等等能力，并把它们整合起来。强人工智能和弱人工智能比起来要难很多。前年看的 <a href="http://bayes.cs.ucla.edu/WHY/">The Book of Why: The New Science of Cause and Effect</a> 说明了因果关系和推理在人工智能的重要地位。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>和人工智能一样，存储系统的顺序性也有两种</p>
</div>
<div class="ulist">
<ul>
<li>
<p>表现出来是顺序的</p>
</li>
<li>
<p>严格在执行层面上就是顺序的</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>当然，限制越多，性能越不好。所以在实现 crimson 的时候，每当要求顺序执行的时候，我都会多问几次"为什么"。Ceph 集群里面，一个读写请求在一生中，至少有下面几个阶段</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>从客户端到 primary OSD</p>
</li>
<li>
<p>从 primary OSD 分配到对应的 PG</p>
</li>
<li>
<p>生成事务，并写入本地磁盘。事务包含 pglog 和对应的用户数据。</p>
</li>
<li>
<p>replica OSD 也回应了请求，确认持久化完成。</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>客户端请求就像方程式赛车一样，</p>
</div>
<div class="ulist">
<ul>
<li>
<p>必须遵守一定的规则，比如只有在持有要求的 osdmap 的时候才能开始处理它，不能依据老版本的 osdmap 行事。</p>
</li>
<li>
<p>需要跑完一定的圈数，</p>
</li>
<li>
<p>而且，对于 Ceph 来说，特定客户端发来的多个请求必须顺序完成。好像来自一个车队的选手必须按照出场顺序完赛一样。</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>在 crimson 里面，满足前两个要求都比较简单直接。问题在于第三个。如果 object store 能保证先进先出，那么是不是只要保证发送请求到 object store 的顺序满足第三个要求就行了呢？</p>
</div>
<div class="paragraph">
<p>答案是不行。在中间有的阶段需要有 write barrier，比如，为了保证 osd 在恢复时有个参考，pglog 保存了 PG 最近的一系列操作，它们保存在 pglog 里面。在构造 transaction 的时候，会和封装用户数据的 journal 一起刷到磁盘上。但是 pglog 是一个链表，链表上每个环节都是一次对 PG 的修改操作。为了逻辑上简单一些，我们需要 pglog 上的操作序列也按照按照客户请求的顺序安排。这样在副本不一致的时候，就可以按照顺序恢复了。不用担心因为乱序执行带来的数据依赖的问题。所以在生成 pglog 的时候，需要保证顺序。</p>
</div>
<div class="paragraph">
<p>类似的，在写磁盘的时候也需要保证顺序，因为相同的读写操作以不同顺序发送到后端存储，得到的结果是不一样的。这个道理和之前《多核和顺序》一文中讨论的问题类似。所以在写磁盘的时候也需要保序。我们使用流水线的设计解决这个问题。</p>
</div>]]></content><author><name>Kefu Chai</name><email>tchaikov@gmail.com</email></author><category term="ceph" /><summary type="html"><![CDATA[请求 client.io-42 在第三圈超过了 client.io-17！]]></summary></entry></feed>